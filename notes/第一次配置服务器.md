第一次白嫖了阿里云的服务器，使用的centos8.5

ip：8.130.30.62

# 安装jdk

首先需要搜索jdk安装包：

```shell
$ dnf search java | grep jdk
```

> ubuntu 下为：
>
> ```shell
> $ apt-cache serach openjdk
> ```

然后就能看到好多版本了

这里我安装了两个版本jdk11和jdk17

```shell
$ dnf install java-11-openjdk
```

**上面这个安装的是jre**：`java-11-openjdk.x86_64 : OpenJDK 11 Runtime Environment`

如果想要一步到位，就使用命令：

```shell
$ dnf install java-11-openjdk-devel
```

> `java-11-openjdk-devel.x86_64 : OpenJDK 11 Development Environment`

因为我安装了两个版本，如果需要切换，使用命令：

```shell
$ alternatives --config java
```

> 在 ubuntu 环境下更换 jdk 版本命令如下：
>
> ```shell
> $ sudo update-alternatives --config java
> ```

打印结果如下：

```shell
There are 2 programs which provide 'java'.

  Selection    Command
-----------------------------------------------
*+ 1           java-11-openjdk.x86_64 (/usr/lib/jvm/java-11-openjdk-11.0.13.0.8-4.el8_5.x86_64/bin/java)
   2           java-17-openjdk.x86_64 (/usr/lib/jvm/java-17-openjdk-17.0.1.0.12-2.el8_5.x86_64/bin/java)

Enter to keep the current selection[+], or type selection number:
```

切换版本还是比较方便的

安装好的jdk存放在：`/usr/lib/jvm`目录下

# 配置JAVA_HOME

这个需要修改环境变量的文件

```shell
$ vim /etc/profile
```

在配置文件的最后添加：

```shell
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-11.0.13.0.8-4.el8_5.x86_64
export PATH=$PATH:$JAVA_HOME/bin
```

添加了JAVA_HOME，配置了PATH

最后不要忘了更新环境变量：

```shell
$ source /etc/profile
```

注意这里其实不需要，也最好不要配置CLASSPATH

具体参考：[classpath和jar](https://www.liaoxuefeng.com/wiki/1252599548343744/1260466914339296)

# 安装Mysql

要安装`mysql-server`：

```shell
$ dnf install mysql-server
```

启动`mysql`：

> ```shell
> # 对于wsl
> $ service mysql start
> # 检查是否已经启动：
> $ ls
> ```

```shell
$ systemctl start mysqld.service
```

> 这里可以选择进入`mysql`安全性安装
>
> ```shell
> mysql_secure_insallation
> ```
>

通过下面的命令查看mysql服务器的状态：

```shell
$ systemctl status mysqld
```

正常情况下mysql会在服务器启动的时候伴随着启动，通过命令设置：

```shell
$ systemctl enable mysqld
```

> 如果希望取消设置：`systemctl disable mysqld`

## 导出原始数据库

```shell
# 将所有数据导出
mysqldump -uroot -p --all-databases > D:/all.sql
# 导出指定的数据库
mysqldump -uroot -p --databases db1 > D:/db1.sql
# 将db1中的user表导出，包含了表的结构和表中的数据
mysqldump -uroot -p --databases db1 --tables users > D:/users.sql
# 将db1中的user表导出，但仅包含部分满足条件的数据
mysqldump -uroot -p --databases db1 -- tables users --where='id=1' > D:/users.sql
# 仅导出结构而不导出数据的写法
mysqldump -uroot -p --no-data [后面的写法和上面一样]
# 仅导出数据而不导出结构的写法
mysqldump -uroot -p --no-create-info [后面的写法和上面一样]
```

## 开启mysql的远程连接

首先进入mysql数据库：

```shell
$ mysql -uroot -p

mysql> use mysql;

mysql> select host, user from user;
+-----------+------------------+
| host      | user             |
+-----------+------------------+
| localhost | debian-sys-maint |
| localhost | mysql.infoschema |
| localhost | mysql.session    |
| localhost | mysql.sys        |
| localhost | root             |
+-----------+------------------+
# 刷新权限管理
mysql> flush privileges;
```

其实这步不一定非要远程登录一个root用户，还可以新建一个用户：

```shell
# mysql8.0以上的版本，分为新建用户和授权两步
# 新建了一个用户buzz，他可以在任意位置（使用%表示）登录，登录的密码是buzz
mysql> create user 'buzz'@'%' identified by 'buzz'
# 授权
mysql> grant all privileges on *.* to 'buzz'@'%' with grant option;
# 刷新权限管理
mysql> flush privileges;

# 如果是mysql 8.0 之前的版本
mysql> grant all privileges on *.* to 'buzz'@'%' identified by 'buzz' with grant option;
# 刷新权限管理
mysql> flush privileges; 
```

## 将数据导入到远程数据库

最简单的办法，把上面导出的`.sql`文件直接拷到`DataGrip`中，然后执行

而现在想要通过`mysql`实现自己导入

首先是导入数据库，这个简单：

```shell
$ mysql -uroot -p [数据库名(k)] < [导出数据库名].sql
```

他会将数据库以及对应表的信息导入

# 上传工程到阿里云

本来使用的是阿里自带的插件上传，后来报错了

干脆直接把jar包传上去就得了，反正也就只需要jar包就可以运行springboot的工程

这里面使用`scp`进行文件的上传和下载

## 从服务器上下载文件

```shell
scp [username]@[ip/domainName]:[pathSend] [pathReceive]
```

看起来和ssh连接远程服务器没太大区别

`[username]`就是登录到远程服务器的用户名

`[ip/domainName]`是远程服务器的ip或者端口号

`[pathSend]`是在远程服务器上的文件路径

`[pathReceive]`是本机上保存文件的路径

比如：

```shell
scp root@aliyun:/root/sh/springboot.sh D:\springboot.sh
```

相当于从服务器上下载一个脚本，这个没有什么实际意义，说明作用

## 上传文件到服务器

```shell
scp [pathSend] [username]@[ip/domainName]:[pathReceive]
# 如果服务器上ssh的端口号并不是默认的22，需要我们指定对应的端口号
scp -P [port] [pathSend] [username]@[ip/domainName]:[pathReceive]
```

好吧，其实真的就是把上面的顺序变了一下

比如：

```shell
scp ./blogs.jar root@aliyun:/root/java_projects/blogs.jar
```

# 程序运行

因为在实际开发过程中和真正产品上线时使用的配置文件是有区别的

在打成jar包的时候，多个配置文件我都已经同时导出了

默认选择的是dev环境下的配置

不过在运行jar文件的时候还可以指定springboot运行的环境：

```shell
$ java -jar [project jar file] --spring.profiles.active=[profile name]
```

因为我们的日志是写入文件的，希望动态查看日志文件：

```shell
tail -f [logFile name]
```

这会动态的显示文件的末尾内容

上面这种简单的运行存在一些问题，比如当我们登出ssh，或者直接<kbd>ctrl + c</kbd>就会终止程序

> 以下内容参考：[jar包 后台运行](https://blog.csdn.net/qq_30739519/article/details/51115075)

毕竟此时程序是在前台运行，我们理所应当可以打断程序

为了实现后台运行，可以在命令最后添加一个`&`，即：

```shell
$ java -jar [project jar file] --spring.profiles.active=[profile name] &
```

此时程序在后台运行，但是，如果我们推出ssh窗口，程序还是会中断

所以改进的方法是：

```shell
$ nohup java -jar [project jar file] --spring.profiles.active=[profile name] &
```

实际运行的时候发现，执行上一条命令后控制台打印了：

```shell
nohup: ignoring input and appending output to 'nohup.out'
```

在项目路径下发现，多了一个`nohup.out`文件夹

因为执行`nohup`，默认会将任务的输出重定向到`nohup.out`文件中，当然我们是可以重定向输出的

所以最终我程序调用的命令格式如下：

```shell
$ nohup java -jar [project jar file] --spring.profiles.active=[profile name] > javaLog.log &
```

> 注意到我将控制台打印的输出重定向到`javaLog.log`中

程序在后台运行，仿佛我们失去了对程序的控制权，对于所有的程序：

```shell
$ jobs -l
```

上一条命令会打印所有运行在后台的程序，包括可程序的编号，这里的编号不是进程号

处于后台的程序如果希望前台运行：

```shell
$ fg %[job number]
```

如果希望再次切换到后台，需要先暂停前台程序<kbd>ctrl + z</kbd>，并输入指令：

```shell
$ bg %[job number]
```

以上的三个命令，注意都是针对于ssh连接的，即如果我们断开了ssh后，在连接，此时指令`jobs -l`是不能查看后台任务的

主要原因在于`jobs`获取的是当前bash进程下，子进程的后台任务，断开ssh连接，后台进程没有了父进程，变为了孤儿进程，被系统父进程接管

而第二次连接ssh后，新的bash下并没有子进程，故查看不到上一次的后台进程

此时如果需要查看后台进程可以：

```shell
# 查看后台的java程序
$ ps -aux | grep java
```

删掉这个进程：

```shell
$ kill -9 [pid]
```

此外还可以使用`screen`

# Screen

* 终端列表：

  ```shell
  $ screen -ls
  ```

* 创建一个虚拟终端：

  ```shell
  # 创建一个名为buzz的虚拟终端
  $ screen -S buzz
  # 创建一个名为buzz的虚拟终端，如果已经有了同名的终端，就加入之前的终端
  $ screen -R buzz
  ```

* 回到主终端：我们在任意一个screen页面中按下：<kbd>ctrl + a</kbd>，然后按<kbd>d</kbd>就可以回到主终端

* 回到某个screen：

  ```shell
  # 回到某个screen，如果不存在就不进，和-R不太一样的是，这个在不存在screen的时候不会新建一个screen
  $ screen -r [pid/name]
  ```

* 退出终端：直接`exit`

* 在主终端中退出：

  ```shell
  # 使用-R/-r/-S均可
  $ screen -R [pid/Name] -X quit
  ```

# 获取免费的SSL证书

从HTTP升级到HTTPS需要SSL证书，这里白嫖：[Let's Encrypt](https://letsencrypt.org/)

官网说使用[Certbot](https://certbot.eff.org/) ACME client获取证书，比较方便配置

然而获取这个客户端又说需要安装snapd，因为我是centos8.2，所以参考：[Installing snap on CentOS | Snapcraft documentation](https://snapcraft.io/docs/installing-snap-on-centos)

## 安装Snapd

这个首先需要添加库：`EPEL`

```shell
# dnf install epel-release
# dnf upgrade
```

在添加完库之后就可以正常安装了

```shell
# dnf install snapd
```

这里报了错

```shell
[root@VM-4-11-centos ~]# dnf install snapd
Invalid configuration value: failovermethod=priority in /etc/yum.repos.d/CentOS-Epel.repo; Configuration: OptionBinding with id "failovermethod" does not exist
Repository epel is listed more than once in the configuration
CentOS Linux 8 - AppStream                                                               87  B/s |  38  B     00:00
Error: Failed to download metadata for repo 'appstream': Cannot prepare internal mirrorlist: No URLs in mirrorlist
```

网上的办法十分暴力，他不是说是`Invalid configuration`吗，那我就把他注了：

```shell
# vim /etc/yum.repos.d/Centos-Epel.repo
# cat /etc/yum/repos.d/Centos-Epel.repo
name=EPEL for redhat/centos $releasever - $basearch
baseurl=http://mirrors.tencentyun.com/epel/$releasever/Everything/$basearch
#failovermethod=priority
enabled=1
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-8
```

这个改完了之后还是报错：

```shell
[root@VM-4-11-centos yum.repos.d]# dnf search snapd
Repository epel is listed more than once in the configuration
CentOS Linux 8 - AppStream                                                               77  B/s |  38  B     00:00
Error: Failed to download metadata for repo 'appstream': Cannot prepare internal mirrorlist: No URLs in mirrorlist
```

这个网上说是Centos8的包已经不在官方镜像中了 ？？？

新的地址在[https://vault.centos.org](https://vault.centos.org/)

修改两个文件：

```shell
# vim /etc/yum.repos.d/CentOS-Linux-BaseOS.repo
# vim /etc/yum.repos.d/CentOS-Linux-AppStream.repo
# cat /etc/yum.repos.d/CentOS-Linux-BaseOS.repo
# CentOS-Linux-BaseOS.repo
#
# The mirrorlist system uses the connecting IP address of the client and the
# update status of each mirror to pick current mirrors that are geographically
# close to the client.  You should use this for CentOS updates unless you are
# manually picking other mirrors.
#
# If the mirrorlist does not work for you, you can try the commented out
# baseurl line instead.

[baseos]
name=CentOS Linux $releasever - BaseOS
mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=BaseOS&infra=$infra
#baseurl=http://mirror.centos.org/$contentdir/$releasever/BaseOS/$basearch/os/
baseurl=https://vault.centos.org/centos/$releasever/BaseOS/$basearch/os/
gpgcheck=1
enabled=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-centosofficial
# cat /etc/yum.repos.d/CentOS-Linux-AppStream.repo
# CentOS-Linux-AppStream.repo
#
# The mirrorlist system uses the connecting IP address of the client and the
# update status of each mirror to pick current mirrors that are geographically
# close to the client.  You should use this for CentOS updates unless you are
# manually picking other mirrors.
#
# If the mirrorlist does not work for you, you can try the commented out
# baseurl line instead.

[appstream]
name=CentOS Linux $releasever - AppStream
mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=AppStream&infra=$infra
#baseurl=http://mirror.centos.org/$contentdir/$releasever/AppStream/$basearch/os/
baseurl=https://vault.centos.org/centos/$releasever/AppStream/$basearch/os/
gpgcheck=1
enabled=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-centosofficial
```

然后就可以正常安装了

官网上还说需要启用一个socket：

```shell
# systemctl enable --now snapd.socket
```

此外还要在根目录下创建一个软链接：

```shell
# ln -s /var/lib/snapd/snap /snap
```

为了可以正常使用`snapd`，最好使用前更新一下版本：

```shell
# snap install core;
# snap refresh core
```

## Certbot

首先是删除掉旧版的certbot

```shell
# dnf remove certbot
```

然后通过`snap`进行安装

```shell
# snap install --classic certbot
```

为了保证`certbot`的正常使用还需要添加一个软链接

```shell
# snap ln -s /snap/bin/certbot /usr/bin/certbot
```

后面的部分就需要域名备案后才能进行了

生成证书：

```shell
# certbot certonly --standalone 
```

这里需要输入域名

生成的证书默认在：`/etc/letsencrypt/live/{域名}/`目录下，一共生成了四个`.pem`文件

因为需要和`springboot`集成，将`.pem`格式转化为`.p12`格式

```shell
# openssl pkcs12 -export -in "{证书的路径}" -inkey "{私钥路径}" -out "{生成.p12格式文件的地址}"
```

一般的都是这种形式：

```shell
# openssl pkcs12 -export -in "/etc/letsencrypt/live/{域名}/cert.pem" -inkey "/etc/letsencrypt/live/{域名}/private.pem" -out "{这个路径自己定，只要文件是.p12结尾的就行}"
```

注意进行转化时会要求输入一个密码，这个不要乱输，很关键。

然后在`springboot`的yaml文件中进行ssl的配置：

```yaml
server:
  ssl:
    key-store: file:/{.p12文件的路径}
    key-store-password: {刚刚输入的密码}
    keyStoreType: PKCS12
```

默认的话`ssl`证书3个月就过期了，需要续期

```shell
# 下面的这个命令会检查所有证书的期限小于30天的，并且进行续期
# certbot renew
```

一般的话可以结合`cron`表达式实现自动续期

不过要注意的是因为在springboot中使用的是`pscs12`格式的`ssl`证书，所以`cron`定时任务不仅需要执行`renew`的操作，还需要重新转化为`.p12`格式的操作

# 修改用户

因为使用腾讯云的话默认给了一个用户`lighthouse`，我想用自己的，又不想新建，就把他这个默认的给改了

首先需要将对应用户的进程全部关掉：

```shell
# pkill -u lighthouse
# pkill -9 -u lighthouse
```

我们需要修改的：用户名、用户组、家目录

查看用户的属性：

```shell
# id [username]
```

注意上面的`username`为可选项，如果不填，那么查询的是默认用户

## 修改用户密码

```shell
# passwd [username]
```

举例来说就是

```shell
# passwd lighthouse
```

## 修改用户名

```shell
# usermod -l [newname] [oldname]
```

举例来说就是：

```shell
# usermod -l buzz lighthouse
```

## 修改家目录

```shell
# usermod -d [家目录] -m [username]
```

举例来说就是：

```shell
# usermod -d /home/buzz -m buzz
```

## 修改用户组

```shell
# groupmod -n [newgroup] [oldgroup]
```

举例来说就是：

```shell
# groupmod -n buzz lighthouse
```

## 为用户赋予sudo权限

反正它默认的这个用户执行：`sudo xxxx`的时候会说：

```shell
buzz is not in the sudoers file
```

就是说我现在这个用户没有`sudo`权限

那我就给他权限：

```shell
# vim /etc/sudoers
```

在`root	ALL=(ALL)	ALL`这行的下面添加：

`buzz	ALL=(ALL)	ALL`

> 注意，文件是只读的，所以为了写入，需要：`:w!`

# 一些基础

## 有关文件

使用命令`ls -l`可以产看文件的属性和所属的用户和组

```shell
$ ls -l
total 0
lrwxrwxrwx 1 buzz buzz  6 Mar 31 11:33 linkdir -> tmpdir
drwxrwxr-x 2 buzz buzz 21 Mar 31 11:35 tmpdir
```

我们看到，`tmpdir`第一项是d表示这是一个目录，而`linkdir`第一项是`l`表示当前文件是一个链接

特别的对于第一项：

- 当为 **d** 则是目录
- 当为 **-** 则是文件；
- 若是 **l** 则表示为链接文档(link file)，这里是软链接；
- 若是 **b** 则表示为装置文件里面的可供储存的接口设备(可随机存取装置)；
- 若是 **c** 则表示为装置文件里面的串行端口设备，例如键盘、鼠标(一次性读取装置)

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/linux_file_attributes.png)

上图中，一共10位标识了文件的权限信息，第一位已经说过了，后面9位是同一个文件针对不同用户的权限，如果有权限，则使用对应字母表示，如果没有权限，使用占位符`-`表示

## 软链接接和硬链接

先说一下linux中的文件系统，在linux中，文件分为两部分，元数据（metadata）和用户数据（userdata）

其中元数据是文件的附加属性，包含了索引节点（Inode）、文件大小、文件创建时间、文件所有者的信息

然而，上面这么多的信息，就是不包含文件名，文件名主要是为了方便用户使用，真正定位一个文件的其实是索引节点号

> 有点类似ip地址和域名的关系

用户数据是文件数据块，即二进制格式的数据块，记录着文件的真实内容

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/linux_metadata_userdata.png)

如果希望查看文件的节点索引号，使用命令

```shell
ls -i [fileName]
```

比如：

```shell
$ vim test.sh
$ cat test.sh
#!/bin/bash

echo "this is shell script"
$ ls -i test.sh
134241173 test.sh
```

### 硬链接

在linux中允许多个文件名含有同一个索引号

硬链接为通过索引节点号进行的链接，通过指令`ln`可以为文件创建硬链接

```shell
ln [original file] [link file]
```

比如：

```shell
$ ln test.sh hardlink.sh
$ ls -il
total 8
134241173 -rwxrwxrwx 2 buzz buzz 42 Mar 31 11:01 hardlink.sh
134241173 -rwxrwxrwx 2 buzz buzz 42 Mar 31 11:01 test.sh
```

可以看到使用硬链接创建的文件`hardlink.sh`具有和源文件`test.sh`相同的节点索引号

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/linux_hardlink.png)

如上图，既然文件节点索引号都一样了，文件数据肯定也是一样

注意到上面在执行了命令：`ls -il`后，表示文件权限后面多了一个2，这表示当前的硬链接数量

我们删除文件，其实删除的就是硬链接，当一个文件的硬链接数量变为0时，这个文件将被删除，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。

硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能。

### 软链接

软链接相当于创建了一个文件，这个文件的内容就是源文件的节点索引号，通过下面的命令创建软链接

```shell
ln -s [original file] [link file]
```

比如：

```shell
$ ln -s test.sh softlink.sh
$ ls -il
total 4
134241172 lrwxrwxrwx 1 buzz buzz  7 Mar 31 11:19 softlink.sh -> test.sh
134241173 -rwxrwxrwx 1 buzz buzz 42 Mar 31 11:19 test.sh
```

可以看到二者的节点索引是不同的，且源文件大小为42Bytes，而软链接的文件大小仅为7Bytes

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/linux_softlink.png)



和硬链接最大的区别在于如果我们删除了源文件，文件就真的被删除了，此时软链接是无效的

```shell
$ rm -rf test.sh
$ cat softlink.sh
cat: softlink.sh: No such file or directory
```

软链接主要应用在两个方面：

- 一是方便管理，例如可以把一个复杂路径下的文件链接到一个简单路径下方便用户访问；
- 另一方面就是解决文件系统磁盘空间不足的情况。例如某个文件文件系统空间已经用完了，但是现在必须在该文件系统下创建一个新的目录并存储大量的文件，那么可以把另一个剩余空间较多的文件系统中的目录链接到该文件系统中，这样就可以很好的解决空间不足问题；

### 目录链接

上面的操作都是创建关于文件的软链接和硬链接

其实关于目录也可以创建软连接（注意这里不能创建硬链接）

```shell
$ mkdir tempdir
$ ln -s tempdir linkdir
$ cd ./tempdir
$ vim test.sh
$ cat test.sh
#!/bin/bash

echo "buzz is shit"
$ cd ..
$ cd linkdir
$ ./test.sh
buzz is shit
```

我们在源文件夹中创建了一个文件`test.sh`，而在软链接指向的`linkdir`中可以查看文件`test.sh`

### 区别

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/linux_hardlink_softlink.png)

### win下的链接

现在有这样一个需求：

我原来新建了一个`learn_design_pattern`的项目，并在里面新建了一个`README`文档，就是笔记

现在我希望把这个笔记同步到我的`note`文件夹中，同时希望可以实现**同步修改**，不管是我直接在`note`文件夹中写，还是在项目的文档中写，我都希望可以直接同步

第一个思路是使用快捷方式，这个应该行，但是问题出现在我的`note`文件夹中设置了坚果云同步，不确定同步快捷方式是否会出现什么问题

既然软链接不行，那就试试硬链接吧，在`win`中使用：`mklink /?`查看有关链接的指令，具体的参数解释很详细了：

```shell
$ mklink /?
创建符号链接。

MKLINK [[/D] | [/H] | [/J]] Link Target

        /D      创建目录符号链接。默认为文件
                符号链接。
        /H      创建硬链接而非符号链接。
        /J      创建目录联接。
        Link    指定新的符号链接名称。
        Target  指定新链接引用的路径
                (相对或绝对)。
```

## 文件权限

linux中的文件权限针对三类对象：`owner`（所属用户）`group`（所属组）`other`（其他）

同时，每个对象对文件的权限通过三个字符表示：`r`读，`w`写，`x`执行

针对文件：`r`：读取文件，`w`修改文件，`x`执行文件（这里是指二进制的程序）

针对目录：`r`查看当前目录下的文件，`w`在目录下删除或创建文件

在linux中，文件的权限通过9个字符描述

通过`chmod`，可以修改文件的权限，使用数字进行修改权限比较简单：

* `r`表示4
* `w`表示2
* `x`表示1

所以一个用户对文件的最高权限表示为7

比如：

```shell
$ chmod 777 test.sh
```

给文件所属用户，文件所属组，及其其他人都赋予了最高权限

# 一些命令

## 删除

一般形式的删除

```shell
rm test.txt
```

删除一个文件的形式，且linux会询问是否真的要删除这个文件

而如果是目录的话就需要加上`-r`

```shell
mkdir test
rm -r test
```

如果仅有一层目录的话还好，如果是目录下还有子目录，还有各种文件，那么这个命令会依次询问是否删除这些目录和文件，太麻烦了

直接终极命令：

```shell
rm -rf test
```

参数`-f`表示不再询问，这个命令还挺危险的，毕竟它全都删掉了，如果写成了`rm -rf /`不知道会发生什么

## 重命名

这个其实就是移动命令：

```shell
mv [originalFile] [ta]
```

## 复制

默认的话只能复制文件，如果希望复制文件夹以及文件夹内部的所有文件：

```shell
cp -r [source] [destination]
```

其他的一些参数：

*   -i：添加这个参数后，复制的时候，如果目标文件 [destination] 已经存在，则会询问是否进行覆盖

*   -p：连同文件的属性(创建时间、权限、用户)一起复制过去(文件备份)

*   -d：如果文件是是一个链接(软链接或硬链接)，则将链接复制过去，而不是复制文件

*   --preserve=all：在 -p 的基础上赋予了一些其他属性

    >   其他属性：SELinux 属性、links、xattr

*   -a：等效于 -dr --preserve=all

## shell脚本

使用命令

```shell
cat /etc/shells
```

这个命令用来查看当前支持的shell脚本

```shell
/bin/sh  	# 指向/bin/bash
/bin/bash	# 最常用的shell
/usr/bin/sh
/usr/bin/bash
```

查看当前使用的shell

```shell
echo $SHELL
```

### shell变量

#### 命名规则

* 变量名称通常是大写字母，它可以由数字、字母（大小写）和下划线_组成。变量名区分大小写；**变量名称不能以数字开头**

* 等号 = 用于为变量分配值，在使用过程中**等号两边不能有空格**
* 变量存储的数据类型是整数值和字符串值
* 在对变量赋于字符串值时，建议用引号将其括起来
* 要对变量进行调用，需要在变量名称前加美元符号$
* 如果需要增加变量的值，那么可以进行变量值的叠加。不过变量需要用双引号包含“变量名”或用{变量名}包含

#### 分类

* 用户自定义变量

* 环境变量：这种变量中主要保存的是和系统操作环境相关的数据。

* 位置参数变量：这种变量主要是用来向脚本当中传递参数或数据的，变量名不能自定义，变量作用是固定的。

* 预定义变量：是Bash中已经定义好的变量，变量名不能自定义，变量作用也是固定的

从变量的作用域上，还可以将变量分为：

* 局部变量：shell 程序内部定义的，其使用范围仅限于定义它的程序，对其它程序不可见。包括：用户自定义变量、位置变量和预定义变量。
* 全局变量：就剩下了一个环境变量

#### 用户自定义变量

比如我们定义了变量name，并通过echo获取这个变量

```shell
buzz@envy-13:~$ name="buzz"
buzz@envy-13:~$ echo $name
buzz
```

需要注意的就是变量名不能是数字开头，等号两次不可以有空格

进行变量叠加时，使用`${var}`的形式避免歧义

比如：

```shell
buzz@envy-13:~$ echo ${name}xy
# 变量名buzz和xy进行叠加
buzzxy
# 系统误以为需要一个namexy的变量，所以输出为空
buzz@envy-13:~$ echo $namexy

```

删除变量：

```shell
buzz@envy-13:~$ name="buzz"
buzz@envy-13:~$ echo $name
buzz
buzz@envy-13:~$ unset name
# 因为删除所有输出为空
buzz@envy-13:~$ echo $name

```

#### 单引号和双引号的区别

* 单引号：直接打印输出，包括特殊字符
* 双引号：对特殊字符进行转移，比如对`\`，`$`进行转移

```shell
buzz@envy-13:~$ echo 'test ${name}'
test ${name}
buzz@envy-13:~$ echo "test ${name}"
test buzz
# \$意味着将$进行转移，它就相当于普通的符号了
buzz@envy-13:~$ echo "test \${name}"
test ${name}
```

#### 环境变量

在bash中，环境变量也分为两种

* 全局变量：对于shell会话和所有的子shell都是可见的

* 局部变量： 它只在自己的进程当中使用

比如：

```shell
$ name="buzz"
$ echo ${nam}
buzz
$ vim test.sh
$ cat test.sh
#!/bin/bash

echo ${name}
# 输出为空，因为bash test.sh相当于在另一个bash中进行了脚本的调用
# 所以访问不到变量name
$ bash test.sh

```

查看全局变量：

```shell
$ env | grep PATH
```

可以通过export将局部变量输出为全局变量：

```shell
buzz@envy-13:~/java_projects/sh$ export name
buzz@envy-13:~/java_projects/sh$ bash test.sh
wsl shell script
buzz
```

这种全局变量是暂时的，个人认为是当前进程和其子进程的，因为如果我再开一个shell，还是访问不了这个变量

实现真正上的全局变量，可以将其写入配置文件

当登录系统或新开启一个ssh连接启动bash进程时，一定会加载这4个配置文件：

- /etc/profile #系统全局环境和登录系统的一些配置

- /etc/bashrc #shell全局自义配置文件，用于自定义shell

  > 在ubuntu下为`/etc/bash.bashrc`

- /root/.bashrc #用于单独自定义某个用户的bash，如果不是root用户就换成`/home/{对用用户}/.bashrc`

- /root/.bash_profile #用户单独自定义某个用户的系统环境，同理如果不是root用户也需要更换访问路径

这就是为什么我们之前需要在`/etc/profile`下配置环境变量了

> 其实其他的位置也可以

#### 配置PATH

SHELL要执行某一个程序，它要在系统中去搜索这个程序的路径，path变量是用来定义命令和查找命令的目录，当我们安装了第三方程序后，可以把第三方程序bin目录添加到这个path路径内，就可以在全局调用这个第三方程序，这就是为什么之前不仅配置了`JAVA_HOME`还配置`PATH`

```shell
# 创建一个脚本文件
root@envy-13:/# vim /home/buzz/java_projects/sh/test.sh
# 为这个脚本文件赋予执行权限
root@envy-13:/# chmod +x /home/buzz/java_projects/sh/test.sh
# 执行
root@envy-13:/# /home/buzz/java_projects/sh/test.sh
wsl shell script
# 再执行
root@envy-13:/# test.sh
test.sh: command not found
```

我们上面直接调用 `test.sh`没有生效，其实就是没有配置PATH

```shell
root@envy-13:/# PATH=$PATH:/home/buzz/java_projects/sh/
root@envy-13:/# test.sh
wsl shell script
```

注意这里的配置其实改变的也是当前bash的PATH配置，如果希望生成全局变量，还是需要将其写入配置文件中

#### 位置参数变量

```shell
root@envy-13:/# cat /home/buzz/java_projects/sh/test.sh
#!/bin/bash

echo "wsl shell script"
# 第0个参数，其实就是命令本身
echo "arg0:$0"
# 第一个参数
echo "arg1:$1"
# 第二个参数
echo "arg2:$2"
# 第10个参数，从这个位置的参数开始，因为是十位数了，所以变量需要通过{}包裹
echo "arg10:${10}"
# 参数传递的时候使用空格间隔
root@envy-13:/# test.sh 111 222 3 4 5 6 7 8 9 10
wsl shell script
# 因为我们之前配了path，所以这里可以找到
arg0:/home/buzz/java_projects/sh/test.sh
arg1:111
arg2:222
arg10:10
```

#### 预定义的变量

这些变量是shell启动的时候预先设定的，无法被修改，为特殊的变量：

| 变量名 |                            说明                             |
| :----: | :---------------------------------------------------------: |
|   $*   |           以一个单字符串显示所有向脚本传递的参数;           |
|   $#   |                    传递到脚本的参数个数                     |
|   $$   |                     当前进程的进程号PID                     |
|   $?   | 显示最后命令的退出状态；0表示没有错误，其他任何值表明有错误 |
|   $!   |              后台运行的最后一个进程的进程号pid              |

```shell
[root@centos-7-24 tmp]# vim special_varliable.sh
#!/bin/bash

echo "$* 表示这个程序的所有参数"
echo "$# 表示这个程序的参数个数"

echo "$$ 表示程序的进程ID"

touch /tmp/b.txt & #最后的&表示程序后台运行
echo "$! 表示执行上一个后台进程的pid"
echo "$$ 表示程序的进程ID"
echo "$? 表示上一个程序的返回结果"                                                                                                                              
[root@centos-7-24 tmp]# chmod +x special_varliable.sh 
[root@centos-7-24 tmp]# ./special_varliable.sh 11 22 33 44 55
# 表示这个程序的所有参数
11 22 33 44 55 
# 表示这个程序的参数个数
5 
# 表示程序的进程ID
25614 
# 表示执行上一个后台进程的pid
25615 
# 表示程序的进程ID
25614 
# 表示上一个程序的返回结果
0 
```

### 读取键盘输入

#### 简单的输入

```shell
$ read a b
123 456
$ echo $a
123
$ echo $b
456
```

#### 密文显示

```shell
$ read -s password
$ echo $password
buzz
```

#### 限制长度

```shell
$ read -n 3 a
123456
$ echo $a
123
```

> 本来我以为是截断的，但是输入超出了后直接bash自动回车了

#### 显示输入提示

```shell
$ read -p "输入密码:" -s password
$ echo $password
buzz
```

### 条件判断

基本形式：

```shell
if [condition]; then
[some commands]
else if [condition]; then
[some commands]
else
[some commands]
fi
```

一个简单的脚本：

```shell
buzz@envy-13:~/java_projects/sh$ vim test.sh
buzz@envy-13:~/java_projects/sh$ cat test.sh
#!/bin/bash

if ls /home/buzz/test_dir; then
        echo "enter if branch"
else
        echo "enter else brancd"
fi

buzz@envy-13:~/java_projects/sh$ ./test.sh
# 最开始目录不存在，这里等效为$?，即上一个程序是否出错，所以进入else分支
ls: cannot access '/home/buzz/test_dir': No such file or directory
enter else brancd
buzz@envy-13:~/java_projects/sh$ cd ..
buzz@envy-13:~/java_projects$ cd ..
buzz@envy-13:~$ mkdir test_dir
buzz@envy-13:~$ bash ./java_projects/sh/test.sh
# 创建目录后
enter if branch
buzz@envy-13:~$
```

## tar

这是一个很厉害的命令，用来打包，并在打包后进行压缩、解压缩

> **打包是指将一大堆文件或目录变成一个总的文件；压缩则是将一个大的文件通过一些压缩算法变成一个小文件。**

简单的例子：

```shell
$ tar -cvf sql.tar blogs.sql
blogs.sql
$ ls
blogs.sql  sql.tar
```

上面的例子把`blogs.sql`文件打包成了`sql.tar`文件，当然，单独的一个文件的打包确实没什么意义，肯定要多个文件：

```shell
$ tar -cvf test.tar blogs.sql test.txt
blogs.sql
test.txt
$ ls
blogs.sql  test.tar  test.txt
```

解释一下参数：

* `-c`：表示创建新的tar文件
* `-v`：表示显示打包过程
* `-f`：表示自定打包后的文件

我们打包之后肯定想看看文件长什么样：

```shell
$ tar -tvf test.tar
-rw-rw-r-- buzz/buzz     11797 2022-04-16 21:57 blogs.sql
-rw-rw-r-- buzz/buzz         0 2022-04-25 14:40 test.txt
```

可以看到一个`test.tar`文件中包含了刚刚打包进去的两个文件

解释一下参数：

* `-t`：表示显示压缩文件内容

### 压缩文件

```shell
$ tar -zcvf test.tar.gz test.tar
```

我们把一个`tar`包进行了压缩，得到了一个`.gz`的压缩文件

当然，实际中可以不用这么麻烦，直接把文件压缩就行：

```shell
$ tar -zcvf test.tar.gz blogs.sql test.txt
```

解释一下参数：

* `-z`：表示使用`gzip`处理文件

### 解压文件

```shell
$ tar -zxvf test.tar.gz
```

一旦使用了这个命令，他将把文件全都解压出来

解释一下参数：

* `-x`：进行解压操作

# 突发奇想

## github

### 页面跳转

突然之间有了一个想法，那就是使用 github 写的 markdown 是可以实现跳转的，而且这种跳转还是和标题相关的，比如我可以在一个文件 a.md 跳转到同一个仓库中某个文件 b.md 的某个标题下

那么如果出现了重名标题，github 是怎么解决的呢，于是就试了一试

首先发现页面标题的跳转主要是依靠 url 后面的 [#] + [参数] 实现，比如现在想要跳转到当前标题下，那 url 一定有这种格式：xxx/第一次配置服务器.md#页面跳转

而对于重名的标题，他是通过 [-] + [序号解决的]，比如现在的重名标题叫 buzz，一共有三个这样的标题

那么如果访问第一个标题，参数为 #buzz；如果访问第二个标题，参数为 #buzz-1；如果访问第三个标题，参数为 #buzz-2

即从第一个重名位置开始，访问后面的标题都需要加上 [-] + [序号]

此外这种重名标题的访问和标题的级别是无关的，不管是几级标题，都符合这个规律，重名的不同级别的标题也服从这个规律

## SpaceVim

我是怎么想着配置这个的呢，主要是这段时间在学多线程，有一些程序，很小，使用IDEA打开的话就太慢了，还占空间

最开始在win下的解决方案是使用sublime，后来发现这个在中文输入的时候总会出现莫名其妙的乱码问题，估计就是win下GBK和UTF-8编码的混乱导致的

后来就想着在`linux`上搞一个类似的，不需要些什么大型项目的一个编辑器

最开始想着直接裸vim了，不过写的时候确实还是有点烦的，虽然比较考验语法基础了

后来就看到使用`spaceVim`，感觉还可以：[SpaceVim中文官网](https://spacevim.org/cn)

就是下载`spaceVim`确实太慢了，感觉在腾讯云上下了至少半个小时

也没有好的加速方法，我看了一下，他其实下载的是一个配置文件，然后再按照配置文件中的内容继续下载，这才变得慢

* 启用Java相关模块：进入`~./SpaceVim.d/init.toml`，加上一行：

  ```toml
  [[layers]]
    name = "lang#java"
  ```

  > 或者SPC f v d

### vim相关指令

* 复制当前行：`yy`

* 剪切当前行：`dd`

* 粘贴复制的内容：`p`

* 复制若干行：此时需要先进入可视模式（按`v`），然后移动光标选择需要复制的行，按`y`会完成复制；如果希望提前退出，直接`esc`即可

* 撤销：`u`（可以看到，撤销还是很危险的）

* 恢复撤销：`Ctrl + r`

* 全选：本来是`Ctrl + a`即可以全选了，这里使用等效的方式

  * `gg`来到文档开头
  * `G`来到文档结尾

  故可以先`gg`来到文档开头，然后`v`进入可视模式，然后`G`来到文档结尾，即可实现全选

  随后`y`表示复制；`d`表示删除

## 重装系统了

处于各种各样奇怪的原因，mysql挂了，重连也连不上，就重装系统了

然后就发现ssh连不上了，解决方式：

```shell
$ ssh-keygen -R tencent 
```

> 是的我换成腾讯云了，因为便宜

## Maven

是的，逐渐开始走上歧途，官网地址：[Maven – Download Apache Maven](https://maven.apache.org/download.cgi)

### 安装Maven

首先下载`maven`的压缩包：

```shell
# wget https://dlcdn.apache.org/maven/maven-3/3.8.5/binaries/apache-maven-3.8.5-bin.tar.gz
```

然后安装`maven`，其实就是解压这个压缩包，记得放在`/usr/local`目录下

```shell
# tar -zxvf apache-maven-3.8.5-bin.tar.gz
```

然后配置`maven`的环境变量：

```shell
# pwd
/usr/local/maven/apache-maven-3.8.5
# vim /etc/profile
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-11.0.13.0.8-4.el8_5.x86_64
export MAVEN_HOME=/usr/local/maven/apache-maven-3.8.5
export PATH=$PATH:$JAVA_HOME/bin:$MAVEN_HOME/bin
```

判断环境有没有配好：

```shell
# echo $MAVEN_HOME
# ehco $PATH
# mvn -v
```

### 一些配置

简单的配置，比如说我们希望自定义本地的`maven`仓库，方便统一管理；再比如我希望换源，因为远程的`maven`仓库下载确实太慢了

这些配置都在：`$MAVEN_HOME/config/settings.xml`文件中进行配置

配置本地仓库：

```xml
<localRepository>/home/buzz/local_repo</localRepository>
```

添加阿里云的镜像：

```xml
<mirrors>
	<!--添加阿里云maven镜像-->
	<mirror>
        <id>aliyunmaven</id>
        <mirrorOf>*</mirrorOf>
        <name>阿里云公共仓库</name>
        <url>https://maven.aliyun.com/repository/public</url>
    </mirror>
</mirrors>
```

### 构建项目

反正至少需要一个空的`Maven`项目：

```shell
# mvn archetype:gengerate
```

他会自动联网下载模板，当然是从镜像下载了

期间会有几个选项，第一个会问模板的类型，这个选择默认的（7）就行

然后是：

* `groupId`：这个就是公司名，我这里填的是：`com.buzz`
* `artifactId`：这个是项目名，随便起
* `version`：这个是版本号，默认为：`1.0-SNAPSHOT`
* `package`：这个是包名，你就和公司名一样就行

创建好项目后赶紧进入项目目录进行一次`mvn compile`，看看能不能编译

然后就报错了：

```shell
[ERROR] Source option 5 is no longer supported. Use 6 or later.
[ERROR] Target option 1.5 is no longer supported. Use 1.6 or later.
```

我一看，这不就是`jdk`版本的问题吗，赶紧到`pom.xml`文件中添加版本的配置：

```shell
vim pom.xml
<properties>
     <maven.compiler.source>11</maven.compiler.source>
     <maven.compiler.target>11</maven.compiler.target>
</properties>
```

## Redis

到官网上下稳定版：

```shell
# wget http://download.redis.io/releases/redis-x.x.x.tar.gz
```

> 我下载的最新的是`6.2.7`

安装过程和`maven`基本上差不多，放在`/usr/local`目录下，进行解压

然后进入`redis`的目录进行源码编译（因为默认带有了gcc环境）

```shell
# make
```

为了可以正常使用`redis`的二进制文件，需要：

```shell
# make install
```

## Nginx

### 安装

还是一样的下载源码：

[nginx: download](https://nginx.org/en/download.html)

```shell
# wget https://nginx.org/download/nginx-1.20.2.tar.gz
```

> 至少我下载的时候稳定版是1.20.2

然后同样的，解压放入/usr/local目录

然后`./configure`，这里我报错了，原因是`./configure: error: the HTTP rewrite module requires the PCRE library.`

解决的方式是：`dnf install pcre-devel`

最后`make`和`make install`

要注意的是，我是在`/usr/local/nginx-1.20.2`目录下进行的解压，并`make`，最后他在`/usr/local/nginx`目录下生成了可执行文件，这个目录下很干净，就是`sbin`、`conf`、`logs`、`html`

个人推测，他是把软件和源码分开了，这里的`/nginx`就是软件，而`/nginx-1.20.2`是源码

`nginx`在运行时，存在`master`和`worker`进程，其中`worker`进程用来解析并响应用户请求

> 多进程了已经

### nginx.conf

```nginx
#user  nobody;
# 因为nginx工作时分为master进程和worker进程，而实际中处理请求的是worker进程
# 这里配置的就是worker进程的个数
# 这里的进程个数一般为机器的内核个数
worker_processes  2;

# 这里配置的是每个worker进程可以同时处理链接的个数
events {
    worker_connections  1024;
}


http {
#   这里的include相当于将其他的配置文件引入，这里引入了一个文件mime.types
#   mime类型对应了响应的类型，比如文件，图片，文本...，随后客户端可以正常解析文件
    include       mime.types;
#   如果响应类型未在mime.types中定义，默认的mimeType为下面的这个
    default_type  application/octet-stream;

    sendfile        on;
    keepalive_timeout  65;
    # 一个server表示了nginx代理的一个主机
    server {
        listen       80;
        server_name  localhost;

        location / {
#           根目录为相对于nginx的目录，即/usr/local/nginx
            root   html;
            index  index.html index.htm;
        }

        #error_page  404              /404.html;

        # redirect server error pages to the static page /50x.html
        #
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
    }
}
```

### 反向代理

这里需要修改的也就是`nginx.conf`，这里以单机模拟`nacos`集群为例，在8847，8848，8849三个端口上启用了

```nginx
```



