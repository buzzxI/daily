# 查看启动参数

* 查看 jvm 启动参数：-XX:+PrintFlagsInitial 这会打印 jvm 所有默认的启动参数

# 日志

在springboot中默认使用了slf4j + logback作为日志框架，从springboot的启动中可以看到，其默认的日志级别是INFO级别

其实使用的时候不需要额外的引入日志框架的依赖了，在启动器：`spring-boot-starter`中默认已经包含了这两个日志框架

> 使用springboot开发web项目的时候肯定需要导入启动器：`spring-boot-starter-web`这个启动器中就含有了`spring-boot-starter`
>
> 其实真正起作用的启动器是：`spring-boot-starter-logging`

这里简单说一下slf4j和logback的区别：`slf4j`从名字上翻译过来是简单日志门面，他并不是一个具体的日志框架，只是定义了日志相关的接口，真正实现了这些接口的是`logback,log4j`这些日志框架，我们调用方法的时候，只需要调用`slf4j`定义好的方法，具体的实现交给底层的框架去做，这样就算以后更换了日志框架，代码层面是不需要改变的，也许还需要改一下配置文件

## level

logback日志级别：`TRACE < DEBUG < INFO < WARN < ERROR`

一般在开发环境中，可以降低日志级别，方便调试，而在生产环境中使用`ERROR`就好

此外`OFF`会关闭日志记录，而`ALL`会开启全部日志记录

在springboot的核心配置文件中，可以指定对应日志配置文件的地址，还可以指定对应包下的日志级别，比如：

```yaml
logging:
  # 配置项目启动后从logback-spring.xml中读取日志相关的配置
  config: classpath:logback-spring.xml
  # 指定将dao层的日志定为trace级别，这会将数据库查询使用的sql打印
  level:
    com.buzz.mapper: trace
   file:
	  # 指定日志文件的输出路径，这里使用j
      path: D:/myLog/
```

直接logback的配置文件直接写死：

```xml
<?xml version="1.0" encoding="UTF-8"?>

<!--
    scan: 当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。
    scanPeriod: 设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。
    debug: 当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。
-->
<configuration scan="true" scanPeriod="15 seconds" debug="false">

    <!--用来区分不同的应用程序的日志-->
    <contextName>logback</contextName>
    <property resource="application.yaml"/>
    <!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径，使用spring-boot的配置项logPath明确具体的位置-->
    <springProperty scope="context" name="LOG_HOME" source="logPath"/>

    <!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符 -->
    <property name="LOG_PATTERN" value="[ %-5level] [%d{yyyy-MM-dd HH:mm:ss.SSS}] [%t] %logger{50} %msg%n"/>

    <!-- 控制台输出 -->
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>

            <pattern>${LOG_PATTERN}</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>


    <!-- 按照每天生成日志文件 -->
    <appender name="INFO_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!--日志名,指定最新的文件名，其他文件名使用FileNamePattern -->
        <file>${LOG_HOME}/info.log</file>
        <!--过滤器，打印INFO级别以上的日志-->
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>INFO</level>
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!--指定滚动日志文件名-->
            <fileNamePattern>${LOG_HOME}/info.log-%d{yyyy-MM-dd}-%i.log</fileNamePattern>
            <!--单个文件最大大小-->
            <MaxFileSize>100MB</MaxFileSize>
            <!--日志文件保留最长天数-->
            <maxHistory>20</maxHistory>
            <!--日志文件的总大小，如果超出了会删除旧的日志文件-->
            <totalSizeCap>4GB</totalSizeCap>
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder><!-- 必须指定，否则不会往文件输出内容 -->
            <pattern>${LOG_PATTERN}</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <append>true</append>
    </appender>


    <appender name="ERROR_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_HOME}/error.log</file>
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>ERROR</level>
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${LOG_HOME}/error.log-%d{yyyy-MM-dd}-%i.log</fileNamePattern>
            <MaxFileSize>100MB</MaxFileSize>
            <maxHistory>20</maxHistory>
            <totalSizeCap>4GB</totalSizeCap>
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder><!-- 必须指定，否则不会往文件输出内容 -->
            <pattern>${LOG_PATTERN}</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <append>true</append>
    </appender>

    <springProfile name="dev">
        <!-- 日志输出级别 -->
        <root level="INFO">
            <appender-ref ref="STDOUT"/>
            <appender-ref ref="INFO_FILE"/>
            <appender-ref ref="ERROR_FILE"/>
        </root>
    </springProfile>

    <springProfile name="prod">
        <!-- 日志输出级别 -->
        <root level="ERROR">
            <appender-ref ref="INFO_FILE"/>
            <appender-ref ref="ERROR_FILE"/>
        </root>
    </springProfile>

</configuration>
```

# 关于加密

主要分为对称加密和非对称加密

>   有的可能还会提到哈希混淆加密，这其实并不是一种加密算法，而是一种散列算法

## Base64 编码

首先这根本就不是加密，就是一种编码格式，因为编码后字符集大小为 64 且为常见的 64 个字符，故称其为 Base64 编码

这 64 个字符为 [A-Z]、[a-z]、[0-9]、'+'、'/'

>   其实应该是 65 个字符，还有一个 '='，这个后面说

具体的转化规则为：6 位二进制一组，不足 6 位时低位补 0，同时在高位填充两位 0 构成一个字节，然后根据编码表中的映射关系，映射到字符集中的一个字符

>   之所以是 6 个一组是因为 6 个二进制可以表示的范围为 000000-111111(0-63)，一共 64 个数，对应了 64 个字符

具体的映射表的的顺序和上面的字符一致([A-Z] 映射了二进制数值的 0 到 25，[a-z] 映射了二进制字符的 26-51... 后面的以此类推)

考虑映射的时候因为在 ASCII 码中字符都是按照一个字节的表示，即一个字节表示一个字符，故一个字符具有 8 位，这样对于原来三个字节的数据，转化为 Base64 编码后变为了 4 个字节

所以实际进行编码时，都是三个字节的原始编码一组，翻译成四个字节 Base64 编码

如果剩余字节不足 3 个字节：

*   剩下 1 个字节，此时可以翻译成两个 Base64 字符，此时后面需要补充两个 '=' 的填充，组成 4 个 Base64 字符
*   剩下 2 个字节，此时可以翻译成三个 Base64 字符，此时后面需要补充一个 '=' 的填充，组成 4 个 Base64 字符

在 java 中使用工具类 [java.util.Base64](https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/Base64.html)，获取 Base64 编码器和解码器，进行编解码

```java
public void test() {
    Base64.Encoder encoder = Base64.getEncoder();
    byte[] encode = encoder.encode("abc".getBytes());
    Base64.Decoder decoder = Base64.getDecoder();
    byte[] decode = decoder.decode(encode);
    System.out.println(new  String(decode)); // 不出所料的打印了 abc
}
```

## Hash算法

这是一种单向的，不可恢复的算法，通过一定的 Hash 算法，提取数据的特征值，可以用来进行数据校验，但不能使用 Hash 运算结果恢复原数据

以前下载 win10 的 ISO 镜像的时候的时候，后面会提供一个 MD5 值，使用这个值可以用来校验镜像的完整性

### MD5

尽管已经出现过两个完全不同的文件，具有相同 MD5 值的例子，不过这个算法还是比较常用的

经过 MD5 运算后，将得到一个 128 bit 的二进制序列，而一般在展示的时候会呈现 16 进制的形式，所以一般看到的是 32 位的数据

一般运用于密码的存储中，密码一般不会以明文的形式保存在数据库中，通过使用 MD5 散列，增强了一定的安全性

不过一些常见的密码的 MD5 值实在是太普遍了，存储这些常见的 MD5 也不是很安全；所以更好的做法是在原始明文密码的基础上"加盐"

所谓加盐就是在原始密码中填充一些若干特定的额外字符，这样就算明文密码相同，在不同的"盐"的作用下，得到的 MD5 值也是不同的

在 java 中，[MessageDigest](https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/security/MessageDigest.html) 可以用来进行 MD5 加密

>   This MessageDigest class provides applications the functionality of a message digest algorithm, such as SHA-1 or SHA-256. Message digests are secure one-way hash functions that take arbitrary-sized data and output a fixed-length hash value.
>
>   MessageDigest 类可以为应用提供消息摘要算法的功能(这里的消息摘要算法其实就是 Hash 算法)，比如 SHA-1、SHA-256(这两个和 MD5 一样都是 Hash 算法)
>
>   消息摘要算法是一种单向的算法，输入可以为任意长度，而输出一定是定长的 hash 值

```java
public void test() {
    try {
        // 通过 getInstance 方法获取对应加密方式的 MessageDigest 对象
        MessageDigest messageDigest = MessageDigest.getInstance("MD5");
        // update 方法用于更新当前需要散列的消息
        messageDigest.update("abc".getBytes());
        // digest 用来完成散列操作
        byte[] digest = messageDigest.digest();
        // 因为得到的是一个 128 位的二进制，写成 byte 数组的话，就是 16 位
        System.out.println(digest.length); // 无论是什么输入, 得到的数组大小一定为 16
        StringBuilder builder = new StringBuilder();
        for (byte b : digest) {
            // 得到字节的十进制表示
            int num = b & 0xff;
            // 得到十六进制表示
            builder.append(Integer.toHexString(num));
        }
        System.out.println(builder.toString());
    } catch (NoSuchAlgorithmException e) {
        throw new RuntimeException(e);
    }
}
```

### SHA-1/SHA-256

和 MD5 差不多，只不过得到的结果是 160bit 的，变长了，就更安全了，但运算速度也变慢了

>   SHA-1 其实早就被发现出现碰撞了，不过这些都不关键，自己用的话 MD5 就够了

```java
public void test() {
    try {
        // 通过 getInstance 方法获取对应加密方式的 MessageDigest 对象
        MessageDigest messageDigest = MessageDigest.getInstance("SHA-256");
        // update 方法用于更新当前需要散列的消息
        messageDigest.update("abc".getBytes());
        // digest 用来完成散列操作
        byte[] digest = messageDigest.digest();
        // 因为得到的是一个 160 位的二进制，写成 byte 数组的话，就是 20 位
        System.out.println(digest.length); // 无论是什么输入, 得到的数组大小一定为 20
        StringBuilder builder = new StringBuilder();
        for (byte b : digest) {
            // 得到字节的十进制表示
            int num = b & 0xff;
            // 得到十六进制表示
            builder.append(Integer.toHexString(num));
        }
        System.out.println(builder.toString());
    } catch (NoSuchAlgorithmException e) {
        throw new RuntimeException(e);
    }
}
```

### HMAC

这个算法就厉害了，这玩意看起来和加盐后的 Hash 操作有点类似，其实也不太一样

HMAC 得到的结果是一个 Message Digest，但是它需要一个密钥才行

>   其实我感觉加盐就够了

在 java 中使用 [Mac](https://docs.oracle.com/en/java/javase/11/docs/api/java.base/javax/crypto/Mac.html)，进行加密

```java
public void test() {
    // 假如需要加密的消息为 "abcde"
    String message = "abcde";
    // 假如使用的密钥为 "123456"
    String key = "123456";
    // 根据密钥(字符形式)和加密算法计算得到一个 SecretKey(密钥类)
    SecretKey secretKey = new SecretKeySpec(key.getBytes(), "HmacMD5");
    try {
        // 根据加密算法 new 一个 HMAC 的加密类
        Mac mac = Mac.getInstance("HmacMD5");
        // 使用生成的密钥初始话这个类
        mac.init(secretKey);
        // 使用 doFinal 进行加密(使用 update 可以不断添加字符但不进行 hash 操作，使用 doFinal 就是 hash 操作了)
        byte[] bytes = mac.doFinal(message.getBytes());
        // 即便需要密钥，本质上和 MD5 操作也差不多，生成的是 128bit 的数据(字节数组大小一定是 16)
        System.out.println(bytes.length);
        StringBuilder builder = new StringBuilder();
        for (byte b : bytes) {
            int num = b & 0xff;
            builder.append(Integer.toHexString(num));
        }
        System.out.println(builder.toString());
    } catch (NoSuchAlgorithmException e) {
        throw new RuntimeException(e);
    } catch (InvalidKeyException e) {
        throw new RuntimeException(e);
    }
}
```

## 对称加密

这里特指 AES 加密，这个算法密钥的长度可选值为：128bit、192bit、256bit

在 java 中加密和解密的关键类是 Cipher，不过在加密和解密之前，随机生成(或者根据指定的字节生成) key 的操作是类似的

为了得到密钥需要：

*   先根据加密算法获取一个 KeyGenerator，即密钥生成器
*   初始化密钥生成器需要生成的密钥的大小(比如 AES 算法的 128bit 长度密钥)
*   调用 generateKey() 获取一个 SecretKey 对象(表示密钥的对象)
*   调用 getEncoded() 方法，获取实际的 AES key

具体的如下：

```java
public void test() {
    try {
        // 需要使用 KeyGenerator 生成 key
        KeyGenerator generator = KeyGenerator.getInstance("AES");
        // 初始化密钥大小为 128bit
        generator.init(128);
        // 根据 generator 生成一个密钥
        SecretKey secretKey = generator.generateKey();
        // 这里可以获取到具体的 key，通过加算法和 key 本身也可以构造出 SecretKey 对象
        byte[] key = secretKey.getEncoded();
    } catch (NoSuchAlgorithmException e) {
        throw new RuntimeException(e);
    }
}
```

实际使用 Cipher 对象的时候使用的密钥并不是字节数组，而是某个 SecretKey 对象，下面给出加密和解密操作

```java
/**
 * 加密操作
 * @param msg 需要加密的消息
 * @param 密钥
 * @return 加密后的字节数组
 */
public byte[] encode(String msg, byte[] key) {
    byte[] encodedMsg;
    try {
        // 根据字节数组生成一个 SecretKey 对象
        SecretKey secretKey = new SecretKeySpec(key, "AES");
        // 获取 AES 算法的 cipher 对象(在 java 中主要使用这个对象进行加密和解密操作)
        Cipher cipher = Cipher.getInstance("AES");
        // 设置 cipher 为加密模式，同时使用密钥对象初始化 cipher 对象
        cipher.init(Cipher.ENCRYPT_MODE, secretKey);
        // 使用 update 方法可以不断添加数据，而不加密，如果调用了 doFinal 方法，就是进行加密
        encodedMsg = cipher.doFinal(msg.getBytes());
    } catch (NoSuchAlgorithmException e) {
        throw new RuntimeException(e);
    } catch (NoSuchPaddingException e) {
        throw new RuntimeException(e);
    } catch (IllegalBlockSizeException e) {
        throw new RuntimeException(e);
    } catch (BadPaddingException e) {
        throw new RuntimeException(e);
    } catch (InvalidKeyException e) {
        throw new RuntimeException(e);
    }
    return encodedMsg;
}

/**
 * 解密操作
 * @param encodedMsg 待解密的字节数组
 * @param key 密钥
 * @return 解密后的信息
 */
public String decode(byte[] encodedMsg, byte key) {
    String msg;
    try {
        // 根据字节数组生成一个 SecretKey 对象
        SecretKey secretKey = new SecretKeySpec(key, "AES");
        // 获取 AES 算法的 cipher 对象(在 java 中主要使用这个对象进行加密和解密操作)
        Cipher cipher = Cipher.getInstance("AES");
        // 设置 cipher 为解密模式，同时使用密钥对象初始化 cipher 对象
        cipher.init(Cipher.DECRYPT_MODE, secretKey);
        // 使用 update 方法可以不断添加数据，而不加密，如果调用了 doFinal 方法，就是进行解密
        byte[] bytes = cipher.doFinal(encodedMsg);
        // 理论上得到的这个 byte 数组可以用来直接 new 数组了，当然最好指明编码格式，一般就是 utf-8
        msg = new String(bytes);
    } catch (NoSuchAlgorithmException e) {
        throw new RuntimeException(e);
    } catch (NoSuchPaddingException e) {
        throw new RuntimeException(e);
    } catch (InvalidKeyException e) {
        throw new RuntimeException(e);
    } catch (IllegalBlockSizeException e) {
        throw new RuntimeException(e);
    } catch (BadPaddingException e) {
        throw new RuntimeException(e);
    }
    return msg;
}
```

可以看到最神秘的过程不过就是得到密钥的过程，剩下的指定好算法就行了，这个密钥是通过 KeyGenerator 得到的，给定加密算法和需要的密钥长度就可以生成一个密钥，十分方便

这个类还可以配置随机源，我觉得是没什么必要的，大佬也是这么想的[encryption - How to create a secure random AES key in Java? - Stack Overflow](https://stackoverflow.com/questions/18228579/how-to-create-a-secure-random-aes-key-in-java/18229498#18229498)

## 非对称加密

就是 RSA 了，剩下的就不考虑了，RSA 的安全性基于大数很难进行质因数分解

因为是非对称加密，所以这个算法会计算出一个私钥和一个公钥，这里私钥和公钥都是通过数对的形式表示的，定义 (n,e) 表示公钥；(n,d) 表示私钥

如果明文为 x，密文为 y，那么有：$y = x^e\mod{n}; x = y^d\mod n$

>   计算的方式如下：
>
>   *   找两个大的质数，比如 p、q，那么 n = pq
>
>   *   定义 m = (p - 1)(q - 1)
>
>   *   在范围 (1,m) 内找到一个 e，使得 gcd(m,e) = 1
>
>       >   就是找到和 m 互质的整数 e，要求这个 e 比 m 要小
>
>   *   找到 d，使得 ed mod m = 1

因为公钥是公开的，所以理论上 n 和 e 都是知道的，如果想要破解 RSA 算法，就需要知道 d，显然关键点在于得到 m

为了知道 m 就需要知道 p 和 q，即通过 n 将其分解为两个大质数，只要能分别得到 p 和 q，就可以计算得到 m，推导出 d

大数的质因数分解是比较困难的(尤其是两个质因数本身也是大数)

基本的写法和对称加密差不多，都是通过密钥生成器生成密钥，然后配合 Cipher 类进行加密或解密操作

首先是获取密钥：

*   获取指定算法的 keyGenerator
*   初始化密钥的长度
*   获取密钥对
*   通过 getEncode() 方法获取密钥的二进制表示用于持久化

```java
public void test() {
    // 获取 RSA 类的密钥生成器(由 KeyGenerator 变为了 KeyPairGenerator)
    KeyPairGenerator generator = KeyPairGenerator.getInstance("RSA");
    // 初始化密钥长度为 2048 位
    generator.initialize(2048);
    // 由密钥生成器获取密钥对
    KeyPair keyPair = generator.generateKeyPair();
    // getEncode 用来获取公钥和私钥的二进制表示，用来持久化密钥
    // 要注意的是默认的 pubKey 的二进制表示是被 X.509 进行编码的，而 privateKey 是被 PKCS#8 编码的
    byte[] privateKey = keyPair.getPrivate().getEncoded();
    byte[] pubKey = keyPair.getPublic().getEncoded();
}
```

然后是加密和解密操作，这里其实主要使用的对象还是 Cipher

```java
/**
 * 加密操作
 * @param msg 需要加密的消息
 * @param key 加密的密钥
 * @return 加密后的字节数组
 */
public static byte[] encode(String msg, byte[] key) {
    byte[] encodedMsg;
    try {
        // 首先需要构造 PublicKey 公钥对象，因为公钥是通过 X.509 编码的，所以需要这个对象还原密钥
        KeyFactory factory = KeyFactory.getInstance("RSA");
        PublicKey publicKey = factory.generatePublic(new X509EncodedKeySpec(key));
        Cipher cipher = Cipher.getInstance("RSA");
        cipher.init(Cipher.ENCRYPT_MODE, publicKey);
        encodedMsg = cipher.doFinal(msg.getBytes());
    } catch (NoSuchAlgorithmException e) {
        throw new RuntimeException(e);
    } catch (InvalidKeySpecException e) {
        throw new RuntimeException(e);
    } catch (NoSuchPaddingException e) {
        throw new RuntimeException(e);
    } catch (InvalidKeyException e) {
        throw new RuntimeException(e);
    } catch (IllegalBlockSizeException e) {
        throw new RuntimeException(e);
    } catch (BadPaddingException e) {
        throw new RuntimeException(e);
    }
    return encodedMsg;
}
/**
 * 解密操作
 * @param encodedMsg 待解密的字节数组
 * @param key 密钥
 * @return 解密后的信息
 */
public static String decode(byte[] encodedMsg, byte[] key) {
    String msg;
    try {
        // 基本一样，区别在于私钥是通过 PCKS#8 进行编码的，所以需要这个对象换原私钥
        KeyFactory factory = KeyFactory.getInstance("RSA");
        PrivateKey privateKey = factory.generatePrivate(new PKCS8EncodedKeySpec(key));
        Cipher cipher = Cipher.getInstance("RSA");
        cipher.init(Cipher.DECRYPT_MODE, privateKey);
        byte[] bytes = cipher.doFinal(encodedMsg);
        msg = new String(bytes);
    } catch (NoSuchAlgorithmException e) {
        throw new RuntimeException(e);
    } catch (NoSuchPaddingException e) {
        throw new RuntimeException(e);
    } catch (InvalidKeyException e) {
        throw new RuntimeException(e);
    } catch (IllegalBlockSizeException e) {
        throw new RuntimeException(e);
    } catch (BadPaddingException e) {
        throw new RuntimeException(e);
    } catch (InvalidKeySpecException e) {
        throw new RuntimeException(e);
    }
    return msg;
}
```

# UUID

这个在`java.util`包下有一个工具类，就叫`UUID`

调用静态方法：`UUID.randomUUID()`会返回一个`UUID`对象，当然我们一般时要将其转换为字符串的形式使用

它返回的UUID形式上是：`{8}-{4}-{4}-{4}-{12}`，一共32位16进制

```java
public void test() {
    // 得到一个格式为 {8}-{4}-{4}-{4}-{12} 的 uuid
    String uuid = UUID.randomUUID().toString();
    // 一般的可以将其格式化，即去除没有意义的横线
    uuid = uuid.replaceAll("-", "");
}
```

# Optional

主要参考：[Optional-API](https://docs.oracle.com/javase/8/docs/api/java/util/Optional.html)、[option工具类](https://blog.csdn.net/qq_41446768/article/details/88991904)

可以简单的认为这个类是一个包装类，它可以将对象包装，避免出现NullPointerException的问题

## 创建包装

首先，它的构造器都是private类型的，这意味着我们不能直接new出来

> 经过尝试，在spring mvc的controller中我们可以直接在方法参数列表中填入一个这个类型的参数，他会自动帮我们封装好

所以为了获取Optional实例显然需要使用静态方法，一共有三个：

```java
public static void main(String args[]){
    //创建一个空的包装类，这里面存储的是null
    Optional<Integer> value1 = Optional.empty();
    //创建一个包装类，使用Optinal.of()方法的时候参数不可以为null，不然会报错
    Optional<Integer> value2 = Optional.of(1);
    //创建一个包装类，这个参数可以为null
    Optional<Integer> value3 = Optional.ofNullable(null);

    System.out.println(value1);		//Optional.empty
    System.out.println(value2);		//Optional[1]
    System.out.println(value3);		//Optional.empty
}
```

综上，只有我们明确了，对象一定不为空的时候才可以使用方法`of()`进行包装类的创建，否则，尽量使用`ofNullable()`创建

## 获取内部对象

从API文档中，看名字都知道肯定使用方法：`get()`

```java
public static void main(String args[]){
    Optional<Integer> value = Optional.of(1);
    System.out.println(value.get());		//1
}
```

然而，要注意的是，内部的对象可能为null，如果我们在内部对象为null的情况下调用这个方法还是会报错的

所以一般情况下，调用get方法之前需要调用`isPresent()`，确定内部对象是否存在：

> 值得一提的是在jdk11中还有一个方法：`isEmpty()`这个方法就是看看内部的value是不是空，看源码可有意思了：
>
> ```java
>     /**
>      * If a value is present, returns {@code true}, otherwise {@code false}.
>      *
>      * @return {@code true} if a value is present, otherwise {@code false}
>      */
>     public boolean isPresent() {
>         return value != null;
>     }
> 
>     /**
>      * If a value is  not present, returns {@code true}, otherwise
>      * {@code false}.
>      *
>      * @return  {@code true} if a value is not present, otherwise {@code false}
>      * @since   11
>      */
>     public boolean isEmpty() {
>         return value == null;
>     }
> ```
>
> 合着你俩隔着玩呢，一个判断是不是null一个判断是不是不是null

```java
public static void main(String args[]){
    Optional<Integer> value = Optional.ofNullable(null);
    if (value.isPresent()) {
        System.out.println(value.get());	//不打印因为内部对象为null
    }
}
```

但其实在引入了lambda表达式后，我们可以简化上面的写法：

```java
public static void main(String args[]){
    Optional<Integer> value = Optional.of(10);
    //value.ifPresent(System.out::println);
    value.ifPresent(integer -> System.out.println(integer.get()));
}
```

> 如果不熟悉lambda表达式的话就忽略注释部分吧

此外我们还可以对这个类使用类似于map中`getOrDefault()`的方法：

```java
public static void main(String args[]){
    Optional<Integer> value = Optional.ofNullable(null);
    // 如果没值就返回给定的default值
    System.out.println(value.orElse(20)); //20
    // 如果没值就返回从Supplier函数式接口中get到的值
    System.out.println(value.orElseGet(() -> 100));
}
```

> 还有一些方法：
>
> `orElseThrow()`如果value为空就抛异常

再有就是jdk8中引入stream后的骚操作了，这里就不说了

# 注解

## 四个元注解

* `@Target`：这个注解表明了注解的作用范围：
  * `ElementType.CONSTRUCTURE`：表示当前注解可以作用于构造器
  * `ElementType.FIELD`：表示当前注解可以作用于成员变量（域）
  * `ElementType.METHOD`：表示当前注解可以作用于方法
  * `ElementType.PACKAGE`：表示当前注解可以作用于包，这个在使用的时候需要在包中新建`package-info.java`
  * `ElementType.PARAMETER`：表示当前注解作用于参数（方法中的参数）
  * `ElementType.LOCAL_VARIABLE`：当前注解作用于局部变量
  * `ElementType.ANNOTATION_TYPE`：当前注解作用于注解
  * `ElementType.Type_USE`：作用于任何地方
* `@Retention`：描述注解保留的时间就三种取值：
  * `RetentionPolicy.SOURCE`：仅在源文件中保留
  * `RetentionPolicy.CLASS`：保留到字节码文件中（编译器保留），这是默认值
  * `RetentionPolicy.RUNTIME`：运行时保留，这个用的比较多，在运行时，可以通过反射获得注解
* `@Documented`：使用javadoc帮助文档时，是否保留类上的注解信息
* `@Inherited`：这个注解做那个用于自定义的注解，考虑注解`A`使用了注解：`@Inherited`，注解`B`继承了`A`，那么`B`会继承`A`注解上的属性

# java8的时间类

由于常用的`Date`和`SimpleDateFormat`并不是线程安全的，所以在java8中提出了新的时间类

即`LocalDate`、`LocalTime`、`LocalDateTime`

其中`LocalDate`可以存储的是日期，即年月日，`LocalTime`存储的是时间即时分秒；而`LocalDateTime`既可以存储时间也可以存储日期

此外还有一个格式化时间的工具`DateTimeFormatter`(这个类本身自己就可以实现日期转换)

> 这下`Date`和`SimpleDateFormat`可以被完全替换掉了

常用的方法：

```java
// 获取当前时间
LocalTimeDate date = LocalTimeDate.now();
// 将当前时间格式化为字符串格式
String time = 
    data.format(DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss a"));
// 将字符串格式的时间解析为时间类
LocalTimeDate dParse = 
    LocalTimeDate.parse(time, (DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss a")));
```

方法`format()`需要一个类型为`DateTimeFormat`类型的参数，往往这个参数并不需要我们手动new出一个对象，可以通过调用静态方法：`ofPattern()`传入我们希望格式化的形式，当然，默认的，已经提供好了若干种格式（在源码里都可以看到，这里就不演示了）

方法`parse()`可以将字符串类型的时间转换为一个时间类

在`mybatis`中已经官方已经提供给了三个`TypeHandler`：

* 对于JDBC类型为`DATE`类型的将转化为`LocalDate`类型
* 对于JDBC类型为`TIME`类型的将转化为`LocalTime`类型
* 对于JDBC类型为`TIMESTAMP`类型的将转化为`LocalDateTime`类型

## 其他转换

有的时候单独的一种 LocalDateTime 可能不能满足需求，有的时候需要让其转换为其他类型，当让最常见的就是和 string 类型的相互转换，这个上面已经提到了

其他的转换机制，比如希望类型 LocalDateTime 和类型 Timestamp 相互转换

```java
LocalDateTime dateTime = LocalDateTime.now();
// 将 LocalDateTime 转换为 Timestamp 类型
Timestamp timestamp = Timestamp.valueof(dateTime);
// 将 Timestamp 转换为 LocalDateTime 类型
LocalDateTime time = timestamp.toLocalDateTime();
```

# final

`final`可以作用在成员变量、类变量、方法、类、当然还包括局部变量

## 类变量

```java
public class TestFinal {
    // 带有static修饰的都是类变量
    private static final int i;
    private static final int j = 1;
    // 报错
    //private static final int k;
    static {
        i = 10;
    }
}
```

被`final`修饰的类变量(带有`static`修饰的)，需要在声明的时候，或者在静态代码块中完成初始化

将上述代码反编译得到：

```shell
Classfile /home/buzz/java_projects/simple_java/TestFinal.class
  Last modified Apr 14, 2022; size 318 bytes
  MD5 checksum ebcafd789f099c239ff7b52943a66aa2
  Compiled from "TestFinal.java"
public class TestFinal
  minor version: 0
  major version: 55
  flags: (0x0021) ACC_PUBLIC, ACC_SUPER
  this_class: #3                          // TestFinal
  super_class: #4                         // java/lang/Object
  interfaces: 0, fields: 2, methods: 2, attributes: 1
Constant pool:
   #1 = Methodref          #4.#17         // java/lang/Object."<init>":()V
   #2 = Fieldref           #3.#18         // TestFinal.i:I
   #3 = Class              #19            // TestFinal
   #4 = Class              #20            // java/lang/Object
   #5 = Utf8               i
   #6 = Utf8               I
   #7 = Utf8               j
   #8 = Utf8               ConstantValue
   #9 = Integer            1
  #10 = Utf8               <init>
  #11 = Utf8               ()V
  #12 = Utf8               Code
  #13 = Utf8               LineNumberTable
  #14 = Utf8               <clinit>
  #15 = Utf8               SourceFile
  #16 = Utf8               TestFinal.java
  #17 = NameAndType        #10:#11        // "<init>":()V
  #18 = NameAndType        #5:#6          // i:I
  #19 = Utf8               TestFinal
  #20 = Utf8               java/lang/Object
{
  public TestFinal();
    descriptor: ()V
    flags: (0x0001) ACC_PUBLIC
    Code:
      stack=1, locals=1, args_size=1
         0: aload_0
         1: invokespecial #1                  // Method java/lang/Object."<init>":()V
         4: return
      LineNumberTable:
        line 5: 0

  static {};
    descriptor: ()V
    flags: (0x0008) ACC_STATIC
    Code:
      stack=1, locals=0, args_size=0
         0: bipush        10
         2: putstatic     #2                  // Field i:I
         5: return
      LineNumberTable:
        line 9: 0
        line 10: 5
}
```

可以看到，我们给类变量`j`声明的时候就已经赋值了，所以在常量池中可以看到常量`1`，而对于类变量`i`在静态代码块中显式的进行赋值

## 方法

被`final`修饰的方法，不可以被子类重写

java编程思想中明确说了，使用`final`修饰方法，只有两个原因：

* 把方法锁定，防止子类进行修改；
* 为了效率，早期的`jdk`会把`final`方法修改为内嵌调用，而内嵌调用的方法如果太大，效率提升会变得很不明显，所以现在使用的`jdk`并不会进行这种优化了

所以现在而言，使用`final`修饰方法，其实就是为了禁止子类重写方法

> private的方法会被隐式的指定为`final`方法
>
> 父类的`private`方法对子类是不可见的，所以也就不存在重写的关系

## 类

`final`的类无法被继承，且`final`类的中的方法也是默认final的

# TimeUnit

工具类，也是枚举类，提供了从天到纳秒级别的单位。

枚举类的实例：

```java
NANOSECONDS(TimeUnit.NANO_SCALE),
MICROSECONDS(TimeUnit.MICRO_SCALE),
MILLISECONDS(TimeUnit.MILLI_SCALE),
SECONDS(TimeUnit.SECOND_SCALE),
MINUTES(TimeUnit.MINUTE_SCALE),
HOURS(TimeUnit.HOUR_SCALE),
DAYS(TimeUnit.DAY_SCALE);
```

## 单位转换

一个通用方法：

```java
//Converts the given time duration in the given unit to this unit. 
public long convert(long sourceDuration, TimeUnit sourceUnit)
```

举例说明：

```java
public static void main(String[] args) {
    long convert = TimeUnit.DAYS.convert(24, TimeUnit.HOURS);
    System.out.println(convert);//1
}
```

我们调用某个枚举实体的方法`convert`，其实就是将对应单位的时间长度，转换为当前的时间长度。

注意的是，这个返回值为`long`类型，实测如果不足进位的话，就舍掉，比如上面的参数如果小于24返回值就是0

其他的转换：

```java
public long toMillis(long d)    //转化成毫秒
public long toSeconds(long d)  //转化成秒
public long toMinutes(long d)  //转化成分钟
public long toHours(long d)    //转化成小时
public long toDays(long d)     //转化天
```

因为不是静态的方法，所以需要枚举实例去调用这些方法

## 线程休眠

这个类最大的作用其实是用来代替`Thread.sleep()`方法实现线程休眠，因为它天然具有多个事件粒度，所以可以直接从方法调用上就能看出来休眠事件

```java
/**
  * Performs a Thread.sleep using this time unit.
  * This is a convenience method that converts time arguments into the
  * form required by the {@code Thread.sleep} method.
  * 
  * @param timeout the minimum time to sleep. If less than
  * or equal to zero, do not sleep at all.
  * @throws InterruptedException if interrupted while sleeping
  */
public void sleep(long timeout) throws InterruptedException {
    if (timeout > 0) {
        long ms = toMillis(timeout);
        int ns = excessNanos(timeout, ms);
        Thread.sleep(ms, ns);
    }
}
```

可以看到其本质上也是调用了`Thread.sleep`方法，其真正的意义在于程序的可读性更高

以线程休眠5min为例：

```java
// 现在的写法
public void main(String[] args) {
    try {
        TimeUnit.MINUTES.sleep(5);
    } catch (InterruptedException e) {
        System.out.println("线程被打断")
    }
}

// 原来的写法
public void main(String[] args) {
    try {
        // 因为原来的方法，默认单位是毫秒，所以需要单位的转换
        Thread.sleep(1000 * 60 * 5);
    } catch (InterruptedException e) {
        System.out.println("线程被打断")
    }
}
```

# CAP理论

[一文看懂｜分布式系统之CAP理论](https://cloud.tencent.com/developer/article/1860632)

# JMX

参考：[集成JMX](https://www.liaoxuefeng.com/wiki/1252599548343744/1282385687609378)

`Java Management Extensions`，用来进行程序监控的。比如内存占用情况，程序中线程的状态

`JMX`定义了监控的接口，通过接口可以获取到程序运行的信息

```asciiarmor
    ┌─────────┐  ┌─────────┐
    │jconsole │  │   Web   │
    └─────────┘  └─────────┘
         │            │
┌────────┼────────────┼────────┐
| JVM    ▼            ▼        │
│   ┌─────────┐  ┌─────────┐   |
| ┌─┤Connector├──┤ Adaptor ├─┐ │
│ │ └─────────┘  └─────────┘ │ |
| │       MBeanServer        │ │
│ │ ┌──────┐┌──────┐┌──────┐ │ |
| └─┤MBean1├┤MBean2├┤MBean3├─┘ │
│   └──────┘└──────┘└──────┘   |
└──────────────────────────────┘
```

`JXM`管理的资源称为`MBean`，所有的`MBean`被`MBeanServer`管理，通过其暴露的接口，可以访问`MBean`

为了在`spring`中使用`JMX`，只需要添加几个注解即可：

* `@EnableMBeanExport`：在配置类或者主启动类配置即可
* `@ManagedResource`：标在类上，指明这是一个`MBean`，属性`objectName`，可以用来指明注册为`MBean`的`name`
* `@ManagedAttribute`：标注在`getter`和`setter`方法上，表示为`JMX`属性
* `@ManagedOperation`：标注在非`getter`和`setter`方法上，表示为`JMX`行为
* `@ManagedParameters`和`@ManagedParameter`：我个人感觉这两个注解就是纯纯的摆烂。都是用来形容`JMX`行为（方法）的参数的，然后就是一个是复数，一个是单数，关键是`@ManagedParameters`里面居然就是一个`@ManagedParameter`数组

使用`jconsole`即可查看到所有的`MBean`

# Protected关键字

其实主要是成员变量的可见性，一共有四种：

* private:仅自己可以访问，一般成员变量使用`private`修饰，然后提供`getter`和`setter`方法
* public:公开的，都可以访问
* 无修饰:一个包内的都可访问
* protected:这个后面细:lock:

简单来说 protected

* 同一个包内和子类可以访问

* 如果子类和父类不在一个包内，那么**子类可以访问从父类继承来的 members** (包括了成员变量和方法，这里的访问方法指的是重写)，但是**子类无法直接访问父类 protected memebers**

  > 典型的例子就是子类中定义了一个父类的成员变量，子类无法直接访问父类`protected`的变量和方法

主要是`clone()`方法是`protected`修饰的，下面也重点说明`clone()`方法，具体的举例子说明：

```java
public class GeneralTest {

	@Test
	public void test() {
		TestProtected obj = new TestProtected();
		obj.clone(); // compile error
	}
}

class TestProtected{}
```

首先我们知道 GeneralTest 和 TestProtected 两个类在同一个包内，但是在`test`方法中，还是无法直接调用`clone()`方法；

如果希望编译不报错，只需要重写方法`clone()`即可

```java
public class GeneralTest {

	@Test
	public void test() {
		TestProtected obj = new TestProtected();
		try {
			obj.clone(); // 编译通过，不过需要捕获异常
		} catch (CloneNotSupportedException e) {
			throw new RuntimeException(e);
		}
	}
}

class TestProtected{
	@Override
	protected Object clone() throws CloneNotSupportedException {
		return super.clone();
	}
}
```

但如果`TestProtected`类和`GeneralTest`类不在同一个包内，调用`clone`方法还是会报错

```java
package com.buzz;

public class GeneralTest {

	@Test
	public void test() {
		TestProtected obj = new TestProtected();
		obj.clone(); // compile error
	}
}
```

```java
package com.buzz.test;

public class TestProtected{
	@Override
	protected Object clone() throws CloneNotSupportedException {
		return super.clone();
	}
}
```

然后说一下子类的访问问题，如果子类和父类不在一个包中：此时子类无法直接调用父类的`protected`方法

```java
package com.buzz.father;

public class Father {
	protected int val;

	public Father(int val) {
		this.val = val;
	}

	protected void modify(int val) {
		this.val = val;
	}
}
```

```java
package com.buzz.son;

class Son extends Father {
	Father father;
	public Son(int val) {
		super(val);
		father = new Father(10);
		System.out.println(this.val); 
        modify(20);
        System.out.println(father.val); // compile error
        father.modify(20); // compile error
	}
}
```

此时有一种特殊的情况：父类中有一个子类的成员变量

```java
package com.buzz.father;

public class Father {
	protected int val;
	Son son;

	public Father(int val) {
		this.val = val;
		son = new Son(10);
		System.out.println(son.val);
		son.modify(20);
	}

	protected void modify(int val) {
		this.val = val;
	}
}
```

```java
package com.buzz.son;

public class Son extends Father {
	public Son(int val) {
		super(val);
	}
}
```

如果子类没有重写`protected`方法，那么父类中是可以调用的`protected`方法的，而子类重写之后，就不能访问了：

```java
package com.buzz.father;

public class Father {
	protected int val;
	Son son;

	public Father(int val) {
		this.val = val;
		son = new Son(10);
		System.out.println(son.val);
		son.modify(20); // compile error
	}

	protected void modify(int val) {
		this.val = val;
	}
}
```

```java
package com.buzz.son;

public class Son extends Father {
	Father father;
	public Son(int val) {
		super(val);
		father = new Father(10);
	}

	@Override
	protected void modify(int val) {
		super.modify(val);
	}
}
```

这种区别主要当子类未重写时，在父类中调用子类对象的`protected`对象，本质上调用的还是父类的对应名称的方法，而一旦子类重写后，只有和子类同一个包，或从子类继承得到的类，才可以调用对应的方法

所以一定要注意，对于`protected`修饰的 member 在父类和子类不在同一个包下的情况，此时子类只能访问继承自父类的`protected`方法，但是无法直接调用父类对象的对应方法

# Top Level Type Declaration

主要参考[Chapter 7. Packages and Modules (oracle.com)](https://docs.oracle.com/javase/specs/jls/se11/html/jls-7.html#jls-7.6)

顶层类型，主要针对类和接口；如果类或接口没有权限修饰符(比如public，private，protected...)，那么`top level type`具有包访问的权限，不过更为一般的形式是使用`public`修饰类和接口

对于top level type 的 declaration 中不可以使用 protected、private、static 修饰

在一个 .java 文件中有且仅有一个 top level class 的修饰符为 public，并且这个 class 的类名和文件名相同

# HTTPS 保证安全的登录

说简单了，就是加密了，然后就安全了，问题是怎么加密，为什么这么加密就安全了

## Symmetric-Key Encryption

考虑使用对称加密, 即使用相同的密钥进行加密/解密, 那么在 client (browser) 开始向 server 请求数据之前, 首先需要明确双方使用的密钥

实际中密钥可能是由通信的双方协作生成的, 一种可能的形式如下:

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/https_%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86.png)

在正是的通信建立之前, 通过明文的形式交换双方的 random key, 组合得到最终的密钥, 由于密钥是完全暴露的, 因此纯 symmetric-key encryption 不能保证安全

## Asymmetric-key Encryption

考虑使用非对称加密, 即使用不同的密钥进行加密/解密; 一般而言将一对密钥分为公钥和私钥, 公钥顾名思义是公开的, 使用公钥加密加密的消息, 只能使用私钥解密, 这样只要 client 使用公钥加密数据, 服务器使用私钥解密, 即可保证 client -> server 单向链路的数据安全性, 一种可能的形式如下:

<img id="Https_Asymmetric_encryption" src="https://cdn.jsdelivr.net/gh/SunYuanI/img/img/https_%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86.png"/>

>   这里没有提到的是, 使用私钥加密的数据, 可以通过公钥解密; 但因为公钥是公开的, 因此一般而言不使用私钥加密数据; 更多的时候私钥加密可以用作数字签名 

上面的方式存在两个问题:

*   只有使用私钥解密的链路才能保证数据的安全性, 因此上面的链路只有 client -> server 是安全的, 而 server -> client 其实和明文差不多

    >   在建立连接的阶段, 可以让 client 将公钥发送给 server, 后续 server 相应的数据均通过 client 提供的公钥加密, 从而保证 client <-> server 双向链路的安全性
    >
    >   不过这种交换公钥的方式仍然会受到中间人攻击, 具体的可以看[后面](#可恶的中间人攻击)

*   非对称加密存在性能问题, 因为使用了不同的密钥进行加密/解密, 从算法的复杂度上考虑, 非对称加密本身的时间复杂度就更高

## hybrid encryption

将两种加密算法结合利用, 兼顾性能和安全:

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/https_%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E5%92%8C%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86.png)

相比 symmetric-key encryption, 密钥的一部分使用了公钥加密, 只有 server 才能通过私钥获取 pre master; 相比 asymmetric-key encryption, 在建立连接阶段, server 需要额外返回一个 sever-random

看起来已经十分完美了

## 可恶的中间人攻击

可能直觉上, 使用非对称加密可以实现单向的数据安全性, 然而现实可能没那么安全 ...

如果中间人在第一次客户端发送请求获取服务器公钥的时候, 就已经介入了, 即中间人伪装成服务器和客户端进行通信, 而为了让通信可以正常进行下去, 中间人也和服务器之间建立了连接, 一种可能的形式如下：

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/mid_attack.drawio.svg)

这里面最关键的点在于中间人在客户端请求得到服务器的公钥的时候就已经接入了, client 获得的是来自中间人的公钥, 从而导致 client 使用 mid pubKey 加密的 pre_master, 在 mid 端可以直接通过 mid priKey 解析

因此现在 mid 知道了加密方式 (server 提供), client_random, server_random, pre_master (mid priKey), 自然可以得知最终使用的加密方式

## CA

上面的中间人攻击, 最大的点在于客户端无法区分中间人和服务器, 获取公钥的请求发过去, 得到了一个公钥, 并不能知道这到底是服务器的公钥还是中间人的公钥

目前解决这个问题的方式是提高来自 serve 端公钥的可信度, 这就需要提到 CA 了; CA 负责对 server 的身份进行验证, 认证通过的 server 会得到一个数字证书, client 仅选择和被认证的 server 通信

生成数字证书的方式很简单: CA 根据 server 提供的公钥和域名等网站信息, 使用 Hash 算法, 得到 Message Digest(信息摘要)

>   常见的 Hash 算法: MD5, SHA-1, SHA-256

随后 CA 会对得到的 Message Digest 使用 CA 的私钥进行加密，得到一份数字签名

>   前面也说过了, 一般而言使用私钥加密数据不能保证数据的安全性, 更多的是作为数字签名以表明身份

最后将数字签名和服务器发送的公钥和一些其他消息组合一起就构成了数字证书

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/digital_message.drawio.svg)

此后 client 请求 server 时, server 会返回数字证书 (不是再是公钥), 一种可能的形式如下:

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/https_digital_certificate.drawio.svg)

client 获取到数字证书后, 进行验证, 只有验证通过的数字证书才能表明其包含的公钥是来自相应的 server 的

>   根据数字证书的生成流程可知, 数字证书本身是包含了 server 公钥的, 理论上不需要验证, client 即可利用公钥完成到 server 的通信; 验证更多的是为了表明数字证书的合法性

所谓验证数字证书主要也就是验证数字签名, CA 通过私钥签上的数字签名, 在 client 端可以通过 CA 权威的公钥进行解密

>   CA 是具有权威性的, 其公开的公钥一定不是来自中间人的; 一般而言 CA 公钥已经嵌入 OS 内部了, 不再需要额外获取

client 解密数字签名得到的结果是是一个 Message Digest, client 使用和 CA 同样的 hash 算法对数字证书内的其他消息进行 hash 运算也生成一个 Message Digest; 只有这两个 Message Digest 完全一致, 才表示验证通过

有了数字证书, 如果中间人还想要伪造服务器的话, 不仅需要修改数字证书中公钥, 还需要修改数字证书中的数字签名, 而由于中间人缺少 CA 的私钥, 是没有办法重新签名的

借助 CA 的数字验证 + 非对称加密 + 对称加密, 可以实现高效的, 可靠的 HTTP 通信

# 鉴权

这部分基本上都是从网上东拼西凑出来的

## 为什么需要鉴权

HTTP 协议是无状态的，每一个从客户端到服务器的请求，都是相互独立的，但有的时候需要服务器保存客户端的状态；最常见的就是登录状态

最开始比较常用的就是 cookie 和 session 技术，后面开始使用 token 的方式鉴权，这里面比较权威的是 JWT

## cookie

"客户端会话技术"：将数据保存到客户端

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/Cookie%E4%B8%BE%E4%BE%8B.png)

在第一次请求后，服务器在响应中添加 set-cookie 字段，并填入对应的 cookie(一个键值对)，这样下一次浏览器(客户端)请求的时候，会在请求头的 cookie 字段中添加刚刚服务器返回的键值对，第二次请求到达服务器后，服务器可以根据 cookie 信息确定请求的对象信息

*   cookie 信息是保存在浏览器(客户端)中的
*   cookie 的大小有限制(最大 4K)
*   cookie 和域名相关(一个域名下的请求才带上)

## session

学 java web 的时候，基本上都是使用 session 的

"服务器端会话技术"：将会话信息保存在服务器上

我个人理解的话，session 是对 cookie 的一个封装，因为 session 底层本质上还是 cookie

客户端第一次发送请求，因为没有 cookie，所以服务器接收到请求后，会在内存中新建一个 session 对象(多个 session 对象之间通过 session-id 区分)，然后在相应中添加 set-cookie 字段，并填入键值对(JSESSIONID=[刚才生成的 session 的session-id])

当 cookie 过期的时候，会话就结束了

session 存在分布式的问题，一般而言，不可能一个 tomcat 就可以承载所有的流量，所以一般都是使用 nginx 做反向代理，负载均衡；其结构可能为：

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/nginx_reverse_proxy.drawio.svg)

可以看到一个反向代理服务器后面可能接了 3 个服务器，考虑连续的两个请求

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/nginx_reverse_proxy_dispatch_request.drawio.svg)

因为反向代理服务器并不保证每次都将请求分发到同一个服务器上，所以可能出现上图的情况

第一次请求时，server A 赋予客户端一个 session-id，第二次请求时 客户端的 cookie 中具有对应 JSESSIONID，然而在 server b 中，并没有对应 session-id 的对象，所以请求是非法的

这个问题就是分布式带来的，解决这个问题的其中之一的方法是将 session-id 进行持久化，保存到分布式数据库中，让分布式数据库替我们决定如何更新，维护这些数据(成本转移了属于是)

## CSRF 攻击

每当提到这个名词，就得献上这个图了

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/CSRF.jpg)

还是那个经典的例子：银行转账

发起转账不过是发起一个请求，比如请求地址为：xxxxbank.com/withdraw?amount=1000&to=bob，表示给 bob 发起一笔转账

正常逻辑是，A 登录后 session 中含有 A 的信息，所以 A 发送这个请求，就是 A 给 bob 转账；A 如果没登录，这个请求就是无效的

考虑用户在 A 中登录通过后，没有马上关闭，新开了一个 tab，然后"不小心"打开了网站 B，在 B 中存在一个链接\<img src="xxxxbank.com/withdraw?amount=1000&to=bob">，A 的浏览器想着从这个链接处获取一个图片，于是发送了这个请求，注意到因为 A 没有关闭页面，session 信息得到了保存，因为是到 xxxxbank.com 的请求，于是携带了 cookie 信息(JSESSIONID)，从而莫名其妙的完成了一次转账

## token

并不说 token 就是 JWT，JWT 是一种实现而已

其实和 cookie 的流程是类似的，客户端建立请求，服务端响应，并返回 token 信息，当客户端再一次请求时，将携带 token 信息请求

这玩意我感觉和 cookie 差不多，不过需要在发送请求时手动在请求头(或请求体)中添加 token 信息，token 中保存了用户身份和权限信息，这样服务器解析携带的 token 信息，就知道是哪个用户，具有哪些权限，是否可以访问对应的资源

显然 token 信息和 cookie 信息都需要保存在客户端中，在 vue 中使用全局的 store 保存 token，但页面刷新后就没了，显然，这是有问题的

### 如何保存 token

*   localStorage：将 token 持久化，保存在浏览器内部；这样做存在风险，因为 localStorage 对所有 js 脚本都是可读的，可能受到 XSS 攻击

    >   简单来说 XSS 就是 向 Web 页面里插入恶意 Script 代码，当用户浏览该页面时，嵌入 Web 里面的 Script 代码会被执行，从而达到恶意攻击用户的目的
    >
    >   显然，此时 localStorage 就是可读的

*   cookie(httpOnly)：被设置为 httpOnly 的 cookie，js 代码是无法访问的，只能通过服务器修改，删除；要注意此时，cookie 只能被 server 设置，此时前端(vue)是读取不到 cookie，显然此时设置 token 其实就相当于设置了一个简单的 cookie

    此时最大的问题其实在于 cookie 本身大小最大为 4K，有的时候 token 中需要保存大量的用户个人信息，可能爆

    此外 CSRF 问题也还存在

*   store 保存，这个保存方法安全，最大的问题前面已经说过了，刷新后，就需要重新登录了

*   "神奇的网友"：这个其实是网上看到的，借鉴了OAuth2.0，access token + refresh token 双 token 的机制

    ![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/%E5%8F%8C%20token.webp)

    简单来说，就是返回两个 token(废话)，其中 refresh token 保存在 cookie 中，并设置为 httpOnly(可能出现 CSRF 问题)，但实际校验的 access token 保存在 store 中

    显然，就算刷新页面，只要 cookie 不过期，就可以获取到 access token

    考虑 CSRF 中的场景，就算被恶意访问了其他网站，就算有 cookie，但 refresh token 并不是用来鉴权的，而请求头中的 Authorization 为空，所以鉴权失败


 # 跨域问题

产生这个问题根本原因就是因为浏览器，如果是一个 node 应用，直接 xhr 请求后端端口，其实是可以返回正确结果的

>   使用 axios 发送异步请求，本质上，都是通过 js 提供的 XMLHttpRequest 发送请求

所以其实并不是说跨域后数据请求不到，而是浏览器接受到跨域请求的响应后，如果没有额外的跨域配置的话，是不会解析数据的

参考了：[跨源资源共享（CORS)](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/CORS)、[springboot CORS](https://docs.spring.io/spring-boot/docs/current/reference/html/web.html#web.servlet.spring-mvc.cors)、[spring mvc CORS](https://docs.spring.io/spring-framework/docs/5.3.22/reference/html/web.html#mvc-cors-global)

>   这里通过在后端，修改响应头部的方式，实现 CORS

## 一些基本的逻辑

跨域请求其实可以分为两类：简单请求和预检请求

简单请求就是直接发，没什么好说的；而预检请求在发送实际的业务报文之前，需要使用 HTTP 的 OPTION 方法，发送一个"预报文"

这些都不重要，因为前端编码的时候请求直接打过去就行了，如果需要发送预请求的话，浏览器会自动加上的；而浏览器只有在不满足简单请求的条件下，才会考虑发送预检请求，具体的条件可以看[简单请求](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/CORS#简单请求)

简单说，一般的如果，只是通过 post 发送请求，其中 request body 中是被 axios 封装好的 json 格式的数据，这种情况下，一个简单请求就可以了，一种可能的 request header 为：

```http
POST /backManagement/login HTTP/1.1
Accept: application/json, text/plain, */*
Accept-Encoding: gzip, deflate, br
Accept-Language: zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6
Connection: keep-alive
Content-Length: 0
Host: localhost:8081
Origin: http://127.0.0.1:5173
Referer: http://127.0.0.1:5173/
Sec-Fetch-Dest: empty
Sec-Fetch-Mode: cors
Sec-Fetch-Site: cross-site
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36 Edg/105.0.1343.33
sec-ch-ua: "Microsoft Edge";v="105", " Not;A Brand";v="99", "Chromium";v="105"
sec-ch-ua-mobile: ?0
sec-ch-ua-platform: "Windows"
```

这个 header 和普通的 header 中最大的区别在于添加了 Origin 字段，向服务器表明当前发送请求所在的域

而如果考虑在 header 中的 Authorization 字段中添加 token，就需要发送预检请求，首先问一下服务器是否允许 header 中存在 Authorization 字段，只有允许的时候，才会发送数据，一种可能的情况为：

```http
OPTIONS /backManagement/login HTTP/1.1
Accept: */*
Accept-Encoding: gzip, deflate, br
Accept-Language: zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6
Access-Control-Request-Headers: authorization,content-type
Access-Control-Request-Method: POST
Connection: keep-alive
Host: localhost:8081
Origin: http://127.0.0.1:5173
Referer: http://127.0.0.1:5173/
Sec-Fetch-Dest: empty
Sec-Fetch-Mode: cors
Sec-Fetch-Site: cross-site
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36 Edg/105.0.1343.33
```

首先发送一个预请求，其中的 Access-Control-Request-Headers 中包含了正式请求中 header 中可能包含的额外字段；Access-Control-Request-Method 包含了正式请求的方法类型

```http
POST /backManagement/login HTTP/1.1
Accept: application/json, text/plain, */*
Accept-Encoding: gzip, deflate, br
Accept-Language: zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6
Authorization: 
Connection: keep-alive
Content-Length: 37
Content-Type: application/json
Host: localhost:8081
Origin: http://127.0.0.1:5173
Referer: http://127.0.0.1:5173/
Sec-Fetch-Dest: empty
Sec-Fetch-Mode: cors
Sec-Fetch-Site: cross-site
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36 Edg/105.0.1343.33
sec-ch-ua: "Microsoft Edge";v="105", " Not;A Brand";v="99", "Chromium";v="105"
sec-ch-ua-mobile: ?0
sec-ch-ua-platform: "Windows"
```

然后再发送一个正常的请求

其实关于跨域请求的客户端实在是没什么要说的，因为跨域不过就是多添加了一些字段(Origin 是必须要有的，剩下的两个 Access-Control-Request-Headers 和 Access-Control-Request-Method 不一定有)，再就是可能发送正式请求之前需要发送一个预请求

不过这些对于前端的编码而言，都是透明的，对于前端而言，就是 axios 的请求地址变了，剩下的都不需要管

但对于后端就不一样了，如果后端不进行额外的配置的话，那么浏览器是不会解析后端返回的数据的，所以后端需要在原始响应头的基础上进行额外的配置，告诉浏览器，是否可以解析响应

首先考虑一个跨域的响应头中可能包含的字段：

*   [Access-Control-Allow-Origin](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/CORS#access-control-allow-origin)：这个字段用来表示服务器允许的跨域请求的源，这个字段对应了跨域请求头中的 Origin，如果 Origin 不在这个范围内，那么浏览器就不会解析响应数据

    >   注意服务器可以通过配置通配符 * 表示允许来自所有域的请求，如果服务器端配置并不是 *，那么跨域响应头中应该还包含了字段 Vary(具体的为 Vary: Origin)，表示服务器针对不同的请求(不同的域)返回不同的结果

*   [Access-Control-Expose-Headers](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/CORS#access-control-expose-headers)：默认的情况下，js 不能读取到完整的响应头(至少 XMLHttpRequest 的 getResponseHeader() 方法不行)，这个方法用来让 js 可以读取到一些额外的响应头，比如之前用来保存 token 的 Authorization

    >   考虑一个登录的例程，登录后服务区返回 token 信息，这个信息可以包含在响应的 data 中，也可以直接放在响应的 header 的 Authorization 字段中，如果选择后者，那么显然，就需要额外的配置 header 中的 Access-Control-Expose-Headers，因为只有这样 js 才可以正常读取到返回的 header 中的 token

*   [Access-Control-Max-Age](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/CORS#access-control-max-age)：这个字段用来表示预检请求的有效时长，注意到并不是每个"不简单的" http 请求都需要携带一个预检请求，比如跨域请求中，请求的是后台的数据，那么正常是需要鉴权的，如果将 token 信息放在了 header 中的 Authorization 字段中了，总不能每个后台请求之前都需要额外添加一个预检请求，让服务器告诉客户端能不能在 header 中携带 Authorization 字段吧；

    这个字段的作用相当于给预检请求设置一个有效期，类似于 cookie 的有效期，在这个有效期内，发送 "不简单的" http 跨域请求时，就不用再发送预检请求了，直接发送就好

    默认的这个字段的单位是秒

*   [Access-Control-Allow-Credentials](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/CORS#access-control-allow-credentials)：这个字段用来确认跨域相应中是否携带 cookie 信息，如果这个值被设置为 true，那么如果服务器需要 setCookie，那么响应报文中就包含了 cookie 的信息

    注意设置这个字段，只能让服务器返回 cookie 信息，并不会让浏览器保存接收到的 cookie 信息，如果希望浏览器保存 cookie 信息，那么前端在使用 XMLHttpRequest 对象发送 ajax 请求的时候就应该设置上 withCredentials(注意设置上了之后请求头不会发生什么变化)

    >   因为一般不会直接操作 XMLHttpRequest 对象，不过封装好的 axios 中也保留了这个设置

    **==这里要注意了==**，如果有跨域 cookie 的需求，那么需要按照设置：

    *   前端：不管是使用 XMLHttpRequest 对象，还是封装之后的 axios，都需要设置 withCredentials 为 true

    *   后端：

        *   设置响应头中 Access-Control-Allow-Credentials 为 true
        *   不能设置 Access-Control-Allow-Origin 为 *，需要指定为特定的值
        *   不能设置 Access-Control-Allow-Headers 为 *，需要指定为特定的值
        *   不能这是 Access-Control-Allow-Methods 为 *，需要指定特定的值

        >   默认的 spring boot 中针对上面的三个默认值都是 *，所以如果后端架构是 spring boot 的，还有跨域设置 cookie 需求的，一定要设置好这三个 header

*   [Access-Control-Allow-Methods](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/CORS#access-control-allow-methods)：这个是一个特殊的字段，仅存在于预检请求的响应中，因为预检请求中包含了 Access-Control-Request-Method 字段，这两个字段是对应的，一个是浏览器向服务器表示后面需要发送的请求的类型，一个服务器向浏览器表示其允许接受请求的类型

*   [Access-Control-Allow-Headers](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/CORS#access-control-allow-headers)：和上面的类似，也仅仅存在于预检请求的响应中，对应了 Access-Control-Request-Headers，表示了服务器可以接受的特殊的 header 信息，注意如果服务器自定义该字段时，需要包含上 Content-Type 类型

## 解决跨域问题

前面也提到了，我这里是通过修改服务端的 header 解决的跨域问题，特别的，后端的架构是基于 spring boot 的

因为是在响应的 header 中添加额外的字段，可以通过配置过滤器，在返回响应之前修改响应头，不过 spring boot 一个最大的特点就是自动装配，写好配置和注解，spring 会把这些配置在启动容器的时候装配起来，自然的，对于跨域请求也存在自动装配类，所以这里考虑的是使用全局的配置类解决跨域问题

首先 spring boot 在整合 spring mvc 默认的就已经进行了配置，如果仅仅是修改其中一部分默认配置，[官方的建议](https://docs.spring.io/spring-boot/docs/current/reference/html/web.html#web.servlet.spring-mvc.auto-configuration)如下：

If you want to keep those Spring Boot MVC customizations and make more [MVC customizations](https://docs.spring.io/spring-framework/docs/5.3.22/reference/html/web.html#mvc) (interceptors, formatters, view controllers, and other features), you can add your own `@Configuration` class of type `WebMvcConfigurer` but **without** `@EnableWebMvc`.

就是说可以定义一个类实现接口 WebMvcConfigurer，并添加注解 @Configuration(用来让 spring 装配 bean) 然后实现其中的方法即可

>   要注意的是这个接口中的方法都具有默认实现，所以在 implements 的后，不会爆红(好评)

因为要解决的是跨域资源共享的问题(CORS 问题)，所以这里实现的方法是 addCorsMappings

```java
package icu.buzzx.blogspring.config;

import org.springframework.context.annotation.Configuration;
import org.springframework.web.servlet.config.annotation.CorsRegistry;
import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;

/**
 * @author buzz
 * @date 2022/9/12 23:21
 * @description 定义了一个类，实现了接口 WebMvcConfigurer，然后添加注解，并实现 CORS 相关的方法
 */
@Configuration
public class WebMvcConfig implements WebMvcConfigurer {
	/**
	 * 重写 addCorsMappings 方法，用来处理跨域请求
	*/
	@Override
	public void addCorsMappings(CorsRegistry registry) {
		WebMvcConfigurer.super.addCorsMappings(registry);
        // addMapping 用来表示跨域的请求处理的 URI 的范围，这里默认所有都处理
		registry.addMapping("/**")
				// 保证在跨域时 set cookie 字段可以正常被加在响应的 header 中
				.allowCredentials(true)
				// 仅允许 post 方式请求
				.allowedMethods("POST")
				// 添加允许跨域的源
				.allowedOrigins("http://127.0.0.1:5173")
				// 添加允许的 header，注意不要落下 content-type
				.allowedHeaders("Authorization", "Content-Type")
				// 预检请求的保存时间最长为 60s，因为是测试，所以小点，实际场景中可以设置的长一点，比如一周
				.maxAge(60);
	}
}
```

注意如果登录案例中使用响应头中的 Authorization 字段返回 token 信息，还需要额外配置 exposeHeader

总所都周知，spring 很喜欢使用注解，所以如果是平时测试用的话，完全写这个自动装配类，直接在 controller 上添加一个注解 [@CrossOrigin](https://docs.spring.io/spring-framework/docs/5.3.22/javadoc-api/org/springframework/web/bind/annotation/CrossOrigin.html)，即可

不过要注意，如果通过这种方式实现的跨域资源共享，那么所有的设置都是默认值，这样至少 cookie 信息是不会在响应头中出现

>   关于 spring 对于跨域的默认配置保存在了 CorsConfiguration 类下的 applyPermitDefaultValues 中，还可以看到默认的 spring 配置的 max-age 是半个小时

尽管我这里通过修改响应头的方式解决了跨域问题，对于前端是透明的，但因为实际场景中还涉及了跨域 cookie 的问题，所以前端，还是需要改动一些代码的，具体的，如果是使用 axios 进行异步请求，那么就需要配置：

```typescript
// 设置 axios 跨域请求时携带 cookie 信息，同时也保证了跨域响应中的 cookie 信息会被保存
axios.defaults.withCredentials = true
```

## 还没完

本来我以为把上面的这些设置好之后，就可以实现跨域请求，并且可以携带 cookie

然而随后，一个请求打过去，set 上 cookie，之后 chrome 就报了一个 warning，他说没有设置 cookie 的 SameSite 属性

大佬博客中解释了一下 cookie 中的 same site 字段：[Cookie 的 SameSite 属性](http://www.ruanyifeng.com/blog/2019/09/cookie-samesite.html)

因为有的时候发起 post 请求也需要携带 cookie，所以这个字段只能设置为 none

然而在传统的 servlet API 的 Cookie 中，并没有提供设置 SameSite 的方法，所以这里选择直接设置 header 中的 Set-Cookie 字段

毕竟 cookie 在 response 中就是通过 header 字段中的 Set-Cookie 实现的，那么直接写就行了，如果直接通过 String 类型拼接写好 header 实在是有点太傻逼了，所以这里使用 Sping 提供的 [ResponseCookie](https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/http/ResponseCookie.html) 帮助构建一个 cookie

从 API 的调用其实很简单，看看上面的 java doc 就知道了

```java
// 注意 cookie 的 name 中不能包含空格
ResponseCookie refreshToken = ResponseCookie.from("refresh_token", user.getUuid())
    // 设置 cookie 为 js 不可读
    .httpOnly(true)
    // 设置 cookie 有效期为 1 周，调试的时候就给 20s 的有效期
    .maxAge(20)
    // 保证在跨域的情况下也可以存储 cookie
    .sameSite("none")
    .build();
```

最后还是需要调用 response 的 setHeader 才能设置上 cookie，举个例子：

```java
@PostMapping("/test")
public void test(HttpServletResponse response) {
    // 注意 cookie 的 name 中不能包含空格
    ResponseCookie refreshToken = ResponseCookie.from("test_cookie", "这里是 cookie 的具体内容")
        // 设置 cookie 为 js 不可读
        .httpOnly(true)
        // 设置 cookie 有效期为 1 周
        .maxAge(7 * 24 * 60 * 60)
        // 保证在跨域的情况下也可以存储 cookie
        .sameSite("none")
        .build();
    response.setHeader(HttpHeaders.SET_COOKIE, refreshToken.toString());
}
```

## 还还没完

本以为这样就行了，然后 chrome 又给我整了个活，他说设置了 sameSite 为 none 的时候必须设置 cookie 为 secure 的，即 cookie 必须通过 https 传输

![](https://cdn.jsdelivr.net/gh/SunYuanI/img@latest/img/22_9_19_%E4%BB%8A%E6%97%A5%E9%A6%96%E7%BB%B7.png)

我真服了，可以访问硬盘，就可以访问 cookie ？？？真没必要这么安全吧

所以现在处理跨域，设置 cookie，并保证可以使用 chrome 正常访问，就需要写成：

```java
@PostMapping("/test")
public void test(HttpServletResponse response) {
    // 注意 cookie 的 name 中不能包含空格
    ResponseCookie refreshToken = ResponseCookie.from("test_cookie", "这里是 cookie 的具体内容")
        // 设置 cookie 为 js 不可读
        .httpOnly(true)
        // 设置 cookie 有效期为 1 周
        .maxAge(7 * 24 * 60 * 60)
        // 保证在跨域的情况下也可以存储 cookie
        .sameSite("none")
        // 设置 cookie 仅允许在 https 下传输
        .secure(true)
        .build();
    response.setHeader(HttpHeaders.SET_COOKIE, refreshToken.toString());
}
```

然后还需要设置 https 访问，具体的看[在 Https 环境下调试](#在 Https 环境下调试)

# JWT

这玩意好啊，也是无状态的，现在服务器再也不需要维护 session 了，全靠 jwt 鉴权就行了

它还有一个官网：[JSON Web Tokens - jwt.io](https://jwt.io/)，因为我肯定不是平白无故使用 jwt，后端是 java 的，那么我就看 java 的库就好了

在所有的库中，选择一个支持加密算法最多的，且**使用人数最多的**，这里选择了 [jwtk/jjwt: Java JWT: JSON Web Token for Java and Android](https://github.com/jwtk/jjwt)

>   看看吧，这个 8.6k star 的项目只有几十个还处于 opened 的 issue
>
>   我丝毫没有说 fastjson 垃圾的意思

github 的 readme 已经很详细了，这里就当一次搬运工

因为使用 maven 构建项目，所以需要先在 pom.xml 中引入依赖

```xml
<dependency>
    <groupId>io.jsonwebtoken</groupId>
    <artifactId>jjwt-api</artifactId>
    <version>0.11.5</version>
</dependency>
<dependency>
    <groupId>io.jsonwebtoken</groupId>
    <artifactId>jjwt-impl</artifactId>
    <version>0.11.5</version>
    <scope>runtime</scope>
</dependency>
<dependency>
    <groupId>io.jsonwebtoken</groupId>
    <artifactId>jjwt-jackson</artifactId> <!-- or jjwt-gson if Gson is preferred -->
    <version>0.11.5</version>
    <scope>runtime</scope>
</dependency>
```

## quick start

jwt 本质上就是一个 json，经过了编码后得到了一个字符串，注意这里使用编码形容，而不是加密，这意味着默认的 jwt 就是明文 json 的编码

而正经使用 jwt 时，都是利用这个 token 进行鉴权，包含了用户的身份，权限信息，显然，明文是很不合适的，实际中如果需要存储用户信息，最好还是加密吧

```java
public void test() {
    Key key = Keys.secretKeyFor(SignatureAlgorithm.HS256);
    String jws = Jwts.builder().setSubject("buzz").signWith(key).compact();
    System.out.println(jws);
}
```

jjwt 另一个比较友好的地方是，它支持流式编程，写在一行就行了

注意到，这里的 test 就是初始化一个 jwt，首先获取一个密钥，然后初始化一个 jwt，并在 payload 字段中添加 [sub claim](https://www.rfc-editor.org/rfc/rfc7519#section-4.1.2) (这是 jwt 官方定义的字段)，随后使用刚才的密钥进行签名，并压缩，最后得到一个字符串，官方称最后得到的字符串是一个 jws(json web signature)

>   注意到这里的签名仅仅是针对 jwt 的 header 和 payload 的一个签名，并不是加密，他的作用是防止 jws 被篡改，而不能保证 jws 是一个密文

获取 jws 中的数据，也是很简单的

```java
public void test() {
    Key key = Keys.secretKeyFor(SignatureAlgorithm.HS256);
    String jws = Jwts.builder().setSubject("buzz").signWith(key).compact();
    String sub = Jwts.parserBuilder().setSigningKey(key).build().parseClaimsJws(jws).getBody().getSubject()
    System.out.println(sub); // buzz
}
```

## 签名算法

jjwt 提供了多种签名算法，具体的参考官方[Signature Algorithms Keys](https://github.com/jwtk/jjwt#signature-algorithms-keys)

比如常见的 HMAC-SHA、RSA，权衡性能和安全性，个人感觉使用 HMAC-SHA 系的算法就够了(尽量简单一点，毕竟自己的应用安全什么的不是很重要，能用一个密钥就不使用公钥私钥对)

不同的加密算法，密钥的最短长度不同，具体的参考官方给出的建议值(建议值比最低值要大一点)

如果不希望自己生成密钥，官方提供了 API，用来生成密钥

```java
// 生成一个 HMAC-SHA 系列的密钥，这里的长度为 256 位，此外还有可选的 384 位和 512 位
SecretKey key = Keys.secretKeyFor(SignatureAlgorithm.HS256); //or HS384 or HS512
// 如果希望持久化存储密钥的话，可以选择将密钥以 base64 编码的形式存储(使用 ascii 编码也是可以的，随便)
String secretString = Base64.getEncoder().encodeToString(key.getEncoded());
// 生成非对称加密的密钥
KeyPair keyPair = Keys.keyPairFor(SignatureAlgorithm.RS256); //or RS384, RS512, PS256, PS384, PS512, ES256, ES384, ES512
// 分别通过 getPrivate() 和 getPublic() 获取公钥和私钥
```

其实从这些 API 也能看出来，和之前的 [HMAC](#HMAC) 和 [RSA](#非对称加密)，中的 API 差不多

因为上面使用 Base64 格式对密钥进行了编码，用于持久化，后面从配置文件中读取密钥时就是一个反过程，此外因为实际加密和解密的时候使用的对象不是密钥的字节数组，而是 SecretKey 对象，所以还需要将其恢复

这里最好还是使用官方提供的 API 进行操作

```java
// 将被 Base64 编码的密钥字符串恢复为 SecretKey 对象 
SecretKey key = Keys.hmacShaKeyFor(BASE64.getDecoder().decode(secretString));
```

 ## 创建一个 jws

其实上面的 [quick start](#quick start) 中已经创建过一个 jws 了，关键点在于调用方法 Jwts.builder() 构造一个 JwtBuiler 对象，对这个对象填充数据，并签名压缩得到的就是一个 jws

### 设置 header

这部分不重要，因为一般不需要修改 header

官方提供了一个例子：

```java
String jws = Jwts.builder()

    .setHeaderParam("kid", "myKeyId")
    
    // ... etc ...
```

>   这个 [kid](https://www.rfc-editor.org/rfc/rfc7515#section-4.1.4) 不是必须的字段

可以通过 setHeader(Map<String, Object> map) 方法一次设置好所有的 header，官方说了，这种方式将覆盖掉所有之前的 header，不过不用担心，jjwt 还是保证了 alg 等必要的字段会在最后由 jjwt 自动帮我们加上

>   也就是说就算手动重写了 alg 字段，jjwt 也会在最后改回成正确的加密算法

### 设置 payload

终于到了关键地方

首先是一些标准声明：

```java
String jws = Jwts.builder()

    .setIssuer("me")
    .setSubject("Bob")
    .setAudience("you")
    .setExpiration(expiration) //a java.util.Date
    .setNotBefore(notBefore) //a java.util.Date 
    .setIssuedAt(new Date()) // for example, now
    .setId(UUID.randomUUID()) //just an example id
    
    /// ... etc ...
```

这里我不是很喜欢它设置时间居然还是使用 java.util.Date 类型，明明这个类型存在一定安全性问题，居然还用这个 API，所以实际设计过期时间的时候，还是在自定义的部分中添加时间吧

对于自定义的字段，可以通过 claim() 设置

```java
String jws = Jwts.builder()

    .claim("hello", "world")
    
    // ... etc ...
```

当然类似于一次性设置好 header，这里也可以一次性设置好自定义的字段

```java
Map<String,Object> claims = getMyClaimsMap(); //implement me

String jws = Jwts.builder()

    .setClaims(claims)
    
    // ... etc ...
```

### 签名

这个写法很固定，毕竟 key 都已经设置好了，直接签名完压缩就行了

```java
String jws = Jwts.builder()

   // ... etc ...
   
   .signWith(key) // <---
   
   .compact();
```

>   如果是使用公钥和私钥对的，注意这里只能使用私钥进行加密，公钥是用来解密的

## 读取 jws

类似于创建 jws 的逆过程，因为之前是先设置 header 和 payload 再签名的，所以这里需要先通过密钥解密(验证)，然后再读取主体部分

```java
Jws<Claims> jws;

try {
    jws = Jwts.parserBuilder()  // (1)
    .setSigningKey(key)         // (2)
    .build()                    // (3)
    .parseClaimsJws(jwsString); // (4)
    
    // we can safely trust the JWT
     
catch (JwtException ex) {       // (5)
    
    // we *cannot* use the JWT as intended by its creator
}
```

首先 Jwts.parseBuilder() 用来获取一个 JwtParseBuilder(其实就是创造者模式)，通过 builder.build() 方法即可获取到 JwtParser，通过解析器可以解析 JWT 中的数据

因为 JWT 是经过数字签名的，所以在获取解析器之前，需要先进行数字签名的认证，注意这里如果数字签名认证没有通过，会抛出异常 JwtException

>   如果是使用公钥私钥对，那么这里应该使用公钥进行认证
>
>   官方上更绝，他还解释了一种使用多种密钥混合使用的情景，更加安全，这里不做过多说明，具体的可以看 github 的[说明页面](https://github.com/jwtk/jjwt#signing-key-resolver)

# 注解处理器

这是一个很厉害的东西，lombok 的自动生成代码靠的就是这玩意

从名字上看就是知道这玩意是针对注解的，在**编译期间**，那些可以被注解处理器处理的注解，可以变成代码，这也就是为什么在 lombok 中一个简单的 @Data，最后编译结束后可以得到各种 getter、setter...

网上有一个很好的教程：[Annotation Processing](http://hannesdorfmann.com/annotation-processing/annotationprocessing101/)

# 在 Https 环境下调试

因为是调试的时候使用，并必须要一个合法的 SSL 证书，所以这里使用了 keytool 生成一个"假"证书

```shell
keytool -genkey -alias test  -storetype PKCS12 -keyalg RSA -keysize 2048  -keystore test.p12 -validity 3650
```

可以看到这个命令参数贼多，不过其实都挺好理解的：

*   -genkey 表示使用 keytool 生成一个带有数字签名的数字证书
*   -alias 表示了证书的别名，设置别名是因为在 spring boot 作为后端的环境下需要配置这个选项，其他的环境不确定
*   -storetype 表示了[密钥仓库类型]，这几个字是上网上抄的，我也不知道这是什么意思
*   -keyalg 设置加密算法，常见的非对称加密算法，也就 RSA 了吧
*   -keysize 表示密钥长度，对于 RSA 2048 位的密钥就是典型长度了
*   -keystore 表示保存的密钥的名字(当然也可以写一个十分复杂的路径)
*   -validity 表示证书的有效期(给了 10 年不会太多了吗...)

随后需要设置[密钥库]的密码，这个密码在配置 spring boot 的时候也需要用到

然后就是一堆乱七八糟的配置了，随便写写就行了

使用 IDEA 在 Https 环境下配置的时候需要把 .p12 证书保存在 /resource 目录下

然后就是在 application.yaml 中进行配置了

```yaml
server:
  ssl:
    key-alias: test # 这里是刚才设置的别名
    key-store: classpath:test.p12 # 这里是存放证书的位置，如果直接放在了 /resource 下就这么写
    key-store-password: 123456 # 刚才设置的密钥库密码
    key-store-type: PKCS12 # [密钥仓库类型]
```

建议是把 serve.port 也设置上，不然也不知道它在那个端口上启动

