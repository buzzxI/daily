# 线程的生命周期

主要参考：[Java Thread Life Cycle and Thread States - HowToDoInJava](https://howtodoinjava.com/Java/multi-threading/Java-thread-life-cycle-and-thread-states/)

![life cycle](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/Java-Thraed-Life-Cycle-States.jpg)

线程的状态只有图中的这6个：`New`、`Runnable`、`Waiting`、`Timed Waiting`、`Blocked`、`Terminated`

> 主流的jvm将java线程映射到操作系统底层的线程中，将线程的调度权委托给操作系统，而在jvm中线程的状态其实是对底层状态的包装，jvm本身不对线程进行调度
>
> 所以我们考虑的上图中线程的6个状态，其实是指线程在虚拟机中的状态

* `New`：一个线程被`new`出来后就进入这个状态了，在调用线程的`start`方法之前，线程一直是这个状态

> 在`jdk1.4`之前的一个bug，即线程被`new`出来后，它的这个引用会被加入内部线程表中，只有调用了`start`方法才会将引用从表中移除；如果我们一直不调用`start`方法，那么这个为这个线程分配的空间就一直不会被`gc`回收

* `Runnable`：只要调用了`start`方法，线程就处于这个状态了；此后程序的控制权交由线程调度器，调度器决定哪个线程被执行（线程分发），那个线程不执行

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/RUNNABLE-VS-RUNNING.png)

在操作系统中，进程具有`Ready`和`Running`两种状态，而在jvm中线程只存在`Runnable`状态，jvm不对这两个状态进行区分，主要是因为线程在操作系统底层的`Running`状态对多停留`10-20ms`，线程切换比较频繁，可以不对其进行区分

* `Blocked`：当线程争夺锁失败的时候会进入`blocked`的状态，等待锁释放

> 一个要注意的点，就是如果线程处于`wait`状态，随后被`notify`，会首先进入`runnable`状态，然后如果被操作系统调度执行，会再次进行锁争夺，如果获取失败，才会进入`blocked`状态，即转移流程是：`waiting --> runnable --> blocked`

* `Waiting`：调用了`Object`类的方法`wait`的线程会进入`wait`状态（调用`join`方法也会进入这个状态），该状态下的线程只有其他线程调用了`notify()`或`notifyAll()`后，**才会重新进入`Runnable`状态**
* `Timed Waiting`：除了调用带有时间的`wait`方法（或者是`join`方法）或者调用`sleep`方法也会进入这个状态。相比于`waiting`状态，它在时间到了之后也会进入`Runnable`状态
* `Terminated`：线程正常退出或者出现了错误，比如各种不处理的异常，或则干脆就是`Error`

## wait/sleep

从行为上分别让线程进入了 waiting 状态和 timed waiting 状态, 看起来二者都会让线程不再继续执行下一条指令

最大的区别在于 **sleep 不会让线程释放当前已经获取的锁, 而 wait 会让线程后释放锁** => 这种特性决定了, 方法 wait 定义在了 Object 内部, 当对象调用 wait 后, 释放当前对象获取的所有锁结构; 而方法 sleep 定义在了 Thread 内部, 对线程调用 sleep 后, 不需要释放锁结构

# 多线程API

## 实现多线程

主要有两种方式实现多线程：

* 继承Thread类
* 实现Runnable接口

实际上，Thread类本身就实现了Runnable接口

```java
public class Thread implements Runnable
```

其实一般要用多线程的时候都会实现Runnable结构，毕竟单根继承，继承了Thread类就不能继承其他类了

多线程中，线程执行的顺序具有随机性，先启动的线程不一定先执行

考虑实现Runnable结构实现多线程，此时为了启动这个线程，需要将这个线程委托给一个Thread对象，并调用这个对象的start方法

> [start()方法和run()方法的区别](#start()方法和run()方法的区别)

对于Thread类具有构造器：

```java
public Thread(Runnable target)
```

可以将一个实现了Runnable结构的对象传入实现，构造一个Thread对象

> ```java
> public Thread(Runnable target, String name)
> ```
>
> 这个接口可以用来指定委托生成的Thread对象的名称

其实因为Thread类本身实现了Runnable结构，这意味着可以将一个Thread类的子类传入上面的构造函数中

## 线程安全问题

一个典型的例子就是生产者，消费者的例子

生产者线程：

```java
public class ProductorThread implements Runnable{
    private Shop shop;
    private static final String msg = "create";
    public ProductorThread(Shop shop) {
        this.shop = shop;
    }

    @Override
    public void run() {
        while (true) {
            shop.operate(msg);
            try {
                Thread.sleep(200);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
}
```

消费者线程：

```java
public class CustomerThread implements Runnable{
    private Shop shop;
    private static final String msg = "buy";
    public CustomerThread(Shop shop) {
        this.shop = shop;
    }

    @Override
    public void run() {
        while (true) {
            shop.operate(msg);
            try {
                Thread.sleep(500);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }

    }
}
```

商品类`Shop`，它具有一个属性：商品数量

```java
package com.company;

public class Shop {
    private int productVolume;
    public Shop() {
        this.productVolume = 0;
    }

    public void operate(String msg) {
        synchronized (this) {
            if (msg.equals("buy")) {
                if (getProductVolume() > 0) {
                    System.out.println(Thread.currentThread().getName() + " is buying");
                    sellProduct();
                    System.out.println(productVolume + " is left");
                    notify();
                }else {
                    try {
                        wait();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
            }else if (msg.equals("create")) {
                if (getProductVolume() < 10) {
                    System.out.println(Thread.currentThread().getName() + " is creating");
                    createProduct();
                    System.out.println(productVolume + " is left");
                    notify();
                }else {
                    try {
                        wait();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
            }
        }
    }

    private void createProduct() {
        this.productVolume++;
    }

    private void sellProduct() {
        this.productVolume--;
    }

    public int getProductVolume() {
        return this.productVolume;
    }
}
```

main方法：

```java
public class Main {

    public static void main(String[] args) {
        Shop shop = new Shop();
        ProductorThread productor1 = new ProductorThread(shop);
        ProductorThread productor2 = new ProductorThread(shop);
        CustomerThread customer1 = new CustomerThread(shop);
        CustomerThread customer2 = new CustomerThread(shop);
        Thread p1 = new Thread(productor1, "productor1");
        Thread p2 = new Thread(productor2, "productor2");
        Thread c1 = new Thread(customer1, "customer1");
        Thread c2 = new Thread(customer2, "customer2");
        p1.start();
        p2.start();
        c1.start();
        c2.start();
    }
}
```

为了保证线程的安全性，对方法operate加了锁，使得不同线程在执行这个方法的时候需要争夺锁

加锁的这部分代码称为`互斥区`，也叫临界区

## 一个奇怪的东西

现在定义线程：就是一个内部的变量，每次调用的时候会让它增加

```java
public class MyThread extends Thread{
    private int i;
    public MyThread() {
        this.i = 1;
    }

    @Override
    public void run() {
        super.run();
        System.out.println(Thread.currentThread().getName()+":"+ i++);
    }
}
```

main：

```java
public class Main {

    public static void main(String[] args) {
        MyThread myThread = new MyThread();
        for (int i = 0; i < 10; i++) {
            Thread thread = new Thread(myThread);
            thread.start();
        }
    }
}
```

因为我们知道println方法内部是同步的

```java
public void println(String x) {
    synchronized(this) {
        this.print(x);
        this.newLine();
    }
}
```

所以我们可能理所当然的认为我们不需要额外做同步了

打印结果应该是i顺序增长，不过那个线程先后就不一定了

然而打印结果长这样：

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/println%E5%92%8Ci++.png)

线程先后顺序应该是不一样的，但为什么i也不是顺序打印的啊

总之，在这个操作中，对i进行自增的操作是在进入println方法前进行的，所以会出现线程安全问题

## Thread.currentThread()与this

> 要注意，这里主要是指当一个类通过继承Thread的方式实现多线程的时候，如果只是实现了Runnable接口根本就没有这种问题，毕竟实现接口中没有属性，所以实现的时候尽量还是实现接口吧

看起来好像差不多，其实不太一样比如下面的代码：

```java
public class MyThread extends Thread{

    public MyThread() {
        System.out.println("ini myThread");
        System.out.println("Thread.currentThread().getName()" + Thread.currentThread().getName());
        System.out.println("Thread.currentThread().isAlive()" + Thread.currentThread().isAlive());
        System.out.println("this.getName()" + this.getName());
        System.out.println("this.isAlive()" + this.isAlive());
        System.out.println("this.currentThread().getName()" + this.currentThread().getName());
        System.out.println("this.currentThread().isAlive()" + this.currentThread().isAlive());
    }

    @Override
    public void run() {
        super.run();
        System.out.println("run myThread");
        System.out.println("Thread.currentThread().getName():" + Thread.currentThread().getName());
        System.out.println("Thread.currentThread().isAlive()" + Thread.currentThread().isAlive());
        System.out.println("this.getName()" + this.getName());
        System.out.println("this.isAlive()" + this.isAlive());
        System.out.println("this.currentThread().getName()" + this.currentThread().getName());
        System.out.println("this.currentThread().isAlive()" + this.currentThread().isAlive());
    }
}
```

```java
public class Main {

    public static void main(String[] args) {
        MyThread myThread = new MyThread();
        //myThread.setName("A");
	    myThread.start();
    }
}
```

打印输出结果如下：

```java
ini myThread//从此时开始调用MyThread的构造器
Thread.currentThread().getName()main//因为此时调用构造器的是main线程，所以当前的thread为main
Thread.currentThread().isAlive()true
this.getName()Thread-0//这里是因为MyThread继承了Thread，所以在调用构造函数前，会调用父类的构造函数，被分配得到一个用来表示当前Thread的名称
this.isAlive()false//因为MyThread对象还没有start，这里显然是false
this.currentThread().getName()main//这里打印结果同上Thread.currentThread().getName()
this.currentThread().isAlive()true//这里打印结果同上Thread.currentThread().isAlive()
run myThread//从这里开始MyThread处于Running状态
Thread.currentThread().getName():Thread-0
Thread.currentThread().isAlive()true
this.getName()Thread-0
this.isAlive()true
this.currentThread().getName()Thread-0
this.currentThread().isAlive()true
```

如果把上面的注释取消掉得到：其实就是多了一个setName的过程，就运行的时候线程的名称变了

```java
ini myThread
Thread.currentThread().getName()main
Thread.currentThread().isAlive()true
this.getName()Thread-0
this.isAlive()false
this.currentThread().getName()main
this.currentThread().isAlive()true
run myThread
Thread.currentThread().getName():A
Thread.currentThread().isAlive()true
this.getName()A
this.isAlive()true
this.currentThread().getName()A
this.currentThread().isAlive()true
```

现在修改main函数：

```java
public class Main {

    public static void main(String[] args) {
        MyThread myThread = new MyThread();
        Thread thread = new Thread(myThread);
        //myThread.setName("A");
	    thread.start();
    }
}
```

此时打印输出得到：

```java
ini myThread
Thread.currentThread().getName()main
Thread.currentThread().isAlive()true
this.getName()Thread-0
this.isAlive()false
this.currentThread().getName()main
this.currentThread().isAlive()true
run myThread
Thread.currentThread().getName():Thread-1
Thread.currentThread().isAlive()true
this.getName()Thread-0
this.isAlive()false
this.currentThread().getName()Thread-1
this.currentThread().isAlive()true
```

和上面最大的区别在于，现在线程run跑起来后打印结果不一样了

这是因为我们通过myThread这个线程重新构造了一个thread运行，相当于myThread这个线程不运行，而thread线程运行

而this表示的是当前对象，Thread.currentThread()表示的是当前线程（它和this.currentThread()相同）

如果将上面的注释打开得到：只是this这个对象的名字变了，而thread这个正在运行的线程的名字是不变的

```java
ini myThread
Thread.currentThread().getName()main
Thread.currentThread().isAlive()true
this.getName()Thread-0
this.isAlive()false
this.currentThread().getName()main
this.currentThread().isAlive()true
run myThread
Thread.currentThread().getName():Thread-1
Thread.currentThread().isAlive()true
this.getName()A
this.isAlive()false
this.currentThread().getName()Thread-1
this.currentThread().isAlive()true
```

## 关于线程的名字

Thread类有一个属性：` private volatile String name;`

这个类有一个空参的构造器：

```java
public Thread() {
	this(null, null, "Thread-" + nextThreadNum(), 0);
}
```

那我们看看这个重载的方法长什么样：

```java
public Thread(ThreadGroup group, Runnable target, String name,long stackSize) {
    this(group, target, name, stackSize, null, true);
}
```

可以看到空参构造器中第三项就是线程的名字，那现在`nextThreadNum()`又是什么东西呢

```java
private static synchronized int nextThreadNum() {
    return threadInitNumber++;
}
```

这是一个私有的，同步的方法，Thread还具有一个属性：`private static int threadInitNumber;`是一个类变量，只要Thread构建了一个对象这个变量就会加一

## isAlive()方法

这个方法用来测试线程是否处于活动状态：线程已经启动，并且尚未终止

要注意这个方法，当将线程委托给一个Thread对象的时候，this.isAlive()返回值为false

## sleep()方法

这个就是让线程休眠，直观上我们认为如果要让当前线程休眠：`Thread.currentThread().sleep(1000)`（当前线程休眠1s），其实更推荐的写法是：`Thread.sleep(1000)`，同样的意思

我们在写`sleep()`方法的时候其实可以看到它进行了一个异常处理：

```java
try {
    Thread.sleep(1000);
} catch (InterruptedException e) {
    e.printStackTrace();
}
```

可以看到，它捕获的是`InterruptedException`，这个异常我们在后面还能看到，这里先记一下，这个异常的抛出，会清除线程的中断标志

注意，这里为了提高程序的可读性，以后再进行线程休眠的操作时，可以考虑使用`TimeUnit`的方法`sleep`进行替换

## getId()方法

获取线程的唯一标识，自己通过继承Thread类定义自己的线程类

```java
public static void main(String[] args) throws InterruptedException {
        ThreadFromExtends threadFromExtends = new ThreadFromExtends();
        Thread thread = new Thread(threadFromExtends);
        System.out.println(Thread.currentThread().getId());//main线程 id为1
        System.out.println(threadFromExtends.getId());//自定义线程，id为14
        System.out.println(thread.getId());//自定义线程委托的线程，id为15
    }
```

## 停止线程

通过调用方法：`Thread.stop()`方法可以直接停止，然而这个方法并不安全，是已经作废的；一个更好的做法是使用`Thread.interrupt()`方法，如果直接调用这个方法并不会直接终止线程，需要加入一个判断才可以停止线程

综上，多种种方法可以停止线程：

* 线程正常退出（使用退出标志），`run()`方法结束运行后线程终止
* 使用`stop()`方法（极不推荐）
* 使用`interrupt()`方法
* 使用`volatile`修饰的标记

### 线程停不下来

我们的main方法：

```java
package com.company;

public class Main {

    public static void main(String[] args) throws InterruptedException {
        MyThread myThread = new MyThread();
        Thread thread = new Thread(myThread);
        thread.start();
        Thread.sleep(1000);
        thread.interrupt();
    }
}
```

我们自定义的线程：

```java
package com.company;

public class MyThread implements Runnable{

    @Override
    public void run() {
        for (int i = 0; i < 500000; i++) {
            System.out.println(i);
        }
    }
}
```

这个线程会循环打印50万次，在main线程启动这个线程1s后，会调用`interrupt`方法

然而如果直接跑一下这个例程会发现，调用这个方法并不能直接停止这个线程，它还是会打印到499999才结束

好吧，其实是因为如果只是调用了`interrupt()`这个方法，它不会停止线程，它仅仅是在对应的线程中打了一个中断的标记

### 判断线程的中断标志

先说几个方法，可以用来判断线程是否有中断标志：`interrupted()`，`isInterrupted()`

这两个方法从名字上来看，好像都是判断线程是否具有中断标志的，好吧，看看源码：

```java
public static boolean interrupted() {
    return currentThread().isInterrupted(true);
}
```

```java
public boolean isInterrupted() {
    return this.isInterrupted(false);
}
```

通过源码就能看出来了，这两个方法本质其实都差不多，一个是静态的，类的方法，一个是普通的方法

`interrupted()`方法是类方法，它会判断当前正在运行的线程是否设置中断标志；而`isInterrupted()`方法是对象的方法，它会判断对应线程是否设置中断标志

他们都会调用一个方法：区别在于调用这个方法的参数不同

```java
private native boolean isInterrupted(boolean var1);
```

好吧，不能继续往下看了

现在有一个举例：

```java
public static void main(String[] args) {
    Thread.currentThread().interrupt();
    System.out.println(Thread.interrupted());//true
    System.out.println(Thread.interrupted());//false
}
```

我们现在仅有一个main线程，我们先给main线程设置中断标记，然后连续两次判断当前的main线程是否中断，从打印结果上来看还是比较奇怪的，因为第二个输出结果是false

好吧，其实如果调用了`Thread.interrupted()`这个方法会判断线程是否中断，如果线程有中断标志，返回值为true，并清除中断标志，所以第二次调用这个方法的时候，返回值为false

另外一个例子：

```java
public static void main(String[] args) {
    try {
        ThreadFromExtends threadFromExtends = new ThreadFromExtends();
        threadFromExtends.start();
        threadFromExtends.interrupt();
        Thread.sleep(100);
        System.out.println(threadFromExtends.isInterrupted());//true
        System.out.println(threadFromExtends.isInterrupted());//true
    } catch (InterruptedException e) {
        e.printStackTrace();
    }
}
```

这个方法两次打印的结果都是true，就是说`isInterrupted()`这个方法并不会清除中断标志；

好吧其实看到源码的时候就能看到`isInterrupted()`方法调用私有方法是传入参数为false，而`interrupeted()`方法调用私有方法传入参数为true，我们姑且认为这个参数就是表明是否清除中断标志

### 停止线程-异常法

好吧，我们上面说了两个方法，用来判断是否具有中断标志，现在通过这个标志结束线程

我们的main线程，为了让自定义线程运行一段时间，main会sleep一段时间

```java
public static void main(String[] args) {
    try {
        MyThread myThread = new MyThread();
        Thread thread = new Thread(myThread);
        thread.start();
        Thread.sleep(100);
        thread.interrupt();
    } catch (InterruptedException e) {
        e.printStackTrace();
    }
}
```

我们自定义的线程，检测到中断标志的时候会跳出循环

```java
public class MyThread implements Runnable{

    @Override
    public void run() {
        System.out.println("myThread run");
        for (int i = 0; i < 100000; i++) {
            if (Thread.interrupted()) {
                System.out.println("break the loop");
                break;
            }
            System.out.println(i);
        }
    }
}
```

因为我们自定义的线程中只有一个for循环，执行完这个循环后`run()`方法运行结束，线程终止，但是为了让线程退出，我们可以使用抛异常的方式退出

现在我们的自定义线程长这样，如果线程设置了中断标志，会抛出异常，程序会运行到catch中，从而结束整个线程

```java
package com.company;

public class MyThread implements Runnable{

    @Override
    public void run() {
        try {
            System.out.println("myThread run");
            for (int i = 0; i < 100000; i++) {
                if (Thread.interrupted()) {
                    System.out.println("break the loop");
                    throw new InterruptedException();
                }
                System.out.println(i);
            }
        } catch (InterruptedException e) {
            System.out.println("通过异常结束线程");
            e.printStackTrace();
        }

    }
}
```

### 停止线程-在睡眠中结束线程

好吧，如果一个线程在睡眠的时候，被设置了中断标志，那么会直接抛出`InterruptedException`，结束掉整个线程

现在我们的自定义线程长成这样，进入线程的时候会进入休眠，main程序和上面一样，所以我们会因为在main线程中将子进程设置了Interrupt标志导致子进程抛出异常而退出线程

```java
package com.company;

public class MyThread implements Runnable{

    @Override
    public void run() {
        try {
            System.out.println("myThread run");
            Thread.sleep(100000);
        } catch (InterruptedException e) {
            System.out.println("通过异常结束线程");
            e.printStackTrace();
        }

    }
}
```

好吧，其实这个和上面异常法结束线程是一样的，只不过这里不需要手动抛出异常了

### 使用return停止线程

这个其实就是字面意思，如果检测到了中断标志，就直接返回

我们的自定义线程长这样：

```java
package com.company;

public class MyThread implements Runnable{

    @Override
    public void run() {
        System.out.println("myThread run");
        for (int i = 0; i < 100000; i++) {
            if (Thread.interrupted()) {
                System.out.println("break the loop");
                return;
            }
            System.out.println(i);
        }
    }
}
```

好吧，书中写的是建议使用抛异常的方式实现终止线程：因为抛出异常的方式可以将异常信息向上抛出，使得线程停止的信息可以传播开

### 使用volatile

这个其实很好解释，把一个循环的条件设置为一个`volatile`修饰的`boolean`值，如果条件满足那么会继续运行，而当其他线程修改了标记值，那么将会结束线程运行，一个简单的例子：

```java
public class GeneralTest {
	static boolean flag = true;
	@Test
	public void test() {
		ExecutorService pool = Executors.newFixedThreadPool(2);
		pool.submit(() ->{
			while (flag) {
				try {
					TimeUnit.MICROSECONDS.sleep(100);
				} catch (InterruptedException e) {
					throw new RuntimeException(e);
				}
			}
			System.out.println("结束循环");
		});
		pool.submit(() -> {
			try {
				TimeUnit.SECONDS.sleep(1);
			} catch (InterruptedException e) {
				throw new RuntimeException(e);
			}
			flag = false;
		});
	}
}
```

> 这个有时可以和`interrupt()`一起使用，比如线程在休眠时被打断了，那么此时将抛出`InterruptedException`异常，并清除打断标记，这时可以选择直接退出

## yeild()方法

这个方法有点类似于操作系统级别的`yeild()`方法，然后看了一下源码

```java
public static native void yield();
```

好吧，看来确实是系统中的方法，让当前正在运行的线程放弃CPU资源，不过这并不意味着其他的线程能够占用到CPU，还有可能这边刚放弃CPU占用，马上又重新占用资源

## join()方法

`joing()`方法针对以下的场景：考虑一个包含了两个线程的场景，其中主线程比较简单，快速运行结束，而子线程需要大量的计算，得到一个计算结果，如果主线程需要等待子线程线程完成计算，获取计算的结果，才可以继续执行

那么这个时候就需要使用`join()`方法了

```java
package com.company.threadApi;

/**
 * @program: learn_thread
 * @description:
 * @author: buzz
 * @create: 2022-04-09 16:35
 **/
public class JoinTest {
	public static void main(String[] args) throws InterruptedException {
		ComplexTask task = new ComplexTask();
		Thread t = new Thread(task, "complex task");
		t.start();
		t.join();
		System.out.println(task.setRst());
	}

}

class ComplexTask implements Runnable {
	private String rst;

	public String setRst() {
		return this.rst;
	}

	@Override
	public void run() {
		System.out.println(Thread.currentThread().getName() + "begins");
		// 模拟复杂运算，线程休眠5s
		for (int i = 0; i < 5; i++) {
			try {
				Thread.sleep(1000);
			} catch (InterruptedException e) {
				e.printStackTrace();
			}
		}
		this.rst = "task done";
		System.out.println(Thread.currentThread().getName() + "ends");
	}
}
```

注意到上面最关键的地方在于我们调用了方法：`t.join()`

如果我们不进行这个调用，那么`main`方法会在完成"复杂运算"之前调用`getRst()`方法，从而得到一个`null`

在jdk源码中`join()`是一个重载方法，会调用`join(0)`

```java

public final synchronized void join(long millis)
    throws InterruptedException {
    long base = System.currentTimeMillis();
    long now = 0;

    if (millis < 0) {
        throw new IllegalArgumentException("timeout value is negative");
    }

    if (millis == 0) {
        while (isAlive()) {
            wait(0);
        }
    } else {
        while (isAlive()) {
            long delay = millis - now;
            if (delay <= 0) {
                break;
            }
            wait(delay);
            now = System.currentTimeMillis() - base;
        }
    }
}
```

`join()`方法其实是通过`isAlive()`和`wait`方法实现的

他有一个重载的方法（被加锁），具有一个参数，表示了当前线程等待子线程的最长时间，如果传入`0`表示当前线程会一直等待子线程

要注意的是`isAlive()`是`Thread`的方法，作用是判断线程是否正在运行，而`wait()`是`Object`的方法作用是使得当前线程进入阻塞状态

我们调用了`t.join()`，源码中的逻辑就是，不断判断子线程线程是否已经运行结束，如果没有运行结束，就让`main`线程进入`wait`阻塞状态

> 首先，这个`join`方法是`synchronized`修饰的，说明锁对象是`this`。
>
> 当`this`运行结束后，在`jvm`内部，会调用`notifyAll`方法，唤醒所有正在等待`this`的其他线程

知道了源码，其实我们也就是知道了使用`join()`方法的时候，一定要在子线程`start`之后，因为如果在此之前，我们调用`isAlive`自然会返回`false`，就无法实现`main`线程等待子线程的效果了

## 线程的优先级

在调度线程资源的时候，优先级高的线程更有可能占用CPU（并不一定每次都占用，毕竟还要保证低优先级的线程能够运行）

设置线程优先级的方法是：`setPriority(int newPriority)`，源码长这样：

```java
public final void setPriority(int newPriority) {
    ThreadGroup g;
    checkAccess();
    if (newPriority > MAX_PRIORITY || newPriority < MIN_PRIORITY) {
        throw new IllegalArgumentException();
    }
    if((g = getThreadGroup()) != null) {
        if (newPriority > g.getMaxPriority()) {
            newPriority = g.getMaxPriority();
        }
        setPriority0(priority = newPriority);
    }
}
```

要注意的是线程的最低优先级是1，最高优先级是10，如果小于1或者大于10，会抛异常

源码中有三个常量：默认情况下，线程的优先级为5

```java
public static final int MIN_PRIORITY = 1;
public static final int NORM_PRIORITY = 5;
public static final int MAX_PRIORITY = 10;
```

注意上面的`setPriority0()`方法，这个方法也是本地方法

* 线程优先级具有继承关系：这里的继承关系，具体来说是说如果在一个线程中启动了另一个进程，那么这两个进程具有相同的优先级

## 守护线程

其实可以从大类上将线程分成两种：用户线程和守护线程

当进程中不存在用户线程（非守护线程）的时候，守护线程会自动销毁，典型的守护线程是垃圾回收线程

## start()方法和run()方法的区别

首先new一个Thread相当于创建一个线程，调用start方法，会启动一个线程，并且线程会进入就绪状态。

start方法执行完线程相应的准备工作后，会执行run方法，实现多线程

如果直接调用run方法，main线程会将其认为是一个普通的方法，会在main线程中执行run方法，并不是多线程工作

## wait、notify、notifyAll

这三个方法都是 Object 对象的方法, 且都是 final 修饰的, 因此不可以被子类重写

调用这三个方法时, 当前线程必须拥有当前对象的 monitor (可以认为是 lock), javadoc 中定义了三种获得对象 monitor 的方法:

*   执行当前对象的某个被 synchronized 修饰的方法时 (在对象的 synchroinzed 方法内部可以调用 this.wait())
*   当前处于某个对象的 synchronized 代码块内时
*   对于 Class 类型的 Object, 在对应类的 static 方法内时也可以获得 monitor lock

>   其实就是在使用 synchronized 关键字时锁住的对象

否则会程序在执行时会抛出异常: IllegalMonitorStateException => 当前线程尚未持有 monitor lock

### wait

调用对象的 wait() 方法后, 当前线程会被添加到对应对象的等待队列中, 等待被唤醒

大家都说看源码是最好的学习方式，这里其实主要看的是源码中的注释，看看二三十年前的代码注释

以下基本都来自源码注释：

`wait`方法会让线程进入`wait`状态，直到线程被唤醒，唤醒的方式：

* `notified`：这个我们都知道，就是上面的两个方法，一个`notify`，一个`nofityAll`

* **`interrupted`**：这个就不太知道了，我们一般会在`Thread.sleep`的时候考虑`interrupted`，这里同样，如果我们对一个调用了`wait`方法的线程进行`interrupted`，那么同样可以唤醒线程

  ```java
  package com.company.threadApi;
  
  /**
   * @program: learn_thread
   * @description:
   * @author: buzz
   * @create: 2022-04-09 19:58
   **/
  public class InterruptedTest {
  	public static void main(String[] args) throws InterruptedException {
  		Object lock = new Object();
  		WaitClass waitClass = new WaitClass(lock);
  		Thread thread = new Thread(waitClass, "wait class");
  		thread.start();
          // 这里让main线程休眠是为了让子线程thread进入到waiting状态
  		Thread.sleep(1000);
  		thread.interrupt();
  	}
  }
  
  class WaitClass implements Runnable {
  
  	private Object lock;
  
  	public WaitClass(Object lock) {
  		this.lock = lock;
  	}
  
  	@Override
  	public void run() {
  		System.out.println(Thread.currentThread().getName() + " begins");
  		synchronized (lock) {
  			try {
  				lock.wait();
  			} catch (InterruptedException e) {
  				e.printStackTrace();
  			}
  		}
  		System.out.println(Thread.currentThread().getName() + " ends");
  	}
  }
  ```

* 定时唤醒：这个就不说了反正就是一个参数

我们调用锁对象的方法`wait`时，一定要保证，当前的线程真的具有锁对象，不然会抛异常`IllegalMonitorStateException`

调用锁对象的`wait`方法后，当前线程会进入当前锁对象的`wait set`，我这里翻译成等待集合，随后获取到当前锁对象的线程会释放锁对象

> 这里引申出来，说如果一个线程拥有两把锁，那么实际释放的调用了`wait`方法的锁，这一点很重要，虽然不常用

随后线程进入休眠状态，直到发生了下面几个条件中的一个：

* 其他拥有了锁对象的线程唤醒了当前线程，包括调用方法`nofity`和方法`nofityAll`

  > 注意`nofity`方法会从`wait set`中随便选择一个线程唤醒

* 其他线程`interrupts`了当前线程：注意我们在写`wait`方法的时候也抛出了一个编译时期异常需要我们捕获：

  ```java
  try {
      lock.wait();
  } catch (InterruptedException e) {
      e.printStackTrace();
  }
  ```

  你说这不是巧了吗，和`sleep`是同类型的异常呢，注意到，这个`InterruptedException`抛出后，同样的，线程的`interrupted`标识会被清空

* 线程定时唤醒

* 线程假醒：这个其实应该算是系统错误，具体的原因，源码注释里面没说，他只说了要避免这种情况发生，所以，一般我们会在一个`while`循环中调用`wait`方法，当满足条件了，即使出现了假醒，也不会影响我们实际的逻辑

线程被唤醒后，会被从`wait set`中移除，并变为`re-enabled for thread scheduling`，即可以被调度的状态

### `notify`

唤醒一个等待当前锁对象监视器的线程，如果有多个线程等待当前锁对象的对象监视器，就从多个线程中随机挑选一个

被唤醒的线程不会立刻进入同步方法中执行，这其实也就是说，调用了锁对象`notify`方法的线程不会立刻释放锁对象

### `notifyAll`

这个方法和上面那个最大的区别在于，调用锁对象的这个方法，会唤醒所有等待当前对象监视器的线程

### 实战

通常，我们是在条件不满足的情况下调用在一个线程内调用锁对象的`wait`方法，而当条件满足后，我们在另外一个线程的中调用锁对象的`notify/notifyAll`方法，唤醒所有休眠的线程

一个比较典型的例子就是生产者和消费者的例子

我们假设，生产者会不断生产，直到物品的数量达到5，之后，生产者会主动让出控制权，进入休眠

而消费者会不断消费，直到物品数量变为0，此后，消费者会主动让出控制权，进入休眠状态

```java
package com.company.threadApi;


import java.util.Deque;
import java.util.LinkedList;

/**
 * @program: learn_thread
 * @description:
 * @author: buzz
 * @create: 2022-04-09 21:09
 **/
public class ConsumerAndProducer {
	public static void main(String[] args) throws InterruptedException {
		Deque<Object> objectDeque = new LinkedList<>();
		Consumer consumer = new Consumer(objectDeque);
		Producer producer = new Producer(objectDeque);
		Thread cThread = new Thread(consumer);
		Thread pThread = new Thread(producer);

		cThread.start();
		// 特意先让消费者跑起来，进入waiting状态
		Thread.sleep(1000);

		pThread.start();

	}
}

class Consumer implements Runnable {

	private final Deque<Object> objectList;

	public Consumer (Deque<Object> objectList) {
		this.objectList = objectList;
	}

	@Override
	public void run() {
		// 让消费者一直消费
		while (true) {
			synchronized (objectList) {
				while (objectList.size() == 0) {
					try {
						System.out.println("由于数量为0消费者休眠");
						objectList.wait();
					} catch (InterruptedException e) {
						e.printStackTrace();
					}
				}
				objectList.poll();
				System.out.println("消费者消费后剩余" + objectList.size());
				try {
					// 没什么目的就是为了让结果打印的慢一点
					Thread.sleep(50);
				} catch (InterruptedException e) {
					e.printStackTrace();
				}
				objectList.notify();
			}
		}
	}
}


class Producer implements Runnable {

	private final Deque<Object> objectList;

	public Producer(Deque<Object> objectList) {
		this.objectList = objectList;
	}

	@Override
	public void run() {
		while (true) {
			// 让生产者一直生产
			synchronized (objectList) {
				while (objectList.size() == 5) {
					try {
						System.out.println("由于数量为5生产者休眠");
						objectList.wait();
					} catch (InterruptedException e) {
						e.printStackTrace();
					}
				}
				objectList.offer(new Object());
				System.out.println("生产者生产后剩余:" + objectList.size());
				try {
					// 没什么目的就是为了让结果打印的慢一点
					Thread.sleep(50);
				} catch (InterruptedException e) {
					e.printStackTrace();
				}
				objectList.notify();
			}
		}
	}
}
```

### 几个国外面试题

* 如果在没有线程处于`waiting`下调用`notify`方法会发生什么：

  什么都不会发生

  首先，对于正常程序，一定不会让`nofity`方法的调用发生在`wait`方法之前的；其次，如果真的发生了这种情况，那么方法`notify`会直接返回，在这个方法后调用的`wait`的线程也会正常的进入`waiting`状态

* 如果进程收到了`notification`，是否能够说明`waiting`的进程已经可以运行了

  肯定不是，一个良好的编程习惯是在一个`while`中调用`wait`方法，当条件不满足是，即使进程被意外唤醒（包含了被其他线程通过意外唤醒和由于jvm底层导致的线程假醒），也可以让线程重新进入`waiting`状态

* `notifyAll`方法真的会唤醒所有的线程吗

  首先，从程序执行的角度上来看，所有等待锁对象监视器的线程都会在锁对象调用了`notifyAll`方法后进入`Runnable`状态

  然而事实上，并不是所有的线程都可以继续运行，当线程获得了对象监视器后（锁对象）会中wait方法中返回（这是通过jvm中的PC保证的），而因为我们都是把`wait`方法放在一个`while`循环中的，所以它还是有可能在进行条件判断的时候发现条件不满足从而仅需进入`waiting`状态

* 如果只要执行一个线程，为什么要唤醒所有线程

  因为`notify`方法唤醒线程是随机的，我们不能确定调用方法后，我们需要运行的线程被唤醒

## Callable接口

之前认为，要实现多线程，要么继承`Thread`类，要么实现`Runnable`接口，现在又多个一个实现`Callable`接口

使用`Runnable`接口实现的多线程是没有返回值的，因此子线程抛出的异常也不会被主线程捕获到。但是`Callable`不同，线程执行后，可以有返回值。

一般的`Callable`接口需要和`Future`接口同时使用，使用`Future`获取线程的返回值。

## park/unpark

这两个方法是`LockSupport`工具类中的静态方法，可以类比`wait`和`nofity`，用来暂停或恢复线程

```java
package com.buzz.api;

import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.LockSupport;

/**
 * @program: tough_thread
 * @description:
 * @author: buzz
 * @create: 2022-05-12 11:33
 **/
public class ParkTest {
	public static void main(String[] args) {
		Thread t = new Thread(() ->{
			try {
				TimeUnit.SECONDS.sleep(1);
			} catch (InterruptedException e) {
				throw new RuntimeException(e);
			}
			System.out.println("t 开始park");
			LockSupport.park();
		});
		t.start();
		LockSupport.unpark(t);
		System.out.println("main 结束");
	}
}

/* 
 * 打印输出如下:
 * main 结束
 * t 开始park
 */
```

对于线程`t`，他会先进行休眠`1s`，然后进入`waiting`状态，而`main`线程会先运行结束。从打印的输出结果上来看`unpark`甚至可以在`park`之前调用

注意到其和`wait、nofity`区别在于：

* 调用方法的两个线程不需要持有相同的锁对象
* 可以更加精确的唤醒某个线程

如果看源码的话，会发现这两个方法其实都是调用了底层`Unsafe`类的同名方法，这里可以认为是`LockSupport`对其的包装

而如果进入`Unsafe`类会发现其调用的`park`和`unpark`都是`native`的方法。

其底层原理可以认为是`park`方法会让当前线程等待一个许可，而`unpark`可以提供一个许可；而要注意的是`unpark`提供的许可不会叠加，故若干次的`unpark`在一次`park`后就已经抵消掉了，之后再一次`park`会让线程阻塞

> 如果`unpark`在前，那么会先提供许可

在`jvm`中，每个线程具有一个`Parker`对象，该对象有三部分：mutex、condition、_counter

线程默认的`counter`为0

* 当调用`park`方法时，会先检查`counter`是不是0，如果是0，那么线程会进入阻塞队列；而如果`counter`是1，那么本次`park`会将`counter`置为0

* 当调用`unpark`方法时，会先将`counter`置为1，然后试图唤醒在阻塞队列中的线程(两次连续的`unpark`也只会让`counter`变为0)，如果唤醒了线程那么`counter`会重新变为0

# synchronized

当考虑一个方法内部的私有变量(局部变量)，不存在线程非安全的问题；但是实例变量存在线程不安全的问题

先考虑一个`Service`类，他会进行服务，根据不同的线程的名称，对实例变量`num`进行不同的赋值

```java
package com.company.threadSafety;

public class Service {
    private int num;

    public Service(int num) {
        this.num = num;
    }

    public void doService(String usrName) {
        try {
            if ("a".equals(usrName)) {
                num = 100;
            }else {
                num = 200;
            }
            Thread.sleep(1000);
            System.out.println(usrName + num);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}
```

考虑两个线程类：

```java
package com.company.threadSafety;

public class ThreadA implements Runnable{
    private Service service;
    private static final String usrName = "a";

    public ThreadA(Service service) {
        this.service = service;
    }
    @Override
    public void run() {
        service.doService(usrName);
    }
}
```

```java
package com.company.threadSafety;

public class ThreadB implements Runnable{
    private Service service;
    private static final String usrName = "b";

    public ThreadB(Service service) {
        this.service = service;
    }
    @Override
    public void run() {
        service.doService(usrName);
    }
}
```

我们的`main`方法：

```java
public static void main(String[] args) {
    Service service = new Service(10);
    Thread threadA = new Thread(new ThreadA(service));
    Thread threadB = new Thread(new ThreadB(service));
    threadA.start();
    threadB.start();
}
```

正常情况下，我们需要打印的结果中`usrName`为a的时候对应的num为100；`usrName`为b的时候对应的num为200

打印结果：

```java
D:\jdk\jdk-11\bin\java.exe "-javaagent:D:\IntelliJ IDEA 2021.3.1\lib\idea_rt.jar=13052:D:\IntelliJ IDEA 2021.3.1\bin" -Dfile.encoding=UTF-8 -classpath D:\learn_thread\out\production\learn_thread com.company.threadSafety.Test
a200
b200

Process finished with exit code 0
```

打印结果确实不是很理想，主要是因为调用sleep方法后，线程会主动让出时间执行权，该线程之后不参与CPU调度，时间到了之后线程处于就绪状态，可以参与CPU调度，获得到CPU资源后线程可以运行

不过如果在service方法上面添加`synchronized`，就可以避免这种情况；添加`synchronized`关键字相当于给方法加锁，而在调用`sleep()`方法的时候线程并不会释放锁，所以可以强迫先获得锁结构的线程执行完run方法后才允许另一个线程执行该方法

对类的普通方法加`synchronized`关键字同步方法，锁是实例对象`this`：

```java
public synchronized void tesk() 
```

>   构造方法除外

对静态方法加`synchronized`关键字同步方法，锁是Class对象`类名.class`

```java
public synchronized static void tesk() 
```

对代码块可以使用特定的对象进行加锁

```java
synchronized(this) {
    //业务代码
}
```

要注意的是**在使用 synchronized 修饰代码块时, 不建议使用 String 类型的对象**, 因为 jvm 会使用字符串常量池进行优化, 如果使用字面量表示的 String, 可能会扩大当前 lock 的范围导致额外的线程阻塞 !!!

```java
public class Test{
    static String lock;
    static {
        lock = new String();
    }
    public static void main(String[] args) {
        int num = 0;
        synchronized(lock) {
            num++;
        }
    }
}
```

反编译：

```java
  public static void main(java.lang.String[]);
    descriptor: ([Ljava/lang/String;)V
    flags: (0x0009) ACC_PUBLIC, ACC_STATIC
    Code:
      stack=2, locals=4, args_size=1
         0: iconst_0	
         1: istore_1			// 0-1为初始化num
         2: getstatic     #2   	// Field lock:Ljava/lang/String;
         5: dup
         6: astore_2			// 将lock存到局部变量表的slot2
         7: monitorenter		// 进入同步代码块，lock的对象头的markword变为ptr_heavyweight_monitor
         8: iinc          1, 1 	// 自增操作
        11: aload_2				// 从局部变量表中获取lock
        12: monitorexit			// 释放锁
        13: goto          21	// 跳转结束
        16: astore_3			// 16-20为异常的处理操作，针对于同步过程中，如果出现异常就进入这里
        17: aload_2
        18: monitorexit
        19: aload_3
        20: athrow
        21: return
      Exception table:
         from    to  target type
             8    13    16   any
            16    19    16   any
```

本质上 synchronized 代码块依赖字节码 monitorenter 与 monitorexit 实现锁获取与锁释放, monitorenter 会让当前线程试图获取对象的 ObjectMonitor, 如果当前 ObjectMonitor 锁计数为 0 表示当前锁可以获取

>   如果是同步方法, 则会在方法的 flag 标识中添加 ACC_SYNCHRONIZED, 表示当前方法是同步方法 => 静态/非静态

jvm 在实现 synchronized 时维护了两个队列, waitSet 与 entryList; 所有竞争的线程首先会进入 entryList, jvm 会保证 entryList 中只有一个线程会改写 synchronized 的**当前线程**字段, 此后同步修改计数器 (自增), synchronized 的可重入特性就是依靠计数器实现的

当 critical section 中的线程调用了 wait 方法后, 会进入 waitSet, 并设置 synchronized 的**当前字段**为 null, 同时将计数器 -1, 进入 waitSet 的线程需要等待被唤醒才能参与竞争

synchronized 关键字在 jvm 中实现时进行了若干优化:

*   锁膨胀: 从无锁状态 -> 偏向锁 (已被废除) -> 轻量级锁 -> 重量级锁 (不会一上来就变成重量级锁)
*   锁消除: 如果某些代码是不可能被共享的, 则会将原有的同步锁消除
*   锁粗化: 将多个锁合并为大锁
*   自适应自旋锁

# ThreadLocal

**ThreadLocal 适用于每个线程需要自己独立的实例且该实例需要在多个方法中被使用，也即变量在线程间隔离而在方法或类间共享的场景**

每个线程的 ThreadLocal 是独立的, 这一点通过在每个线程中维护一个类型为 ThreadLocalMap 的变量 threadLocals 实现, 只要所有针对 ThreadLocal 的操作都只是针对当前线程中保存的某个成员变量而言, 自然可以实现线程独立

## ThreadLocalMap

每个线程可以保存多个 ThreadLocal, 因此线程内部使用 ThreadLocalMap 保存各个 ThreadLocal, 本质上 ThreadLocalMap 维护的是一个以 ThreadLocal 为键, 对应类型为 value 的 entry

```java
// ThreadLocal.java

static class ThreadLocalMap {

    /**
     * The entries in this hash map extend WeakReference, using
     * its main ref field as the key (which is always a
     * ThreadLocal object).  Note that null keys (i.e. entry.get()
     * == null) mean that the key is no longer referenced, so the
     * entry can be expunged from table.  Such entries are referred to
     * as "stale entries" in the code that follows.
     */
    static class Entry extends WeakReference<ThreadLocal<?>> {
        /** The value associated with this ThreadLocal. */
        Object value;

        Entry(ThreadLocal<?> k, Object v) {
            super(k);
            value = v;
        }
    }
    
    /**
     * The table, resized as necessary.
     * table.length MUST always be a power of two.
     */
    private Entry[] table;
}
```

ThreadLocalMap 当然是通过数组实现的, 维护了一个 Entry 类型的数组, 而每个 Entry 继承了 WeakReference, 并再 WeakRefence 的基础上额外保存了 value; 因此在使用 Entry 时可以认为其就是一个包含了两个引用的对象, 其中 ThreadLocal 类型的引用是一个 WeakReference, Object 类型的引用是强引用

>   最开始看 ThreadLocal 时总是好奇为什么 Entry 使用 WeakReference 保存 ThreadLocal, 不仅代码更难写了 (因为之前没用过 WeakRefernce, 所以各种操作都需要查文档), 而且根据网上的说法, 还可能导致内存泄漏
>
>   实际上, WeakReference 是必须的, jvm 在进行 GC 时, 是不会回收那些强引用的对象的, 如果这里使用强引用, 将导致所有添加的 ThreadLocal 对象都无法及时被回收 => 即便用户程序已经访问不到该 ThreadLocal 对象了, 但是 ThreadLocalMap 还是保存了强引用, 而 ThreadLocalMap 具有和线程一样长的生命周期, 因此**如果使用了强引用, 则只要当前线程没有运行结束, 那么当前进程创建的各个 ThreadLocal 都不会被销毁**
>
>   至于内存泄漏问题, 说的是 GC 在对 ThreadLocal 进行回收后, Entry 中 ThreadLocal 的引用变为了 null, 但 value 不为 null, 此时无法通过 ThreadLocal 暴露的各种接口访问到 value, 造成内存泄漏; 这里的内存泄漏主要由于 GC 负责回收引用, 但 ThreadLocalMap 并没有及时将 key 为 null 的 value 及时回收; 不过 ThreadLocalMap 设计已经充分考虑了这种情况, 不管是 set 还是 get, ThreadLocalMap 都会试图将所有 key 为 null 的 value 回收 => 将 entry 的 value 置为 null, 肯定还是 GC 负责回收
>
>   所以如果当前线程会不断声明新的 ThreadLocal, 那么其实是不需要过于担心内存泄漏问题的, 当然如果不希望通过这种被动的方式进行内存回收, 也可以在使用完 ThreadLocal 后主动的调用 remove(), 此后 ThreadLocalMap 会将对应的 ThreadLocal 回收的

## set

其实 ThreadLocal 在使用时主要就两个 api, set/get (硬要说的话可以把 remove 也包括在内); 先从 set 开始说

```java
// ThreadLocal.java

/**
 * Sets the current thread's copy of this thread-local variable
 * to the specified value.  Most subclasses will have no need to
 * override this method, relying solely on the {@link #initialValue}
 * method to set the values of thread-locals.
 *
 * @param value the value to be stored in the current thread's copy of
 *        this thread-local.
 */
public void set(T value) {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null) {
        map.set(this, value);
    } else {
        createMap(t, value);
    }
}

ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;
}

void createMap(Thread t, T firstValue) {
    t.threadLocals = new ThreadLocalMap(this, firstValue);
}
```

ThreadLocalMap 的设计也使用了 lazy-loading, 只有在真的需要存储 ThreadLocal 时才会将 ThreadLocalMap 初始化

所以 ThreadLocal 的 set 方法其实很简单, 就是将当前线程的 ThreadLocalMap 拿出来, 然后将对应的 value 存到 ThreadLocalMap 中, 真正麻烦的其实是 ThreadLocalMap 的 set 方法

```java
// ThreadLocal.java

static class ThreadLocalMap {

    /**
     * Set the value associated with key.
     *
     * @param key the thread local object
     * @param value the value to be set
     */
    private void set(ThreadLocal<?> key, Object value) {

        // We don't use a fast path as with get() because it is at
        // least as common to use set() to create new entries as
        // it is to replace existing ones, in which case, a fast
        // path would fail more often than not.

        Entry[] tab = table;
        int len = tab.length;
        int i = key.threadLocalHashCode & (len-1);

        for (Entry e = tab[i];
             e != null;
             e = tab[i = nextIndex(i, len)]) {
            if (e.refersTo(key)) {
                e.value = value;
                return;
            }

            if (e.refersTo(null)) {
                replaceStaleEntry(key, value, i);
                return;
            }
        }

        tab[i] = new Entry(key, value);
        int sz = ++size;
        if (!cleanSomeSlots(i, sz) && sz >= threshold)
            rehash();
    }
}
```

ThreadLocalMap 其实也是一个 Map, 但和 HashMap 不同的是, ThreadLocalMap 是使用开放地址的方式解决 hash 冲突的 (HashMap 使用的是数组链表 + 红黑树优化)

>   使用开放地址方式实现的 Map 最需要考虑的问题是, 在删除元素之后, 需要避免空穴, 在 clox 中通过 remove 删除 key 后使用 tombstone 的方式标记空穴, 但在 ThreadLocalMap 中 GC 会将 key 回收, 除此之外没有其他的操作, ThreadLocalMap 处理空穴的方式贯穿了各个内部的方法

set 函数首先会根据当前 key 的 hash code 确定当前 key 所在的偏移量, hash code 通过 ThreadLocal 中的属性 threadLocalHashCode 表示

```java
// ThreadLocal.java

public class ThreadLocal<T> {
    /**
     * ThreadLocals rely on per-thread linear-probe hash maps attached
     * to each thread (Thread.threadLocals and
     * inheritableThreadLocals).  The ThreadLocal objects act as keys,
     * searched via threadLocalHashCode.  This is a custom hash code
     * (useful only within ThreadLocalMaps) that eliminates collisions
     * in the common case where consecutively constructed ThreadLocals
     * are used by the same threads, while remaining well-behaved in
     * less common cases.
     */
    private final int threadLocalHashCode = nextHashCode();

    /**
     * The next hash code to be given out. Updated atomically. Starts at
     * zero.
     */
    private static AtomicInteger nextHashCode =
        new AtomicInteger();

    /**
     * The difference between successively generated hash codes - turns
     * implicit sequential thread-local IDs into near-optimally spread
     * multiplicative hash values for power-of-two-sized tables.
     */
    private static final int HASH_INCREMENT = 0x61c88647;

    /**
     * Returns the next hash code.
     */
    private static int nextHashCode() {
        return nextHashCode.getAndAdd(HASH_INCREMENT);
    }
}
```

注意到 ThreadLocal 的 hash code 是在 new 对象时调用静态方法创建的, 该 hash code 使用了模数自增的方式创建 (初始为 0 后续每个创建的 ThreadLocal 的 hash code 都在前一个基础上增加了 0x61c88647)

>   为什么是 0x61c88647 并没有给出解释, 从数学上, 好像是因为在这个数字下, 对 2 的幂次进行取模时, 可以尽可能将数字分散

基于此每个被创建的 ThreadLocal 都会根据 HASH_INCREMENT 以及前一个 ThreadLocal 计算当前 hash code, 在方法 set 中再通过取模的方式计算用于存储当前 key 的 entry 的下标

还记得前面说过的, 采用开放地址方式实现的 hash table, key 的 hash 冲突时, entry 一定是连续的, 因此在搜索时, 只要找到了一个 entry 为 null (key 不一定为 null), 则说明当前 hash table 中不存在对应的 key

这里先不考虑 entry 的 key 为 null 的情况, 那么上述 ThreadLocalMap 的 set 方法其实就是从 hash index 开始搜索, 找到当前 key 对应的 entry, 如果已经存过了那么就覆盖, 如果还没存过 (出 for 循环), 就从 entry 为 null 的地方添加当前 pair; 注意到在完成添加后, 还对当前 hash table 的容量进行了检查, 并在达到阈值后进行扩容 (rehash) 操作

>   注意这里的描述是不准确的, rehash 不一定扩容, 后面会再说

而如果考虑 key 为 null 的情况, 即在 for 循环中遇到了空穴, 此时 ThreadLocalMap 会调用 replaceStaleEntry 处理这种情况 (至少需要将当前 entry 的 value 置为 null => 防止内存泄漏)

```java
// ThreadLocal.java

static class ThreadLocalMap {
    private void replaceStaleEntry(ThreadLocal<?> key, Object value,
                                   int staleSlot) {
        Entry[] tab = table;
        int len = tab.length;
        Entry e;

        // Back up to check for prior stale entry in current run.
        // We clean out whole runs at a time to avoid continual
        // incremental rehashing due to garbage collector freeing
        // up refs in bunches (i.e., whenever the collector runs).
        int slotToExpunge = staleSlot;
        for (int i = prevIndex(staleSlot, len);
             (e = tab[i]) != null;
             i = prevIndex(i, len))
            if (e.refersTo(null))
                slotToExpunge = i;

        // Find either the key or trailing null slot of run, whichever
        // occurs first
        for (int i = nextIndex(staleSlot, len);
             (e = tab[i]) != null;
             i = nextIndex(i, len)) {
            // If we find key, then we need to swap it
            // with the stale entry to maintain hash table order.
            // The newly stale slot, or any other stale slot
            // encountered above it, can then be sent to expungeStaleEntry
            // to remove or rehash all of the other entries in run.
            if (e.refersTo(key)) {
                e.value = value;

                tab[i] = tab[staleSlot];
                tab[staleSlot] = e;

                // Start expunge at preceding stale entry if it exists
                if (slotToExpunge == staleSlot)
                    slotToExpunge = i;
                cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);
                return;
            }

            // If we didn't find stale entry on backward scan, the
            // first stale entry seen while scanning for key is the
            // first still present in the run.
            if (e.refersTo(null) && slotToExpunge == staleSlot)
                slotToExpunge = i;
        }

        // If key not found, put new entry in stale slot
        tab[staleSlot].value = null;
        tab[staleSlot] = new Entry(key, value);

        // If there are any other stale entries in run, expunge them
        if (slotToExpunge != staleSlot)
            cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);
    }
}
```

ThreadLocalMap 的想法是, 如果遇到了空穴就想办法把附近的空穴都处理了, 而减少 value 导致的内存泄漏, 在该方法中当前位置被定义为为 staleSlot, 而第一个空穴的位置被定义为 slotToExpunge

因此进入这个方法后, ThreadLocalMap 做的第一个事情是从当前位置开始向前找, 看看之前是否存在空穴, 直到找到 entry 为 null 的位置为止, 在这个过程中, 如果遇到了空穴就更新 slotToExpunge

```java
// ThreadLocal.java

// Back up to check for prior stale entry in current run.
// We clean out whole runs at a time to avoid continual
// incremental rehashing due to garbage collector freeing
// up refs in bunches (i.e., whenever the collector runs).
int slotToExpunge = staleSlot;
for (int i = prevIndex(staleSlot, len);
     (e = tab[i]) != null;
     i = prevIndex(i, len))
    if (e.refersTo(null))
        slotToExpunge = i;
```

>   注意到 ThreadLocalMap 并没有无脑全盘搜索, 那样实在太慢了

整个 ThreadLocalMap, 只有 set 方法可以进入当前方法 replaceStaleEntry, 所以只要进入了当前方法, 就意味着一个 ThreadLocal 正等着被添加, 所以这里还进行了后续的搜索工作, 看看当前 key 是不是已经保存在 ThreadLocalMap 中了, 一旦发现当前 key 已经存在于 map 中了, 就开始执行空穴替换, 即将靠后的 key 与当前位置 staleSlot 处的空穴进行替换, 这样做可以减少后续针对相同 key 的搜索开销 (毕竟更近了)

而如果当前 hash table 中本身就没有当前 entry, 则会将需要添加的 ThreadLocal 添加到空穴上, 如果之前将 staleSlot 标记为了 slotToExpunge, 则此时还应该更新 slotToExpunge, 因为此时的 staleSlot 已经不是空穴了而是新的 key, 但 slotToExpunge 总归是要更新的, 这里将其更新为了 hash table 中 entry 为 null 的位置

所以在第二个 for 循环后, 空穴一定被填充了, 可能是被替换了, 可能是被覆盖了, 由于 ThreadLocalMap 一次性处理多个空穴的想法, 因此在完成当前 pair 的添加后, 还是从slotToExpunge 指向的位置开始, 进行空穴的处理

>   slotToExpunge 并不一定是真的空穴也可能是等效的空穴, 比如上面提到的, key 原先不存在与 ThreadLocalMap 的情况, 此时 slotToExpunge 指向的为 null

方法 expungeStaleEntry 被称为试探性清理, 其返回值为 stale slot 的后一个 null 的 entry, 而方法 cleanSomeSlots 被称为启发式清理, 二者的作用都是清理空穴

### 试探性清理

也就是 expungeStaleEntry 

```java
// ThreadLocal.java

static class ThreadLocalMap {
    /**
     * Expunge a stale entry by rehashing any possibly colliding entries
     * lying between staleSlot and the next null slot.  This also expunges
     * any other stale entries encountered before the trailing null.  See
     * Knuth, Section 6.4
     *
     * @param staleSlot index of slot known to have null key
     * @return the index of the next null slot after staleSlot
     * (all between staleSlot and this slot will have been checked
     * for expunging).
     */
    private int expungeStaleEntry(int staleSlot) {
        Entry[] tab = table;
        int len = tab.length;

        // expunge entry at staleSlot
        tab[staleSlot].value = null;
        tab[staleSlot] = null;
        size--;

        // Rehash until we encounter null
        Entry e;
        int i;
        for (i = nextIndex(staleSlot, len);
             (e = tab[i]) != null;
             i = nextIndex(i, len)) {
            ThreadLocal<?> k = e.get();
            if (k == null) {
                e.value = null;
                tab[i] = null;
                size--;
            } else {
                int h = k.threadLocalHashCode & (len - 1);
                if (h != i) {
                    tab[i] = null;

                    // Unlike Knuth 6.4 Algorithm R, we must scan until
                    // null because multiple entries could have been stale.
                    while (tab[h] != null)
                        h = nextIndex(h, len);
                    tab[h] = e;
                }
            }
        }
        return i;
    }
}
```

方法 expungeStaleEntry 做的事情很简单, 从当前位置 staleSlot 开始不断向后找, 直到找到一个为 null 的 entry; 在这个过程中不断清理空穴 (entry 的 value 置为 null, 方便 GC, 再将 entry 置为 null 表示当前位置没人用)

而对于空穴后的不为 null 的 entry, 如果其 hash code 指向的位置 h 和当前位置 i 不相等, 则意味着当前元素一定是之前 hash 冲突后被强迫移过来的, 此时会想办法将当前 entry 添加到**之前清空出来的空穴位置处**, 而将当前位置标记为 null

最后方法的返回值一定是一段连续不为 null entry 后的第一个为 null 的entry

### 启发式清理

也就是 cleanSomeSlots

```java
// ThreadLocal.java

static class ThreadLocalMap {
    /**
     * Heuristically scan some cells looking for stale entries.
     * This is invoked when either a new element is added, or
     * another stale one has been expunged. It performs a
     * logarithmic number of scans, as a balance between no
     * scanning (fast but retains garbage) and a number of scans
     * proportional to number of elements, that would find all
     * garbage but would cause some insertions to take O(n) time.
     *
     * @param i a position known NOT to hold a stale entry. The
     * scan starts at the element after i.
     *
     * @param n scan control: {@code log2(n)} cells are scanned,
     * unless a stale entry is found, in which case
     * {@code log2(table.length)-1} additional cells are scanned.
     * When called from insertions, this parameter is the number
     * of elements, but when from replaceStaleEntry, it is the
     * table length. (Note: all this could be changed to be either
     * more or less aggressive by weighting n instead of just
     * using straight log n. But this version is simple, fast, and
     * seems to work well.)
     *
     * @return true if any stale entries have been removed.
     */
    private boolean cleanSomeSlots(int i, int n) {
        boolean removed = false;
        Entry[] tab = table;
        int len = tab.length;
        do {
            i = nextIndex(i, len);
            Entry e = tab[i];
            if (e != null && e.refersTo(null)) {
                n = len;
                removed = true;
                i = expungeStaleEntry(i);
            }
        } while ( (n >>>= 1) != 0);
        return removed;
    }
}
```

这里的启发式清理方法就是从一个地方开始, 搜索 $\log n$ 次, 每次只要找到了一个空穴, 就执行一次试探性清理, 方法返回值为是否执行过试探性清理

### rehash

对于有空穴的情况, 添加操作其实是替换, entry 数组内 pair 的数量并没有增加, 但上面也提到了, 如果最后必须将 ThreadLocal 放在一个 entry 为 null 的位置, 此时 entry 中存储的元素的个数其实是增加了的

对于 ThreadLocalMap 而言, 如果增加了元素, 首先第一反应是执行启发式清理 (不执行试探性清理是因为当前位置已经确定是一个有效的 key 了), 然后查看当前 entry 中保存的元素个数是否达到了阈值, 如果到达了阈值则会调用方法 rehash

```java
// ThreadLocal.java

static class ThreadLocalMap {
	/**
     * Re-pack and/or re-size the table. First scan the entire
     * table removing stale entries. If this doesn't sufficiently
     * shrink the size of the table, double the table size.
     */
    private void rehash() {
        expungeStaleEntries();

        // Use lower threshold for doubling to avoid hysteresis
        if (size >= threshold - threshold / 4)
            resize();
    }
    
    /**
     * Expunge all stale entries in the table.
     */
    private void expungeStaleEntries() {
        Entry[] tab = table;
        int len = tab.length;
        for (int j = 0; j < len; j++) {
            Entry e = tab[j];
            if (e != null && e.refersTo(null))
                expungeStaleEntry(j);
        }
    }
    
    /**
     * Double the capacity of the table.
     */
    private void resize() {
        Entry[] oldTab = table;
        int oldLen = oldTab.length;
        int newLen = oldLen * 2;
        Entry[] newTab = new Entry[newLen];
        int count = 0;

        for (Entry e : oldTab) {
            if (e != null) {
                ThreadLocal<?> k = e.get();
                if (k == null) {
                    e.value = null; // Help the GC
                } else {
                    int h = k.threadLocalHashCode & (newLen - 1);
                    while (newTab[h] != null)
                        h = nextIndex(h, newLen);
                    newTab[h] = e;
                    count++;
                }
            }
        }

        setThreshold(newLen);
        size = count;
        table = newTab;
    }
    
    /**
     * Set the resize threshold to maintain at worst a 2/3 load factor.
     */
    private void setThreshold(int len) {
        threshold = len * 2 / 3;
    }
}
```

方法 rehash 是有点暴力的, 每次 rehash 的时候, 会先进行一次全盘的试探性清理, 去除 entry 数组中所有的空穴, 再去除后, 如果剩下的有效 pair 的个数依旧达到了 threshold 的 $\frac{3}{4}$ 才会进行真正扩容操作

>   ThreadLocalMap 保存的 entry 数组大小一定是 2 的幂次, 因此这里的 $\frac{3}{4}$ 不存在整数除法导致的精度问题

而 resize 其实很简单, 就是将大小翻倍, 然后重新挨个 pair 计算新位置, 注意到最后因为数组大小修改了, 还需要重新计算阈值, 因此这里也知道了, 阈值就是整个数组大小的 $\frac{2}{3}$

## get

其实 get 还更简单一点

```java
// ThreadLocal.java

/**
 * Returns the value in the current thread's copy of this
 * thread-local variable.  If the variable has no value for the
 * current thread, it is first initialized to the value returned
 * by an invocation of the {@link #initialValue} method.
 *
 * @return the current thread's value of this thread-local
 */
public T get() {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null) {
        ThreadLocalMap.Entry e = map.getEntry(this);
        if (e != null) {
            @SuppressWarnings("unchecked")
            T result = (T)e.value;
            return result;
        }
    }
    return setInitialValue();
}

/**
 * Variant of set() to establish initialValue. Used instead
 * of set() in case user has overridden the set() method.
 *
 * @return the initial value
 */
private T setInitialValue() {
    T value = initialValue();
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null) {
        map.set(this, value);
    } else {
        createMap(t, value);
    }
    if (this instanceof TerminatingThreadLocal) {
        TerminatingThreadLocal.register((TerminatingThreadLocal<?>) this);
    }
    return value;
}
```

本质上还是调用 ThreadLocalMap 的 get 方法, 比较有意思的是 get 方法处理了在 set 之前就 get 的情况, 此时会在当前 ThreadLocalMap 中设置一个 key 为 ThreadLocal, value 为 null 的默认值

```java
// ThreadLocal.java

static class ThreadLocalMap {
    /**
     * Get the entry associated with key.  This method
     * itself handles only the fast path: a direct hit of existing
     * key. It otherwise relays to getEntryAfterMiss.  This is
     * designed to maximize performance for direct hits, in part
     * by making this method readily inlinable.
     *
     * @param  key the thread local object
     * @return the entry associated with key, or null if no such
     */
    private Entry getEntry(ThreadLocal<?> key) {
        int i = key.threadLocalHashCode & (table.length - 1);
        Entry e = table[i];
        if (e != null && e.refersTo(key))
            return e;
        else
            return getEntryAfterMiss(key, i, e);
    }
    
    /**
     * Version of getEntry method for use when key is not found in
     * its direct hash slot.
     *
     * @param  key the thread local object
     * @param  i the table index for key's hash code
     * @param  e the entry at table[i]
     * @return the entry associated with key, or null if no such
     */
    private Entry getEntryAfterMiss(ThreadLocal<?> key, int i, Entry e) {
        Entry[] tab = table;
        int len = tab.length;

        while (e != null) {
            if (e.refersTo(key))
                return e;
            if (e.refersTo(null))
                expungeStaleEntry(i);
            else
                i = nextIndex(i, len);
            e = tab[i];
        }
        return null;
    }
}
```

getEntry 的逻辑也没有很繁琐, 就是先计算 ThreadLocal 的 hash 值, 然后从对应偏移量开始向后搜索, 如果直接命中说明没有 hash 冲突, 且没有空穴, 直接返回即可; 否则说明存在 hash 冲突, 如果当前 ThreadLocal 存在于 entry 数组中, 则必然需要是从当前位置先后连续搜索

方法 getEntryAfterMiss 处理了 entry 为空穴的情况, 在遇到空穴后调用 expungeStaleEntry 将当前空穴替换为一个有效的 entry (可能为 null)

# 线程死锁

简单来说就是线程等待一个不可能被释放的资源

一个简单的例子，即线程`A`等待线程`B`占用的资源，而线程`B`同时也在等待线程`A`占用的资源：

```java
package com.company;

/**
 * @program: learn_thread
 * @description:
 * @author: buzz
 * @create: 2022-04-10 15:30
 **/
public class DeadLock {
	private static final Object LOCK1 = new Object();
	private static final Object LOCK2 = new Object();
	public static void main(String[] args) {
		Thread a = new Thread(() -> {
			synchronized (LOCK1) {
				System.out.println(Thread.currentThread().getName()  + "get lock1");
				try {
					Thread.sleep(1000);
				} catch (InterruptedException e) {
					e.printStackTrace();
				}
				synchronized (LOCK2) {
					System.out.println(Thread.currentThread().getName() + "get both locks");
				}
			}
		});
		Thread b = new Thread(() -> {
			synchronized (LOCK2) {
				System.out.println(Thread.currentThread().getName()  + "get lock2");
				try {
					Thread.sleep(1000);
				} catch (InterruptedException e) {
					e.printStackTrace();
				}
				synchronized (LOCK1) {
					System.out.println(Thread.currentThread().getName() + "get both locks");
				}
			}
		});

		a.start();
		b.start();
	}

}
```

打印输出：

```shell
Thread-1get lock2
Thread-0get lock1
```

即线程等待一个不可能被释放的资源

## 定位死锁

* `jstack`：在`cmd`中使用`jps`命令可以打印正在运行的`java`程序，得到程序名对应的PID，比如：

  ```shell
  $ jps
  17616 Launcher
  2752 Jps
  16068 DeadLock
  19064 RemoteMavenServer36
  6488
  19084 
  ```

  然后使用`jstack {对应的PID}`，即可得到对应的栈信息：

  ```shell
  # 这上面还有若干内容
  Found one Java-level deadlock:
  =============================
  "Thread-0":
    waiting to lock monitor 0x0000012991d67060 (object 0x000000008a35ffe0, a java.lang.Object),
    which is held by "Thread-1"
  
  "Thread-1":
    waiting to lock monitor 0x0000012991d682c0 (object 0x000000008a35ffd0, a java.lang.Object),
    which is held by "Thread-0"
  
  Java stack information for the threads listed above:
  ===================================================
  "Thread-0":
          at com.buzz.locks.DeadLock.lambda$main$0(DeadLock.java:24)
          - waiting to lock <0x000000008a35ffe0> (a java.lang.Object)
          - locked <0x000000008a35ffd0> (a java.lang.Object)
          at com.buzz.locks.DeadLock$$Lambda$16/0x0000000800c01a00.run(Unknown Source)
          at java.lang.Thread.run(java.base@17.0.2/Thread.java:833)
  "Thread-1":
          at com.buzz.locks.DeadLock.lambda$main$1(DeadLock.java:37)
          - waiting to lock <0x000000008a35ffd0> (a java.lang.Object)
          - locked <0x000000008a35ffe0> (a java.lang.Object)
          at com.buzz.locks.DeadLock$$Lambda$17/0x0000000800c01c18.run(Unknown Source)
          at java.lang.Thread.run(java.base@17.0.2/Thread.java:833)
  
  Found 1 deadlock.
  
  ```

  可以看到两个线程阻塞了，且每个线程都在等待对方线程当前正持有的锁对象

* `jconsole`：图形化界面

## 造成进程死锁的四个条件

>   纯八股

* 互斥条件：任意一个资源同一时刻最多被一个进程占用
* 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放
* 不剥夺条件：进程占用的资源不会被其他进程强行剥夺，只有当持有资源的进程完成任务后才会释放资源
* 循环等待条件：多个进程之间形成头尾相接的循环等待资源的关系

所以为了避免出现线程死锁，我们可以想办法破坏上面的条件：

* 破坏互斥条件：让资源处于共享模式，多个进程可以同时占用同一资源；但是这样就没有意义了，如果是共享的，为什么还要加锁
* 请求与保持条件：让一个进程一次占有所有资源
* 破坏不剥夺条件：当一个进程无法申请到资源进入等待时，让其释放已经占用的资源
* 破坏循环等待条件：重排进程申请资源的顺序，线程按序申请资源，反序释放资源

# ReentrantLock

可重入锁（其实`synchronized`的也是可重入的）

基本的使用方法：

```java
Lock lock = new ReentrantLock();
lock.lock();// 加锁操作
try{
    // 临界区
}finally{
    lock.unlock();
}
```

可以看到，现在使用这个锁需要手动加锁，离开临界区后需要手动解锁

和`synchronized`的区别：

* 锁可以中断，当某个线程因为等待锁对象而进入`blocking`状态，通过调用`interrupt`方法可以打断对应的线程。
* 可设置超时时间，如果一段时间内获取不到锁就放弃，进行其他分支操作

* 可以设置为公平锁（说白了，就是把`block`的线程放到一个队列，先等待的先获得释放出来的锁对象）

* 多个条件变量：即有多个`waitset`，不满足对应的条件，进入对应的`waitset`等待

## 可打断

此时需要不要使用`lock()`方法加锁，而应该使用`lockInterruptibly()`，表明如果尝试加锁时进入了`blocking`的状态，是可以被打断的。

```java
package com.buzz.api;

import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.ReentrantLock;

/**
 * @program: tough_thread
 * @description:
 * @author: buzz
 * @create: 2022-05-12 20:07
 **/
public class ReentrantLockTest {
	public static void main(String[] args) {
		ReentrantLock lock = new ReentrantLock();
		lock.lock();
		try {
			Thread t = new Thread(() -> {
				try {
					lock.lockInterruptibly();
					try {
						System.out.println("获取到lock");
					}finally {
						lock.unlock();
					}
				} catch (InterruptedException e) {
					System.out.println("被打断");
				}
			});
			t.start();
			TimeUnit.SECONDS.sleep(1);
			t.interrupt();
		} catch (InterruptedException e) {
			throw new RuntimeException(e);
		} finally {
			lock.unlock();
		}
	}
}

// 打印输出：被打断
```

可以看到，在`main`线程进行了加锁操作，而在`try-finally`中添加了一个新的线程，并让其试图获取锁对象，其一定会加锁失败。

## 超时时间

这里需要调用的方法也不是`lock()`而是`boolean tryLock(long timeout, TimeUnit unit)`，其中第一个参数为最大等待时间大小，第二个参数为时间单位。如果调用方法时不传入参数，那么在获取锁失败后，会直接返回`false`

设定锁的超时时间，可以保证线程不会无限制的等待锁对象

注意`tryLock`本身也是支持被打断的，所以使用的带有参数的`tryLock`时需要使用`try-catch`包裹

利用这个超时时间可以很容易的解决死锁问题：

```java
import java.util.concurrent.locks.ReentrantLock;

/**
 * @program: tough_thread
 * @description:
 * @author: buzz
 * @create: 2022-05-12 17:50
 **/
public class DeadLock {
	private static final ReentrantLock LOCK1 = new ReentrantLock();
	private static final ReentrantLock LOCK2 = new ReentrantLock();
	public static void main(String[] args) {
		Thread a = new Thread(() -> {
			while (true) {
				if (LOCK1.tryLock()) {
					try {
                        // 关键点在于如果获取LOCK2失败了，就进入finally块中释放自己已经有的锁
						if (LOCK2.tryLock()) {
							try {
								System.out.println(Thread.currentThread().getName() + "get lock");
							}finally {
								LOCK2.unlock();
							}
						}
					}finally {
						LOCK1.unlock();
					}
				}
			}
		});
		Thread b = new Thread(() -> {
			while (true) {
				if (LOCK2.tryLock()) {
					try {
						if (LOCK1.tryLock()) {
							try {
								System.out.println(Thread.currentThread().getName() + "get lock");
							}finally {
								LOCK1.unlock();
							}
						}
					}finally {
						LOCK2.unlock();
					}
				}
			}
		});
		a.start();
		b.start();
	}
}
```

使用`ReentarntLock`解决死锁主要破坏了不剥夺条件，即当尝试获得锁失败后，就释放自己已经持有的锁对象

## 公平性

默认的`ReentrantLock`也是不公平锁，通过在`new`锁对象时，调用构造方法传入参数的不同实现构造公平/不公平的锁

```java
/**
  * Creates an instance of {@code ReentrantLock} with the
  * given fairness policy.
  *
  * @param fair {@code true} if this lock should use a fair ordering policy
  */
public ReentrantLock(boolean fair) {
    sync = fair ? new FairSync() : new NonfairSync();
}
```

## 多个条件

在消费者和生产者的例子中，我们调用了`wait`和`nofity`方法实现了不满足条件时等待，而满足条件后唤醒。

在这里我们可以使用`Condition`类替换原来的锁对象，在条件不满足时，让其进入`Condition`对象的`waitset`中`wait`，而不是锁对象的。在条件满足时唤醒对应`waitset`中的对象。转而调用`condition`对象的方法：`await`和`singal(singalAll)`

```java
package com.buzz.locks;

import java.util.LinkedList;
import java.util.Queue;
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.ReentrantLock;

/**
 * @program: tough_thread
 * @description:
 * @author: buzz
 * @create: 2022-05-12 21:34
 **/
public class ConsumerAndProvider {
	public static void main(String[] args) {
		ReentrantLock lock = new ReentrantLock();
		Condition condition = lock.newCondition();
		Queue<Object> queue = new LinkedList<>();

		Thread consumer = new Thread(new Consumer(queue, lock, condition), "consumer");
		Thread provider = new Thread(new Provider(queue, lock, condition), "provider");
		consumer.start();
		provider.start();
	}
}
class Consumer implements Runnable {

	private final Queue<Object> objectQueue;
	private final ReentrantLock lock;
	private final Condition condition;
	public Consumer(Queue<Object> objectQueue, ReentrantLock lock, Condition condition) {
		this.objectQueue = objectQueue;
		this.lock = lock;
		this.condition = condition;
	}

	@Override
	public void run() {
		while (true) {
			lock.lock();
			try {
				while (objectQueue.size() == 0) {
					try {
						condition.await();
					} catch (InterruptedException e) {
						throw new RuntimeException(e);
					}
				}
				System.out.println("Consumer consume:" + objectQueue.size());
				objectQueue.poll();
				condition.signalAll();
			} catch (Exception e) {
				return;
			}
			finally {
				lock.unlock();
			}
		}
	}
}

class Provider implements Runnable{
	private final Queue<Object> objectQueue;
	private final ReentrantLock lock;
	private final Condition condition;

	public Provider(Queue<Object> objectQueue, ReentrantLock lock, Condition condition) {
		this.objectQueue = objectQueue;
		this.lock = lock;
		this.condition = condition;
	}

	@Override
	public void run() {
		while (true) {
			lock.lock();
			try {
				while (objectQueue.size() == 10) {
					try {
						condition.await();
					} catch (InterruptedException e) {
						throw new RuntimeException(e);
					}
				}
				objectQueue.offer(new Object());
				System.out.println("Provider provide:" + objectQueue.size());
				condition.signalAll();
			} catch (Exception e) {
				return;
			}
			finally {
				lock.unlock();
			}
		}

	}
}
```

这里比较关键的地方在于调用方法`lock.newCondition()`，新建了一个`waitobject`，让消费者和生产者在该对象的`waitset`中等待

# 面试

## 三个线程交替输出abc

可以分别使用`wait-notify`、`park-unpark`、`await-signal`解决

### wait-notify

```java
public class Solution {
	// 一共循环5次
	private static final int L00P_COUNT = 5;
	public static void main(String[] args) {
		new Thread(() -> {
			for (int i = 0; i < L00P_COUNT; i++) WaitNotify.print("a", 0);
		}).start();
		new Thread(() -> {
			for (int i = 0; i < L00P_COUNT; i++) WaitNotify.print("b", 1);
		}).start();
		new Thread(() -> {
			for (int i = 0; i < L00P_COUNT; i++) WaitNotify.print("c", 2);
		}).start();
	}
}

class WaitNotify{
	static volatile int count = 0;
	private static final int MOD = 3;
    // 因为wait必须要在临界区使用，所以这里使用synchronized加锁
	public synchronized static void print(String s, int print) {
		while (count != print) {
			try {
				Solution.class.wait();
			} catch (InterruptedException e) {
				throw new RuntimeException(e);
			}
		}
		System.out.print(s);
		count = (count + 1) % MOD;
		Solution.class.notifyAll();
	}
}
```

### await-signal

```java
public class Solution {
	private static final int L00P_COUNT = 5;
	public static void main(String[] args) {
		new Thread(() -> {
			for (int i = 0; i < L00P_COUNT; i++) AwaitSignal.print("a", 0);
		}).start();
		new Thread(() -> {
			for (int i = 0; i < L00P_COUNT; i++) AwaitSignal.print("b", 1);
		}).start();
		new Thread(() -> {
			for (int i = 0; i < L00P_COUNT; i++) AwaitSignal.print("c", 2);
		}).start();
	}
}

class AwaitSignal{
	private static volatile int count = 0;
	private static final int MOD = 3;
    // 最大的区别在于新建了三个waitset
	private static final Condition[] CONDITIONS;
	private static final ReentrantLock LOCK = new ReentrantLock();
	static {
		CONDITIONS = new Condition[MOD];
		for (int i = 0; i < MOD; i++) {
			CONDITIONS[i] = LOCK.newCondition();
		}
	}

	public static void print(String s, int print) {
		LOCK.lock();
		try {
			while (count != print) {
				try {
					CONDITIONS[print].await();
				} catch (InterruptedException e) {
					throw new RuntimeException(e);
				}
			}
			System.out.print(s);
			count = (count + 1) % MOD;
			int next = (print + 1) % MOD;
			CONDITIONS[next].signalAll();
		}finally {
			LOCK.unlock();
		}
	}
}
```

### park-unpark

```java
public class Solution {
	private static final int L00P_COUNT = 5;
	public static void main(String[] args) {
		Thread[] threads = new Thread[3];
		threads[0] = new Thread(() -> {
			for (int i = 0; i < L00P_COUNT; i++) ParkUnpark.print(threads[1], "a", 0);
		});
		threads[1] = new Thread(() -> {
			for (int i = 0; i < L00P_COUNT; i++) ParkUnpark.print(threads[2], "b", 1);
		});
		threads[2] = new Thread(() -> {
			for (int i = 0; i < L00P_COUNT; i++) ParkUnpark.print(threads[0], "c", 2);
		});
		for (int i = 0; i < 3; i++) threads[i].start();
	}
}

class ParkUnpark{
	private static volatile int count = 0;
	private static final int MOD = 3;
    // 注意到park-unpark不需要加锁，仅仅是单纯的唤醒-休眠
	public static void print(Thread toUnlock, String s, int print) {
		while (count != print) LockSupport.park();
		System.out.print(s);
		count = (count + 1) % MOD;
		LockSupport.unpark(toUnlock);
	}
}
```

# 并发的三个特性

参考：[并发编程三大特性——原子性、可见性、有序性](https://www.cnblogs.com/yeyang/p/13576636.html)

就是常说的原子性、可见性、有序性

## 原子性

**即一个操作或者多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。**

```java
i = 0;      	//1
j = i;      	//2
i++;         	//3
i = j + 1;   	//4
```

以上的这些指令，有哪些是原子的？

如果反编译成字节码指令的话，会发现，上面的这四个没有一个是原子的，然而，根据[官网说明](https://docs.oracle.com/javase/tutorial/essential/concurrency/atomic.html)

他说了，一下两类操作是原子的：

* 读写引用类型或者大部分的基本数据类型是原子的

> 这里的大部分主要是排除了`double`类型和`long`类型

* 读写带有`volatile`修饰的变量是原子的，这里包含了`double`和`long`类型

好吧，其实这里可以参考：[jmm中的8种原子操作](./JVM.md#8种原子操作)

下面的内容半信半疑：

个人理解为第一个操作为原子的，因为它对应了8种原子操作中的`assign`操作

第二个操作不是原子的，因为他首先需要进行一次对变量`i`的`use`，然后对变量`j`进行`assign`

而至于第三个，这个一看就不是原子的

我们根据`jmm`中8种原子操作也可以知道，`lock`操作和`unlock`操作是为了更大范围的原子性设定的

即我们可以通过`lock`一个变量，线程对变量进行读写，这期间，所有其他线程不可以访问这个变量，而当我们`unlock`变量的时候，jvm的规则保证了，新的运算结果会被写回主内存

而事实上，我们并不能直接进行`lock`和`unlock`操作，`jvm`提供的字节码指令中的`monitorenter`和`monitorexit`其实相当于对这两个操作进行了封装，这也就是说我们在使用`synchronized`关键字时，其实保证了操作变量的原子性（也可以认为操作是原子的）

但是`synchronized`关键字让代码段变为原子的，这会导致，线程运行时的串行，最坏的情况下，将多个线程等效为了单个线程执行，不仅如此，多线程之间的上下文切换也是需要开销的，所以在这种情况下，多线程的并发执行效率可能不如单线程

> 个人认为在`unlock`前一定需要将更新的结果写回主内存，这同时也保证了可见性
>
> 怪不得都给`synchronized`扣上了一个万能的帽子

一定要明确的是`volatile`并不能保证原子性，举一个简单的例子：

```java
public class TestVolatile{
    public volatile static int num;
    static {
        num = 0;
    }

    public static void increase() {
        num++;
    }

    public static void main(String[] args) {

        for (int i = 0; i < 5; i++) {
            new Thread(() -> {
                for (int j = 0; j < 10000; j++) increase();
            }).start();
        }

        System.out.println("num:" + num);
    }
}
```

我们开了5个线程，让它对`num`进行自增的操作，连续调用的打印挤结果如下：

```shell
[buzz@VM-4-11-centos volatile]$ java TestVolatile
num:31737
[buzz@VM-4-11-centos volatile]$ java TestVolatile
num:30932
[buzz@VM-4-11-centos volatile]$ java TestVolatile
num:26406
```

我们可以看到，尽管每次都不同，但都没有达到我们的预期值：`50000`

通过反编译可以看到，当我们进行加一的操作时，实际的指令有4条，`volatile`关键字可以保证每次我们`getstatic`都是从主内存中获取的变量，且进行`putstatic`后变量也会立刻同步回内存

但是问题就出现在`volatile`并不保证原子性，完全可能存在一种极端情况，即`5`个线程按照一定顺序，先后从主内存中获取到了变量`i`(注意，此时这些线程都仅仅执行第一条指令后放弃当前的控制权)，然后由按照一定顺序进行了加一操作，每个线程都计算得到了1，然后再按照先后顺序写回主内存，这样，即便看起来是进行了`5`次`increase`操作，实际等效为`1`次有效的`increase`操作

```java
 public static void increase();
    descriptor: ()V
    flags: (0x0009) ACC_PUBLIC, ACC_STATIC
    Code:
      stack=2, locals=0, args_size=0
         0: getstatic     #2                  // Field num:I
         3: iconst_1
         4: iadd
         5: putstatic     #2                  // Field num:I
         8: return
      LineNumberTable:
        line 12: 0
        line 13: 8
```

## 可见性

**可见性是指当一个线程修改了共享变量的值，其他线程能够立即得知这个修改**

举个例子：

```java
// 线程A执行的代码
k = 0; //1
k = 5; //2
// 线程B执行的代码
j = k; //3
```

如果`A`线程在`B`线程之前执行，那么`j`的值应该是多少

这个我们是不知道的，就算我们把`k = 5`删掉，我们也不能确定`j`的取值

因为`k = 0`这个行为是在工作内存中进行的，我们也不知道它什么时候同步到主内存中

这会导致：**线程`B`不能立刻看到线程`A`对变量的修改**

线程之间变量的可见性必须通过主内存，即一个线程在工作内存中修改了变量，必须将其写回主内存，而另一个线程需要重新从主内存中获取对应的变量

`voltaile`关键字的保证了，当一个线程对变量进行修改后，该值会被立刻同步到主内存，且每次线程使用变量时，必须从主内存中获取变量；通过这种规则，**`voltaile`关键字保证了多线程之间，变量的可见性**

此外，我们知道`synchronized`关键字会间接的对内存中的变量进行`lock`操作，这会清空其他线程工作内存中，该变量的取值，从而当其他线程需要使用对应变量时，会进入`blocked`状态；当程序从`synchronized`代码块中离开的时候，会间接的对变量进行`unlock`操作，根据jmm的规则，线程必须将工作内存中的变量写回主内存；所以通过`synchronized`关键字，也可以实现变量的可见性

## 有序性

首先我们要明确的是，在单线程环境中，肯定不会出现有序性的问题，因为jvm进行指令重排的要求是，保证在单线程下不会改变执行的结果

所以我们需要关注的是多线程下的指令重排，一个比较典型的例子就是在单例模式的`DCL`中，我们必须使用`volatile`修饰单例对象

因为在`jvm`中实例化一个对象并不是原子的，即可以分为三步：

* 首先在堆区中开辟一段空间，这一步是确定的
* 在堆区中进行对象的初始化
* 将堆区的引用赋给单例的成员变量

我们都知道后面两步的顺序是不确定的，使用`volatile`修饰，可以保证对象在实例化的时候不会发生指令重排序

此外我们还知道，使用了`synchronized`修饰，变相的在字节码中使用了`monitorenter`和`monitorexit`，这两个指令隐式的对变量进行了`lock`和`unlock`操作，这意味着，对变量的访问变成了单线程的访问，即便出现了指令重排的情况，也不会出现访问安全问题

综上，`volatile`可以保证变量的可见性和有序性，而`synchronized`关键字在此基础上还可以保证变量访问的原子性

# volatile

`volatile`关键字可以保证变量的可见性并且防止指令发生重排序，其底层实现是内存屏障

> `volatile`在`jdk 1.5`之后才可以保证有序性！！！

内存屏障分为读屏障（load barrier）和写屏障（store barrier）

`volatile`变量的写指令之后会加入写屏障；而`volatile`变量的读指令之前会加入写屏障

在写屏障之前对变量的改动会被写回工作内存中，而在读屏障之后的变量均从主存中获取；通过这种方式可以保证变量的可见性

写屏障可以保证指令重排时，写屏障之前的代码不会重排到写屏障之后，而读屏障可以保证指令重排时，读屏障之后的代码不会重排到读屏障之前；通过这种方式保证有序性

但一定要注意的时`volatile`并不能保证原子性，简单来说：

```java
public class Test{
    private static volatile int num = 0;
    // thread 1执行
    public void static inc() {
        num++;
    }
    // thread 2执行
    public void static dec() {
        num--;
    }
}
```

没有人可以保证在执行之后num值还为`0`

因为`++`和`--`操作本身不是原子的，所以完全可能出现一种情况：

* `thread 1`从内存中读取`num`为0
* `thread 2`从内存中读取`num`为0
* `thread 1`进行自增操作，因为`volatile`，保证了读取、计算、写回工作内存的一系列操作不发生指令重排，并及时的将`num`写回了主内存
* `thread 2`进行的自减操作，具体操作和上面类似
* 最终主内存中的`num`为-1

`volatile`关键字的有序性保证了线程内部，进行`++`（或`--`）操作的有序性，并不是说线程的执行顺序是有序的

> `volatile`的一个比较直观的使用例子其实是在单例模式的懒汉式（DCL）中
>
> 使用`volatile`避免了指令重排，保证了`new`对象时的有序性：
>
> * 在堆区开辟一段内存空间
> * 调用构造方法初始化对象
> * 将内部`static`的`singleTon`指向这片空间
>
> 关键在于保证了第二步和第三步之间的有序性，从而使得当`singleTon`不为`null`时，那么对象一定完成了初始化

更精确的说法：

## 四种内存屏障

要明确的是内存屏障是针对处理器的说法，针对的是处理器是指令

* `LoadLoad`内存屏障：这种屏障出现在连续的两次`load`之间，比如：`load1 -> loadload屏障 -> load2`；这种屏障可以保证进行`load2`以及后续操作之前，`load1`已经进行完毕
* `StoreStore`内存屏障：这种屏障出现在连续的两次`store`之间，比如：`store1 -> storestore -> store2`；这种屏障可以保证进行`store2`以及后续操作之前，`store1`产生的改变（写入主内存）对所有其他处理器可见
* `LoadStore`内存屏障：这种屏障出现在`load`和`store`之间，比如：`load1 -> loadstore -> store2`；这种屏障可以保证进行`store2`以及有序操作之前，`load1`已经进行完毕
* `StoreLoad`内存屏障：这种屏障出现在`store`和`load`之间，比如：`store1 -> storeload -> load2`；这种屏障保证进行`load2`之前，`store1`写入的操作对所有其他处理器是可见的

要说明的是，最后一种屏障`storeload`的开销最大，而其本身的特点是万能的，可以认为如果加入了这种屏障，可以实现上面三种屏障的功能

实际`jmm`添加的屏障还是比较复杂的：

* 在每个volatile写操作前插入StoreStore屏障，在写操作后插入StoreLoad屏障；在写之前加上`storestore`屏障，保证了普通的写操作发生在`volatile`写操作之前
* 在每个volatile读操作前插入LoadLoad屏障，在读操作后插入LoadStore屏障；

## happens before

参考[Chapter 17. Threads and Locks (oracle.com)](https://docs.oracle.com/javase/specs/jls/se17/html/jls-17.html#jls-17.4.5)

如果第一个操作`happens before`第二个操作，那么前一个操作对后一个操作是可见的

对于两个操作`x, y` 如果`x happens before y`，那么简写为`hb(x, y)`

* 一个线程中如果操作`x`在程序执行顺序上在操作`y`之前，那么` hb(x, y)`
* `object`的构造方法`happens before`其`finalizer`
* 如果操作`x`在时间上和操作`y`具有`sychonized`的关系（这里翻译的不好，我感觉意思是`x`和`y`操作使用了同一个锁对象，然后`x`发生在`y`之前），那么`hb(x, y)`
* 如果具有关系：`hb(x, y)`和`hb(x, z)`，那么有：`hb(x, z)`

更为具体的，明确存在`happens before`的例子：

* 在一个`monitor`上的`unlock`操作一定`happens before`所有的后续的`lock`操作
* 对`volatile`变量的`write`操作`happens before`所有后续的`read`操作
* 线程的`start()`方法的调用`happens before`线程内部的所有操作
* 如果存在一个线程调用了另一个线程的`join()`方法，在该线程不被打断，从而顺利从`join()`方法中获取返回值，那么另一个线程的所有操作`happens before`当前线程的`join()`的返回
* 对于一个对象的默认初始化操作`happens before`其他操作（要注意的是这里的其他操作不包括写）

当程序中出现了冲突的访问的情况（最典型的就是多线程下访问共享变量），并且这些访问不存在`happens before`的关系，那么称其存在`data race`

不过如果存在多个线程访问数组大小，是不会出现`data race`的

# CAS

>   乐观锁的具体实现

有的时候使用`CAS`操作，在不加锁的条件下，就可以实现变量访问的安全性问题，比较高效

## 一个多线程竞争的例子

大家都说，`CAS`是一种乐观锁，而`synchronized`是一种悲观锁

他俩都可以通过锁的形式保证变量更新的原子性，不过既然是多线程访问，那么肯定存在多线程竞争变量的情况，简单举个例子，现在有一个简单的方法：

```java
public class Demo {
    private static int num;
    static {
        num = 0;
    }
    public static void inc() {
        num++;
    }
}
```

现在多个线程需要调用方法`inc()`，了解一点多线程的，基本上都知道，上面的方法调用存在安全性问题，即`inc()`方法不是原子的

那么就可以通过锁的形式保证原子性

对于`synchronized`关键字而言，我直接在方法上添加该关键字就是加锁，不过这将导致同一时间仅有一个线程可以进入这个方法，**而其他所有线程将进入阻塞状态**，方法的执行由并行变为等效的串行，此外由于多线程的上下文切换的开销，此时多线程下执行方法`inc()`效率反倒不如单线程下的执行

而对于`CAS`就不太一样了，它不需要加锁，因此多个线程可以同时进入方法不会出现线程阻塞的情况，多线程下执行方法具有更高的效率，但它还是可以保证线程的安全性

## java中的CAS

下面就具体说以下，因为`CAS`涉及到一些底层的，包括`CPU`指令，`JNI`在内的东西，所以这次并没有参考`stackOverFlow`上的解答；别问，问就是看不懂

主要参考：

* 两篇腾讯云的博客：[Java CAS 原理分析](https://cloud.tencent.com/developer/article/1122595?from=article.detail.1462258)、[Java 的 CAS原理](https://cloud.tencent.com/developer/article/1462258)

  > 我其实感觉这俩其实抄的

* [Java：CAS(乐观锁) ](https://www.jianshu.com/p/ae25eb3cfb5d)

首先要知道的是在`java`中是没有`CAS`的具体实现的，不过在`jdk`的实现中，给出了由内联汇编的形式实现的`CAS`，即`CAS`方法其实是一个`native`的方法，我们使用`CAS`更多的是在于使用`jdk`提供的原子类，比如：`AtomicInteger`，这个类里面的方法的具体实现，调用了`native`的`CAS`方法，实现了原子更新

先说一下`CAS`全名：`compare and swap`，即比较并交换

这里面涉及到三个变量：内存中的变量`V`、期望值`A`、新值`B`

一次`CAS`操作是这样的：

* 将内存中的变量`V`的值和期望值`A`进行比较
* 如果相等，则将新值`B`赋给变量`V`，并返回成功（这里的成功表现在`native`方法的返回值为`true`）
* 如果不相等，则直接返回失败（可以认为`native`方法返回了`false`）

从上面的操作中，我们可以看到，对于`CAS`加锁的变量，一个线程调用方法`inc`并不会导致其他线程阻塞，只不过在多个线程同时进行`CAS`操作时，有些线程会得到`false`的结果，即操作失败了

一次`CAS`操作是原子的，这个不是`java`保证的，这是通过`jdk`源码部分，即汇编代码保证的

以`AtomicInteger`类为例, 从名字上就知道，就是一个对整型类的一个原子性封装，所以本质上就是一个`Integer`

```java
public class AtomicInteger extends Number implements java.io.Serializable {
    
    private static final long serialVersionUID = 6214790243416807050L;
    // 一个 Unsafe 类的一个对象 => 执行 native 方法
    private static final Unsafe U = Unsafe.getUnsafe();
    // 获取当前类中字段 value 的偏移地址
    private static final long VALUE
        = U.objectFieldOffset(AtomicInteger.class, "value");
	// int 类型的 value 本身 (volatile 封装保证可见性)
}
```

具体到对数字操作时, 调用 unsafe 提供的 compareAndSet 实现

```java
public class AtomicInteger extends Number implements java.io.Serializable {
	/**
     * Atomically sets the value to {@code newValue}
     * if the current value {@code == expectedValue},
     * with memory effects as specified by {@link VarHandle#compareAndSet}.
     *
     * @param expectedValue the expected value
     * @param newValue the new value
     * @return {@code true} if successful. False return indicates that
     * the actual value was not equal to the expected value.
     */
    public final boolean compareAndSet(int expectedValue, int newValue) {
        return U.compareAndSetInt(this, VALUE, expectedValue, newValue);
    }
}
```

根据参数类型大概也能知道, 对当前对象的某个偏移地址进行 int 类型的 CAS 操作

```java
/**
 * Atomically updates Java variable to {@code x} if it is currently
 * holding {@code expected}.
 *
 * <p>This operation has memory semantics of a {@code volatile} read
 * and write.  Corresponds to C11 atomic_compare_exchange_strong.
 *
 * @return {@code true} if successful
 */
@HotSpotIntrinsicCandidate
public final native boolean compareAndSetInt(Object o, long offset, int expected, int x);
```

直接调用了`native`方法，看不到了

## 汇编中的CAS

在此之前，插一句，在底层，处理器这个级别的，可以保证读写的原子性，而对于处理器而言执行多条指令是不能保证原子性的，比如汇编指令`inc`在处理器级别就是先读，再计算，最后写回，一共包含了三条指令，假如我们考虑的是两个核心，同时对内存中的变量进行`inc`操作，也可能出现变量安全性问题；

那些设计人员肯定是注意到了这个问题的，所以他们的解决方式是想办法，避免让多个核心同时操作相同的一片内存空间；所以他们在设计的时候，引入了`lock`前缀，只要在指令前面加入`lock`前缀就可以保证访问变量的安全性

> 在一条汇编指令前加入`lock`前缀，即使这一条汇编指令相当于处理器的多个指令，那么处理器在执行这多个指令时也是原子的
>
> 顺带提一嘴，具体的`lock`实现，是当处理器读取到带有`lock`前缀的指令后，会发出`LOCK#`信号，锁定处理器核心缓存区中的对应变量

中间拿着`this`、`VALUE`如何取操作的这里就不管了，这里变为了三个参数，一个是新值`exchange_value`、一个是内存中的地址`dest`、一个是我们的期望值`campare_value`

```c
inline jint Atomic::cmpxchg (jint exchange_value, volatile jint* dest, jint compare_value) {  
   // 判断是否是多核 CPU
  int mp = os::is_MP();
  // 将参数值放入寄存器中
  __asm {    
    // 注意: dest 是指针类型，这里是把内存地址存入 edx 寄存器中
    mov edx, dest    
    mov ecx, exchange_value
    mov eax, compare_value    
    // LOCK_IF_MP
    cmp mp, 0
    /*
     * 如果 mp = 0，表明是线程运行在单核 CPU 环境下。此时 je 会跳转到 L0 标记处，
     * 也就是越过 _emit 0xF0 指令，直接执行 cmpxchg 指令。也就是不在下面的 cmpxchg 指令前加 lock 前缀。
     * 毕竟对于单核来讲，也不会出现
     */
    je L0    
    /*
     * 0xF0 是 lock 前缀的机器码，这里没有使用 lock，而是直接使用了机器码的形式。
     */ 
    _emit 0xF0L0:    
    /*
     * 比较并交换。简单解释一下下面这条指令，熟悉汇编的朋友可以略过下面的解释:
     *   cmpxchg: 即“比较并交换”指令
     *   dword: 全称是 double word，在 x86/x64 体系中，一个 
     *          word = 2 byte，dword = 4 byte = 32 bit
     *   ptr: 全称是 pointer，与前面的 dword 连起来使用，表明访问的内存单元是一个双字单元
     *   [edx]: [...] 表示一个内存单元，edx 是寄存器，dest 指针值存放在 edx 中。
     *          那么 [edx] 表示内存地址为 dest 的内存单元
     *          
     * 这一条指令的意思就是，将 eax 寄存器中的值（compare_value）与 [edx] 双字内存单元中的值
     * 进行对比，如果相同，则将 ecx 寄存器中的值（exchange_value）存入 [edx] 内存单元中。
     */
    cmpxchg dword ptr [edx], ecx
  }
}
```

## ABA问题

上面其实一直回避了一个问题，即期望值`A`是怎么设置的，回到最开始的方法`compareAndSet`发现它的参数列表中已经包含了期望值，而更为一般的情况下，以`inc`举例，我们需要先从内存中获取到原来的值作为期望值，然后进行比较交换并写回（CAS）

所以完全有可能出现下面的情况：

两个线程的情况下，假设分别叫线程`1`，`2`

两个同时获取到了原来的值作为期望值`A`

其中线程`1`放弃了调度，而线程`2`以期望值`A`，新值`B`，进行了`CAS`操作，结果显然成功了

随后程序运行到下一阶段，线程`2`再次从内存中获取到期望值`B`，并以新值`A`，再进行一次`CAS`操作，而此时因为线程`1`依旧没有进行调度，所以线程`2`又执行成功了

即线程`2`将变量从`A`修改为`B`后，后将其修改回`A`

随后线程`1`被唤醒，而线程`2`放弃了调度，线程`1`再次将变量修改为`B`

上面的场景称为ABA问题

如果直接看的话，好像觉得没什么问题，但如果我们考虑这样一个场景：两个线程同时对`num`执行操作，最开始执行加法操作，而当`num`达到一次`10`后，开始执行减法操作：

```java
public class Demo{
    private volatile boolean flag;
    private AtomicInteger num;
    
    static{
        flag = false;
        num = new AtomicInteger(0);
    }
    
    public static void operate() {
        if (!flag) {
            num.getAndIncrement();
            if (num == 10) flag = true;
        }else {
            num.getAndDecrement();
        }
    }
}
```

那么假如现在`num`的`value`为9，两个线程进来了，并按照上面`ABA`问题的描述执行程序，那么线程`2`先将`num`修改为`10`，随后标识`flag`为`true`，并再次进行`CAS`将`10`修改为9，而线程`1`不能及时意识到`flag`已经变为`true`了，他会在醒来之后直接进行`CAS`，并执行成功，将变量从`9`修改为`10`

更具体的: 如果变量 V 在第一次读取的时候发现是 A, 那么此时并不能说明当前变量没有被其他线程修改过, 但是 CAS 会无脑认为此时变量是没有被修改过的状态

解决办法：在变量前面追加版本号：每次变量更新就把版本号加1，则A-B-A就变成1A-2B-3A；`AtomicStampedReference`类实现了这种版本号控制：其compareAndSet方法首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用的该标志的值设置为给定的更新值。

## 总结一下

首先要明确的是`CAS`操作是属于汇编层面的，其原子性是处理器本身解决的，所以调用`java`封装之后的方法，不需要加锁。

> 而实际在处理器的层面，看到了，其本身还是使用了`#LOCK`信号进行了加锁

使用`java`封装好的原子类进行操作的一般流程是：（这里以`AtmoicInteger`举例）

```java
private AtomicInteger value;
public void multiThreadSet(int ops) {
    while (true) {
        int pre = value.get();
    	int newVal = // 这里是将pre和ops进行一堆复杂的运算得到一个新的结果
        if (value.compareAndSet(pre, newVal)) break;
    }
}
```

使用`CAS`对变量进行赋值时，不断自旋，直到赋值成功

> 当然，在不考虑方法调用次数时，完全可以不考虑赋值操作是否可以成功，就算失败也返回

使用`CAS`操作离不开原子类，原子类本身就是对变量的一个封装，且变量作为成员变量使用了`volatile`进行修饰保证了每次调用`value.get()`的时候可以获取到最新的值

`CAS`相比于加锁操作效率更高，这主要是因为`CAS`操作不会出现线程阻塞的情况，一旦发生了线程阻塞，将引入额外的线程切换的开销（这里假设因为处理器调用产生的上下文的开销是一样的）。但这其实并不全面，在线程竞争激烈的情况下，`CAS`操作可能一直失败，从而一直重试。特别的根据线程数和处理器核心的个数的关系，可以分为两个场景：如果线程数小于核心数，使用加锁的操作，将导致同一时间只有一个线程（核心）可以进行操作，效率确实低；但使用`CAS`，如果发生了失败，不会导致线程阻塞，而仅仅发生重试，效率更高；但当线程数变多时，`CAS`操作失败的次数大大增加，白白浪费了处理器资源

## CAS工具类

位于：`java.util.concurrent.atomic`

主要是：原子整数、原子引用、原子数组、字段更新器、原子累加器

### 原子整数

主要包括了`AtomicInteger`、`AtomicBoolean`、`AtomicLong`

> 这里如果看源码的话`AtomicBoolean`内部封装的是一个`int`类型的值：
>
> ```java
> // 它的get方法是判断value是不是0
> public final boolean get() {
>     return value != 0;
> }
> ```

`AtomicInteger`：

* 类似于`i++`：`getAndIncrement`、类似于`++i`：`incrementAndGet`，这两个可以保证`i++`和`++i`是原子的

* 自增量更大：`addAndGet`、`getAndAdd`，和上面类似，都可以保证加法的原子性

  > 参数可以是负数，实现了`Integer`的加减的原子性

* `updateAndGet`、`getAndUpdate`：参数类型为`IntUnaryOperator`，这是一个函数式接口（仅包含了一个抽象方法，不过它内部有一些默认的方法）

  ```java
  @FunctionalInterface
  // 整形的一元的操作符（直接翻译的话）
  public interface IntUnaryOperator {
  
      /**
       * Applies this operator to the given operand.
       * @param operand the operand
       * @return the operator result
       * 给定一个操作数，返回对应的映射值
       */
      int applyAsInt(int operand);
  }
  ```

  简单来说可以这样：

  ```java
  @Test
  public void test() {
      AtomicInteger val = new AtomicInteger(10);
      System.out.println(val.updateAndGet(num -> num * 10)); // 输出100
  }
  ```

  使用了这个`IntUnaryOperator`接口后可以进行任意的整数计算，并且可以保证原子性（其实就是`CAS`不断自旋尝试）

  现在看一下源码：他这个设计简直绝了

  ```java
  // 这个是jdk17里的实现 
  public final int getAndUpdate(IntUnaryOperator updateFunction) {
       int prev = get(), next = 0;
       for (boolean haveNext = false;;) {
           if (!haveNext)
               next = updateFunction.applyAsInt(prev);
           // 如果CAS操作成功了，就返回
           if (weakCompareAndSetVolatile(prev, next))
               return prev;
           // 如果没成功，那么就计算当前的输入是否发生了改变，如果没变，下次就不需要再进行operator的操作了
           haveNext = (prev == (prev = get()));
       }
   }
  ```

### 原子引用类型

主要是`AtomicReference<V>`、`AtomicStampedReference<V>`、`AtomicMarkableReference<V>`，引用类型适用性更广

> 后面这两个主要解决的是`ABA`问题

这里主要使用的还是`compareAndSet`，不过更加通用的还是`updateAndGet`和`getAndUpdate()`这两个方法需要的参数是：`UnaryOperator`也是一个函数式接口

```java
public final V updateAndGet(UnaryOperator<V> updateFunction) {
    V prev = get(), next = null;
    for (boolean haveNext = false;;) {
        if (!haveNext)
            next = updateFunction.apply(prev);
        if (weakCompareAndSetVolatile(prev, next))
            return next;
        haveNext = (prev == (prev = get()));
    }
}
```

这个方法的实现和`AtomicInteger`中只能说是完全一致

> 个人感觉，那个`AtomicInteger`完全可以继承于`AtomicReference`

使用`AtomicStampedReference<V>`可以解决`ABA`问题，因为其在进行操作时，添加了`stamp`，引入了戳的概念，用来标识每一次的更新。

在`new`对象的时候同样也需要添加版本号，这个类仅有一个构造方法：

```java
public class AtomicStampedReference<V> {

    private static class Pair<T> {
        final T reference;
        final int stamp;
        private Pair(T reference, int stamp) {
            this.reference = reference;
            this.stamp = stamp;
        }
        static <T> Pair<T> of(T reference, int stamp) {
            return new Pair<T>(reference, stamp);
        }
    }

    private volatile Pair<V> pair;

    /**
     * Creates a new {@code AtomicStampedReference} with the given
     * initial values.
     *
     * @param initialRef the initial reference
     * @param initialStamp the initial stamp
     */
    public AtomicStampedReference(V initialRef, int initialStamp) {
        pair = Pair.of(initialRef, initialStamp);
    }
    ...
}
```

可以看到其内部使用了内部类`Pair`保存引用的取值和`stamp`

在更新时：

```java
/**
 * Atomically sets the value of both the reference and stamp
 * to the given update values if the
 * current reference is {@code ==} to the expected reference
 * and the current stamp is equal to the expected stamp.
 *
 * @param expectedReference the expected value of the reference
 * @param newReference the new value for the reference
 * @param expectedStamp the expected value of the stamp
 * @param newStamp the new value for the stamp
 * @return {@code true} if successful
 */
public boolean compareAndSet(V   expectedReference,
                             V   newReference,
                             int expectedStamp,
                             int newStamp) {
    Pair<V> current = pair;
    /**
     * 它要求stamp和value都和已经存储的一样
     * 并且进行了优化，如果新值和新版本号和已经存储的一样，就直接返回
     * 仅在预期值和stamp和当前值相同，且更新值和新stamp和当前值不同时进行cas操作
     */
    return
        expectedReference == current.reference &&
        expectedStamp == current.stamp &&
        ((newReference == current.reference &&
          newStamp == current.stamp) ||
         casPair(current, Pair.of(newReference, newStamp)));
}
// 这里引入了一个新类VarHandle（其实是接口）
private static final VarHandle PAIR;
static {
	// 这里主要是对PAIR的赋值操作，这里不讨论了
}
// 在jdk8的时候这里也只是简单的调用了Unsafe类的compareAndSwapObject
private boolean casPair(Pair<V> cmp, Pair<V> val) {
    return PAIR.compareAndSet(this, cmp, val);
}
```

在`AtomicStampedReference<V>`中使用了`int`类型记录了`stamp`，但其实有的时候并不需要这么精确，比如还是之前的`ABA`问题，一个线程是加还是减主要取决于有没有到达过10，所以我们其实主要关系的并不是每次更改的先后`stamp`，而是在进行这次更改前，共享变量有没有到达过10，此时可以使用`AtomicMarkedReference<V>`

```java
public class AtomicMarkableReference<V> {
	
    // 可以看到这里pair里的"stamp"的类型为boolean
    private static class Pair<T> {
        final T reference;
        final boolean mark;
        private Pair(T reference, boolean mark) {
            this.reference = reference;
            this.mark = mark;
        }
        static <T> Pair<T> of(T reference, boolean mark) {
            return new Pair<T>(reference, mark);
        }
    }

    private volatile Pair<V> pair;
	...
}
```

### 原子数组

主要是`AtmoicIntegerArray`、`AtomicLongArray`和`AtomicReferenceArray`

这里以更加通用的`AtomicReferenceArray`为例：

```java
public class AtomicReferenceArray<E> implements java.io.Serializable {
    private static final long serialVersionUID = -6209656149925076980L;
    private static final VarHandle AA
        = MethodHandles.arrayElementVarHandle(Object[].class);
    @SuppressWarnings("serial") // Conditionally serializable
    private final Object[] array; // must have exact type Object[]

    /**
     * Creates a new AtomicReferenceArray of the given length, with all
     * elements initially null.
     *
     * @param length the length of the array
     */
    public AtomicReferenceArray(int length) {
        array = new Object[length];
    }

    /**
     * Creates a new AtomicReferenceArray with the same length as, and
     * all elements copied from, the given array.
     *
     * @param array the array to copy elements from
     * @throws NullPointerException if array is null
     */
    public AtomicReferenceArray(E[] array) {
        // Visibility guaranteed by final field guarantees
        this.array = Arrays.copyOf(array, array.length, Object[].class);
    }
}
```

可以看到，这里内部存储的结构是`Object`类型的数组，默认存在两个构造方法，一个是长度的构造方法，还有一个是将普通的数组转化为原子数组

基本的方法比如：`length()`获取长度、`get(int idx)`获取对应下标的值、`set(int idx, E newValue)`为下标设置新值

不过最通用的方法还是`updateAndGet()`

```java
 /**
    * Atomically updates (with memory effects as specified by {@link
 * VarHandle#compareAndSet}) the element at index {@code i} with
 * the results of applying the given function, returning the
 * updated value. The function should be side-effect-free, since it
 * may be re-applied when attempted updates fail due to contention
 * among threads.
 *
 * @param i the index
 * @param updateFunction a side-effect-free function
 * @return the updated value
 * @since 1.8
 */
public final E updateAndGet(int i, UnaryOperator<E> updateFunction) {
    E prev = get(i), next = null;
    for (boolean haveNext = false;;) {
        if (!haveNext)
            next = updateFunction.apply(prev);
        if (weakCompareAndSetVolatile(i, prev, next))
            return next;
        haveNext = (prev == (prev = get(i)));
    }
}
```

### 字段更新器

带有后缀`Updater`的：`AtomicReferenceFieldUpdater`、`AtomicIntegerFieldUpdater`、`AtomicLongFieldUpdater`

字段更新器可以保护成员变量的安全性

要使用字段更新器，需要调用其静态方法获取对象：

```java
/**
 * Creates and returns an updater for objects with the given field.
 * The Class arguments are needed to check that reflective types and
 * generic types match.
 * 因为是通过反射获取成员变量，成员变量不能是private，且需要明确类名、成员变量的类型、名称
 * @param tclass the class of the objects holding the field 类.class
 * @param vclass the class of the field 成员变量的类型.class
 * @param fieldName the name of the field to be updated 成员变量名
 * @param <U> the type of instances of tclass 类名
 * @param <W> the type of instances of vclass 成员变量类型名
 * @return the updater
 * @throws ClassCastException if the field is of the wrong type 成员变量类型错了会抛异常
 * @throws IllegalArgumentException if the field is not volatile 成员变量不是volatile会抛异常
 * @throws RuntimeException with a nested reflection-based 其他的异常
 * exception if the class does not hold field or is the wrong type,
 * or the field is inaccessible to the caller according to Java language
 * access control
 */
@CallerSensitive
public static <U,W> AtomicReferenceFieldUpdater<U,W> newUpdater(Class<U> tclass,
                                                                Class<W> vclass,
                                                                String fieldName) {
    return new AtomicReferenceFieldUpdaterImpl<U,W>
        (tclass, vclass, fieldName, Reflection.getCallerClass());
}
```

好吧，其实使用字段更新器限制挺多的：

- 字段必须是volatile类型的，用于保证可见性。
- 字段和字段更新器的访问类型(public/protected/private)必须一致。
- 字段只能是实例变量，不能是类变量(static)。
- 字段不能是final的变量，这样的字段不可修改。
- 如果要处理Integer和Long类型，则需要使用`AtomicIntegerFieldUpdater`和`AtomicLongFieldUpdater`

其实感觉这个字段更新器还挺鸡肋的，如果我希望成员变量的原子更新，为什么不使用原子类直接封装，而使用字段更新器，在 stackoverflow 上找到了答案[java - AtomicReference vs AtomicReferenceFieldUpdater, what's a purpose of AtomicReferenceFieldUpdater? - Stack Overflow](https://stackoverflow.com/questions/52687051/atomicreference-vs-atomicreferencefieldupdater-whats-a-purpose-of-atomicrefere) 主要目的就是为了节省内存

它给出的例子来自于源码：

```java
 class Node {    
     private volatile Node left, right;      
     private static final AtomicReferenceFieldUpdater<Node, Node> leftUpdater =      AtomicReferenceFieldUpdater.newUpdater(Node.class, Node.class, "left");    
     private static AtomicReferenceFieldUpdater<Node, Node> rightUpdater =      AtomicReferenceFieldUpdater.newUpdater(Node.class, Node.class, "right");      
     
     Node getLeft() { 
         return left; 
     }    
     boolean compareAndSetLeft(Node expect, Node update) {      
         return leftUpdater.compareAndSet(this, expect, update);    
     }    
     // ... and so on  
 }
```

在 Node 类中有两个字段 left 和 right 现在需要原子的更新他们，只需要使用 volatile 进行修饰，然后再定义两个字段更新器，注意这两个字段更新器是由 static final 修饰的，即为常量

> 这里注意它这个 rightUpdater 没有使用 final 修饰，源码里就是这样的

如果不使用字段更新器，需要使用 `AtomicReference<Node>` 进行修饰，相比于单独的 Node 需要更多的内存开销

### 原子累加器

`LongAdder`、`LongAccumulator`、`DoubleAdder`、`DoubleAccumulator`

> `LongAccumulator`可以认为是`LongAdder`的增强，它可以进行任意的运算，而`LongAdder`主要进行的是加法
>
> `DoubleAdder`其实使用了`long`类型的字段存储了`double`类型的变量：
>
> ```java
>     /**
>      * Adds the given value.
>      *
>      * @param x the value to add
>      */
>     public void add(double x) {
>         Cell[] cs; long b, v; int m; Cell c;
>         // 注意这里进行了doubleToRawLongBits，为将double转化为long用作存储
>         // 而longBitsToDouble是将long类型转换为double类型
>         if ((cs = cells) != null ||
>             !casBase(b = base,
>                      Double.doubleToRawLongBits
>                      (Double.longBitsToDouble(b) + x))) {
>             int index = getProbe();
>             boolean uncontended = true;
>             if (cs == null || (m = cs.length - 1) < 0 ||
>                 (c = cs[index & m]) == null ||
>                 !(uncontended = c.cas(v = c.value,
>                                       Double.doubleToRawLongBits
>                                       (Double.longBitsToDouble(v) + x))))
>                 doubleAccumulate(x, null, uncontended, index);
>         }
>     }
> 
> ```

相比于`AtomicLong`，`LongAdder`累加的性能更强；`LongAdder`内部的优化其实很好说，它使用了多个累加单元，这样将线程分配到不同的累加单元，大大减低`CAS`自旋的次数，提升性能，而在求值的时候将所有累加单元求和，得到正确结果

这几个类都继承了`Striped64`这个类，其中几个关键的成员变量：

```java
    /** Number of CPUS, to place bound on table size 就是处理器的个数*/
    static final int NCPU = Runtime.getRuntime().availableProcessors();

    /**
     * Table of cells. When non-null, size is a power of 2.
     * 累加单元的个数，累加单元的个数为2的指数，且不会超过处理器的个数
     */
    transient volatile Cell[] cells;

    /**
     * Base value, used mainly when there is no contention, but also as
     * a fallback during table initialization races. Updated via CAS.
     * 在没有竞争时，将使用base进行累加
     */
    transient volatile long base;
	/**
     * Spinlock (locked via CAS) used when resizing and/or creating Cells.
     * 当cell进行扩容时，使用CAS进行加锁，将cellBusy写为1，扩容结束时再写回0
     */
    transient volatile int cellsBusy;
```

这里先看一下累加单元`Cell`的实现：

```java
@jdk.internal.vm.annotation.Contended 
static final class Cell {
    volatile long value;
    Cell(long x) { value = x; }
    final boolean cas(long cmp, long val) {
        return VALUE.weakCompareAndSetRelease(this, cmp, val);
    }
    final void reset() {
        VALUE.setVolatile(this, 0L);
    }
    final void reset(long identity) {
        VALUE.setVolatile(this, identity);
    }
    final long getAndSet(long val) {
        return (long)VALUE.getAndSet(this, val);
    }

    // VarHandle mechanics
    private static final VarHandle VALUE;
    // 下面是对VarHandle的初始化操作
}
```

这个累加单元本身的实现是比较简单的，就是保存了一个value，然后使用`CAS`进行更新

这里面唯一需要注意的是注解`@Contended`，这个注解是为了防止缓存行伪共享

> 这里涉及到处理器缓存失效的问题，简单来说，因为这里认为使用不同的线程 -> 不同的处理器，因为每个`Cell`大小约为24Bytes（16Bytes的对象头，加上long类型成员变量8Bytes），而根据程序的空间局部性，可知，一次缓存读取的`Block`中可能包含了多个`Cell`。
>
> 当处理器的某个核心进行了修改数据的操作，将导致其他核心缓存的`Block`中的数据失效。所以可能出现当一个核心更新了`Cell[0]`，使得`Cell[1]`失效。从而第二个核心需要重新从内存中获取最新的数据，从而增加了时延开销。
>
> 所以这个`@Contented`注解，会在每个`Cell`对象的前后各添加`128Bytes`的`Padding`，保证每个`Cell`在位于不同的`Block`中，从而一个核心更新的数据，不会使得其他`Cell`所在的`Block`中的数据失效
>
> 称，一个`Block`中具有多个`Cell`的情况为缓存行伪共享，而`@Content`因为添加了`Padding`，避免了伪共享

#### 扒一下源码

##### add(long x)

现在回到`LongAdder`，看一下其具体的增加操作的实现：

```java
/**
 * Adds the given value.
 *
 * @param x the value to add
 */
public void add(long x) {
    Cell[] cs; long b, v; int m; Cell c;
    if ((cs = cells) != null || !casBase(b = base, b + x)) {
        int index = getProbe();
        boolean uncontended = true;
        if (cs == null || (m = cs.length - 1) < 0 ||
            (c = cs[index & m]) == null ||
            !(uncontended = c.cas(v = c.value, v + x)))
            longAccumulate(x, null, uncontended, index);
    }
}
```

看起来十分复杂：首先要知道的是`longAccumulate`方法，是用来初始化（扩容）`Cell`数组的；而默认的`Cell`数组是懒加载的，即只有出现了线程冲突才进行加载。

所以默认的，`LongAdder`中只有一个base，用来存储value

它这个判断，首先判断`Cell`数组是否已经创建了：

* 如果没有创建，就使用base进行`CAS`更新操作，如果更新失败，认为出现了竞争，从而进入`if`条件分支
* 而如果`Cell`数组已经创建了，就使用`Cell`数组更新取值，直接进入`if`条件分支，所以只要`Cell`数组完成了初始化，就不再使用`base`更新了

进入内层的`if`分支后，首先会调用`getProbe()`方法，这个方法是用来获取当前线程对应`Cell`数组中的位置的。

> 进入内层`if`分支，有两种可能，一种是`Cell`已经完成过一次初始化、一种是使用`base`更新，但出现了竞争

内层`if`分支进入判断：

* 如果`Cell`数组为空，说明未完成初始化，直接进入方法`longAccumulate`
* 如果数组不为空，需要继续判断当前线程对应的`Cell`数组中的位置是否完成初始化，如果没有的话也会进入方法`longAccumulate`
* 如果当前`Cell`不为空，那么针对当前线程对应的`Cell`进行`CAS`操作，如果更新失败，认为出现了竞争，需要进行`Cell`数组扩容，从而进入方法`longAccumulate`

> 进入最内层的`if`分支，并调用方法`longAccumulate`一共有三种情况：`Cell`数组尚未完成初始化、`Cell`数组中当前线程对应的位置未完成初始化、当前线程对应的`cell`进行`cas`更新失败，出现竞争，需要进行扩容

现在，知道了方法`longAccumulate`主要是用于初始化，包括`Cell`数组本身和`Cell`数组中的对应位置和`Cell`数组扩容的，所以现在重点在于`longAccumulate`

##### longAccumulate()

```java
/**
 * Handles cases of updates involving initialization, resizing,
 * creating new Cells, and/or contention. See above for
 * explanation. This method suffers the usual non-modularity
 * problems of optimistic retry code, relying on rechecked sets of
 * reads.
 *
 * @param x the value
 * @param fn the update function, or null for add (this convention
 * avoids the need for an extra field or function in LongAdder).
 * @param wasUncontended false if CAS failed before call
 * @param index thread index from getProbe
 */
final void longAccumulate(long x, LongBinaryOperator fn,
                          boolean wasUncontended, int index) {
    if (index == 0) {
        ThreadLocalRandom.current(); // force initialization
        index = getProbe();
        wasUncontended = true;
    }
    for (boolean collide = false;;) {       // True if last slot nonempty
        Cell[] cs; Cell c; int n; long v;
        if ((cs = cells) != null && (n = cs.length) > 0) {
            if ((c = cs[(n - 1) & index]) == null) {
                if (cellsBusy == 0) {       // Try to attach new Cell
                    Cell r = new Cell(x);   // Optimistically create
                    if (cellsBusy == 0 && casCellsBusy()) {
                        try {               // Recheck under lock
                            Cell[] rs; int m, j;
                            if ((rs = cells) != null &&
                                (m = rs.length) > 0 &&
                                rs[j = (m - 1) & index] == null) {
                                rs[j] = r;
                                break;
                            }
                        } finally {
                            cellsBusy = 0;
                        }
                        continue;           // Slot is now non-empty
                    }
                }
                collide = false;
            }
            else if (!wasUncontended)       // CAS already known to fail
                wasUncontended = true;      // Continue after rehash
            else if (c.cas(v = c.value,
                           (fn == null) ? v + x : fn.applyAsLong(v, x)))
                break;
            else if (n >= NCPU || cells != cs)
                collide = false;            // At max size or stale
            else if (!collide)
                collide = true;
            else if (cellsBusy == 0 && casCellsBusy()) {
                try {
                    if (cells == cs)        // Expand table unless stale
                        cells = Arrays.copyOf(cs, n << 1);
                } finally {
                    cellsBusy = 0;
                }
                collide = false;
                continue;                   // Retry with expanded table
            }
            index = advanceProbe(index);
        }
        else if (cellsBusy == 0 && cells == cs && casCellsBusy()) {
            try {                           // Initialize table
                if (cells == cs) {
                    Cell[] rs = new Cell[2];
                    rs[index & 1] = new Cell(x);
                    cells = rs;
                    break;
                }
            } finally {
                cellsBusy = 0;
            }
        }
        // Fall back on using base
        else if (casBase(v = base,
                         (fn == null) ? v + x : fn.applyAsLong(v, x)))
            break;
    }
}
```

这个量确实太大了，主要分为两部分，首先第一部分`if`判断，判断当前的`index`，即当前线程对应的位置是不是0如果是0的话重新获得一个位置；第二部分就是一个for死循环，所有的出口都是`break`出来的，所以重点的初始化和扩容的操作都在第二部分中。

为了简化冗长的for死循环，可以将其简化，这个for循环的主要逻辑是这样的：

```java
for (boolean collide = false;;) {       // True if last slot nonempty
    Cell[] cs; Cell c; int n; long v;
    if ((cs = cells) != null && (n = cs.length) > 0){
        // 进行一堆操作
    } else if (cellsBusy == 0 && cells == cs && casCellsBusy()) {
        // 进行一堆操作
    } else if (casBase(v = base,
                             (fn == null) ? v + x : fn.applyAsLong(v, x)))
                break;
}
// 虽然，但是比上面的一堆if稍微好了一点    
```

首先第一个判断，如果当前的`Cell`数组不为空，将进入第一个分支。这个主要是`cell`不为空，但是当前线程对应的数组中的位置尚未完成初始化（或者是需要进行扩容）

要注意，进入第二个判断的前提条件是当前的`Cell`数组尚未完成初始化：

* 首先判断`cellsBusy`是不是0，这个`cellsBusy`其实就是之前的自旋锁，当进行初始化，扩容的时候`cellsBusy`将变为1

* 然后判断`cells == cs`，这个是判断是否已经有线程，进入这个循环完成了创建，并完成了解锁，如果完成了创建，那么`cs`为null而`cells`不为`null`

  > 个人感觉这个判断是很严谨的，因为条件判断和加锁两个操作是非原子的
  >
  > 所以如果没有这个判断，那么会出现情况：
  >
  > * 第一个线程进入判断，`cellsBusy`为0，然后放弃调度
  > * 第二线程进行判断，`cellsBusy`为0，然后加锁，并完成初始化，最后解锁，然后放弃调度
  > * 第一个线程唤醒，如果没有这个判断，那么它将再进行一次初始化操作

* 注意到`casCellsBusy`就是对前面的自旋锁进行加锁的操作，如果加锁成功将进入条件分支

要注意，进入第三个判断的前提是当前`Cell`数组未完成初始化，并且已经存在了其他线程进行初始化操作

> 当前线程也想要进行`Cell`数组初始化，只不过没有竞争过而已

最后一个判断其实是对`base`进行了`cas`操作：

* 如果成功了，将直接跳出死循环，注意到这里的`cas`操作是和传入的参数`LongBinaryOperator`有关的，如果这个参数不为空，将按照这个函数式接口对应的方式进行运算，否则直接在当前的`base`上添加传入的参数`x`
* 如果失败了，将再进入一次for循环

上面一共折叠了两个`if`条件，从代码量的角度考虑，还是第二个`if`的代码量更少一点，所以这里先说明第二个`if`，这个分支的主要作用是初始化`Cell`数组

```java
else if (cellsBusy == 0 && cells == cs && casCellsBusy()) {
    try {     // Initialize table
        if (cells == cs) {
            Cell[] rs = new Cell[2];
            rs[index & 1] = new Cell(x);
            cells = rs;
            break;
        }
    } finally {
        cellsBusy = 0;
    }
}
```

在这个分支中，首先再次确认`cells == cs`，即当前的`Cell`数组的引用和`cs`都是`null`

> 这个再次判断真的很细，它杜绝了一种情况：
>
> * 第一个线程进入`if`分支，然后判断`cellsBusy`为0，然后`cells == cs`，然后放弃调度
> * 第二个线程和第一个线程一样，只不过完成了加锁操作，完成了初始化，并解锁，最后离开分支，然后放弃调度
> * 第一个线程醒来，然后进行加锁成功，如果在这个分支内部不再做一次判断，那么第一个线程将再次进行初始化操作，使得第二个线程初始化的结果丢失

然后默认的`new`了一个大小为`2`的`Cell`数组，并将初始化当前线程对应的位置，这里把参数`x`作为`Cell`的初始值

第一个`if`分支的情况为`Cell`数组已经完成创建，而线程对应的累加单元尚未创建，可以看到这里面还是比较复杂的

```java
if ((cs = cells) != null && (n = cs.length) > 0) {
    // 这个 if 判断的是当前Cell数组存在，而当前线程对应数组中的位置不存在
    if ((c = cs[(n - 1) & index]) == null) {
        // 一堆操作
        /*
        	进入下面的分支的前提是，当前Cells数组存在，且当前线程对应的位置不是null
        	下面的这个if 没什么意义，因为默认我们传入的就是false，一定会落入这个if分支
        	所以其实就是把参数从false变为了true，不过后面还需要再进一次循环
        */
    } else if (!wasUncontended)       // CAS already known to fail
        wasUncontended = true;      // Continue after rehash
    // 这里的分支其实就是正常的CAS操作，如果操作成功，将直接返回，
    // 注意到为了操作的通用性，这里使用了函数式接口LongBinaryOperator
    else if (c.cas(v = c.value,
                   (fn == null) ? v + x : fn.applyAsLong(v, x)))
        break;
    /* 
    	这里是检查当前Cell数组的大小是不是已经大于了处理器核心的个数
    	如果已经到达阈值了，就不进行后面的扩容逻辑了
    */ 
    else if (n >= NCPU || cells != cs)
        collide = false;            // At max size or stale
    /*
    	注意到最后的一个if分支内部即为扩容操作
    	要想进入最后一个分支，那么变量collide必须为true
    	所以这里扩容是很谨慎的，第一次需要扩容并不会马上进行，而是需要将再循环一次
    */
    else if (!collide)
        collide = true;
    else if (cellsBusy == 0 && casCellsBusy()) {
        // 一堆操作
    }
    // 注意这个操作，它相当于改变当前线程对应的Cell数组中的位置，通过一种伪随机的方式进行
    index = advanceProbe(index);
}   
```

上面的第一个条件分支的内部长这样，这个分支是用来初始化当前线程对应Cell数组中位置的：

```java
// 这个分支容易顺，但是不容易想明白
if ((c = cs[(n - 1) & index]) == null) {
    /*
    	在其他线程没有进行更新Cell数组时，当前线程对当前位置进行初始化操作
    	注意到cellsBusy的意义，当其为1，表示当前存在线程对Cell数组进行初始化、扩容的操作
    */
    if (cellsBusy == 0) {       // Try to attach new Cell
        // 这里注意他是新建Cell 对象，然后在考虑加锁，就是它下面标注的 Optimistically create
        Cell r = new Cell(x);   // Optimistically create
        // 这里尝试加锁，如果加锁失败则进入下一次循环
        if (cellsBusy == 0 && casCellsBusy()) {
            try {               // Recheck under lock
                Cell[] rs; int m, j;
                /*
                    这里二次判断主要是为了防止其他线程已经完成了对象的创建
                    从而导致Cell对象重复创建，而使得第一次创建的结果丢失
                    举例来说，流程如下：
                    * 第一个线程进入上面的if判断cellBusy == 0，然后放弃调度
                    * 第二个线程进入if判断，并加锁进行对象的创建，并解锁离开，然后放弃调度
                    * 第一个线程加锁成功，进入判断，如果没有下面的判断，那么重复创建的Cell对象将覆盖掉第一次的结果
                */
                if ((rs = cells) != null &&
                    (m = rs.length) > 0 &&
                    rs[j = (m - 1) & index] == null) {
                    rs[j] = r;
                    break;
                }
            } finally {
                cellsBusy = 0;
            }
            // 注意这里，其实就是为了应对之前提到的重复创建的情况，此时解锁后，应该让第一个线程再进行一次循环
            continue;           // Slot is now non-empty
        }
    }
    collide = false;
} else ...
```

上面的第二个条件分支就是扩容的操作：

```java
// 注意到这里也是判断自旋锁cellsBusy是否为0，在为0的基础上进行加锁操作
else if (cellsBusy == 0 && casCellsBusy()) {
    try {
        
        if (cells == cs)        // Expand table unless stale
            cells = Arrays.copyOf(cs, n << 1);
    } finally {
        cellsBusy = 0;
    }
    collide = false;
    continue;                   // Retry with expanded table
}
index = advanceProbe(index);
```

##### sum()

这个其实就是最终从`LongAdder`中获取值的函数：

```java
/**
 * Returns the current sum.  The returned value is <em>NOT</em> an
 * atomic snapshot; invocation in the absence of concurrent
 * updates returns an accurate result, but concurrent updates that
 * occur while the sum is being calculated might not be
 * incorporated.
 *
 * @return the sum
 */
public long sum() {
    Cell[] cs = cells;
    long sum = base;
    if (cs != null) {
        for (Cell c : cs)
            if (c != null)
                sum += c.value;
    }
    return sum;
}
```

从方法的具体实现上，可以看出来，如果有的线程进行累加，而别的线程还在运算，那么将得到错误的结果

> 注释里面也写了，因为这个方法不是原子的

## spin lock

通过 CAS 实现的最简单的锁应该就是自选锁了

```java
class SpinLock {
    private final AtomicReference<Thread> owner = new AtomicReference<>();

    public void lock() {
        Thread current = Thread.currentThread();
        while (!owner.compareAndSet(null, current));
    }

    public void unlock() {
        Thread current = Thread.currentThread();
        owner.compareAndSet(current, null);
    }
}
```

本质上封装了引用类型的 CAS 操作实现, 将当前线程引用保存在 owner 中, 借助原子类保证可见性

>   不要直接使用带有 volatile 修饰的引用替代这里的 AtomicReference, 因为 CAS 操作涉及到读并交换

## CLH

>   [Java AQS 核心数据结构-CLH 锁](https://mp.weixin.qq.com/s/jEx-4XhNGOFdCo4Nou5tqg)

自旋锁避免了因为线程阻塞导致的线程上下文开销, 但自旋锁也存在缺点: 

*   锁饥饿问题: 没有公平性保障, 哪个线程执行完全取决于哪个线程先成功完成了 CAS 操作 (讲道理 synchronized 其实也存在公平性问题)
*   性能问题: 在竞争激烈的时候, 可能存在 CPU 空转的情况, 程序都忙着处理自选操作了, 因为线程不会被阻塞, 那些没有获取到锁的线程还是会被调度

>   关于性能的问题, 这也是为什么都说, 在竞争激烈的时候最好还是使用悲观锁, 直接把其他线程阻塞吧

CLH 对自旋锁进行了改进, 请求相同锁的线程会构成一个隐式阻塞链, 采用 FIFO 的方式保证了公平性, 每个线程都会按照申请锁的时间顺序获得锁

简单来说 CLH 将各个线程根据申请锁的顺序抽象为一个链表, 同时使用 CAS 操作维护当前链表的尾节点, 每个节点记录了当前当前占用资源的状态, 这样一旦当前节点发现前一个节点释放的资源的占用即可立刻完成锁的获取

```java
class CLH {
    private final ThreadLocal<Node> node = ThreadLocal.withInitial(Node::new);
    private final AtomicReference<Node> tail = new AtomicReference<>(new Node());

    private static class Node {
        private volatile boolean locked;
    }

    public void lock() {
        Node n = node.get();
        n.locked = true;
        Node pre = tail.getAndSet(n);
        while (pre.locked);
    }

    public void unlock() {
        Node n = node.get();
        n.locked = false;
        node.set(new Node());
    }
}
```

注意到这里的 CLH 链表并没有显式维护 next 指针, 在 lock 时每个线程会先通过 CAS 操作获取当前的 CLH 的尾节点, 并将自己更新为新的尾节点; 这是因为 CLH 将 CAS 自旋的操作分散了, 每个线程 (节点) 查看的都是前一个线程 (节点) 的资源占用状态, 只要前一个线程 (节点) 释放了资源, 当前线程即结束了自旋并进行资源占用

>   这也是为什么前面说 CLH 维护的是一个隐式链表

注意到这里有一个比较关键的地方, 即在 unlock 时, 需要 set 一个新的 Node, 这是为了避免出现死锁, 考虑如果两个线程 t1 与 t2 按照如下顺序执行:

```shell
t1 lock -> t2 lock(spin) -> t1 critial section -> t1 unlock -> t1 lock(spin) 
```

注意到在 t1 释放 lock 后, 将 locked 状态修改为 false 后, t2 并没有被调度, 反而是 t1 再次进行锁申请, 此时 CLH 维护的 list 有如下结构:

```shell 
t1 node -> t2 node -> t1 node
```

在 t2 检查 t1 的 node 的 locked 属性之前, t1 再次获取锁, 如果没有在 t1 释放锁时 set 一个新的 Node, 那么 t2 再次运行时读到的是被再次置为 true 的 locked 属性, 此时会出现 t2 等待 t1 的 unlock 变为 false, 而 t1 也等待 t2 的 unlocked 变为 false 的情况 => 死锁

因此在 unlock 中一定需要将 ThreadLocal 中的 node 重新赋值

使用 CLH 相比裸 CAS 的 spin lock 有很多好处:

*   每个线程不再自旋于 CAS 操作, 每个线程的自选中仅仅是获取一个 volatile 类型变量的取值; 此外线程解锁时也只需要设置一个 volatile 类型的变量; 唯一的 CAS 操作仅出现在获取队列的尾节点, 比 spin lock 的开销更小
*   公平锁, 每个线程按照申请锁的顺序占用锁

在 java 中, juc 工具类的基石 AbstractQueuedSynchronizer (AQS) 就是在 CLH 的基础上进行了补充完善:

*   CLH 本质上还是自旋操作, 尽管自旋的开销很小, 但还是浪费了 CPU 资源; AQS 将自旋修改为阻塞
*   AQS 对锁功能进行了扩充, 比如 reentrant (可重入)

AQS 扩展了 CLH 中每个节点的状态:

```java  
// AbstractQueuedSynchronizer.java

 // Node status bits, also used as argument and return values
static final int WAITING   = 1;          // must be 1
static final int CANCELLED = 0x80000000; // must be negative
static final int COND      = 2;          // in a condition wait

/** CLH Nodes */
abstract static class Node {
    volatile Node prev;       // initially attached via casTail
    volatile Node next;       // visibly nonnull when signallable
    Thread waiter;            // visibly nonnull when enqueued
    volatile int status;      // written by owner, atomic bit ops by others
}
```

使用 bit mode + status 的方式表示当前节点的状态, 同时显式维护了当前节点的前置节点和后驱节点, 好处在于, 如果当前被阻塞的节点被打断, 从而取消了对当前锁的申请, 那么后驱节点在进行锁状态的判断时, 可以直接访问到当前节点的前驱节点

此外由于 AQS 会将 CLH 中所有等待的节点阻塞掉, 因此在当前节点释放锁时需要显式的唤醒后续节点

## Lock-Free Queue

基本的思想还是 M&S Queue, [Fast Concurrent Queue Algorithms](https://www.cs.rochester.edu/research/synchronization/pseudocode/queues.html)

在 java 中有了 AtomicReference, 链表的实现还是比较简单的, 对于一个队列而言其实就是两种操作, offer 与 poll

整体思路和 M&S 相同, 创建一个 dummy node, offer 的时候链接在尾节点后面, poll 的时候获取的是头节点后的第一个节点

首先说 offer, 这个操作相对简单一点, 通过 CAS 操作修改 tail 的 next 节点

```java
public void offer(T val) {
    // 进循环前, 创建节点
    Node<T> node = new Node<>(val);
    while (true) {
        // 获取尾节点 (不一定准确)
        Node<T> t = tail.get();
        // 只有在 "尾节点" 的 next 节点为 null 时, 才能说明当前的节点是真的 "尾节点", 此时更新
        if (t.next.compareAndSet(null, node)) {
            // 同时间只有一个线程会成功添加, 注意到添加新节点后再更新 tail 指
            tail.compareAndSet(t, node);
            return;
        }
    }
}
```

poll 会麻烦一点, 这里需要判断当前队列是否为空, 在队列非空的情况下通过 CAS 操作移动 head 指针

```java
public T poll() {
    while (true) {
        Node<T> h = this.head.get();
        Node<T> ne = h.next.get();
        // ne 为 null, 其余线程还是可以添加新节点, 因此这里是比较保守的判断
        if (ne == null) {
            return null;
        } else {
            // 在 ne 不为 null 的情况下, 至少有一个线程会成功从队首获取元素
            // 具体的方式就是移动 head 指针
            if (head.compareAndSet(h, ne)) {
                return ne.val;
            }
        }
    }
}
```

```java
// All on one

import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicReference;

public class LockFreeQueue<T> {
    private static class Node<T> {
        private final T val;
        private final AtomicReference<Node<T>> next;

        public Node(T val) {
            this.val = val;
            this.next = new AtomicReference<>();
        }
    }

    private final AtomicReference<Node<T>> head;
    private final AtomicReference<Node<T>> tail;
    private final AtomicInteger size;
	
    public LockFreeQueue() {
        Node<T> dummy = new Node<>(null);
        this.head = new AtomicReference<>(dummy);
        this.tail = new AtomicReference<>(dummy);
        size = new AtomicInteger(0);
    }

    public void offer(T val) {
        Node<T> node = new Node<>(val);
        while (true) {
            Node<T> t = tail.get();
            if (t.next.compareAndSet(null, node)) {
                tail.compareAndSet(t, node);
                size.incrementAndGet();
                return;
            }
        }
    }

    public T poll() {
        while (true) {
            Node<T> h = this.head.get();
            Node<T> ne = h.next.get();
            if (ne == null) {
                return null;
            } else {
                if (head.compareAndSet(h, ne)) {
                    size.decrementAndGet();
                    return ne.val;
                }
            }
        }
    }

    public int size() {
        return size.get();
    }
}
```

## Semaphore

在 java 中 semaphore 是通过 AQS 实现的

>   事实上在 libc 中就已经提供了 system-level 的 semaphore, 但是 java 还是定义了自己的 semaphore

和一般的 semaphore 相同, 初始化的时候可以控制一次性进入 critical section 的线程数量, 通过 P (acquire) 进行锁获取, 通过 V (release) 进行锁释放

所以可以认为 semaphore 实现的是一个 shared lock, 并在初始化线程数为 1 时, shared lock 退化为 exclusive lock

默认情况下, semaphore 是非公平锁, 通过修改构造方法的参数可以构建一个公平锁 (AQS 队列实现)

### acquire

```java
// Semaphore.java

public void acquire() throws InterruptedException {
    sync.acquireSharedInterruptibly(1);
}

public void acquire(int permits) throws InterruptedException {
    if (permits < 0) throw new IllegalArgumentException();
    sync.acquireSharedInterruptibly(permits);
}
```

acquire 方法是 Semaphore 类暴露的供线程获取锁的方法, 看一下实现, 其实就是检查一下参数, 然后调用 AQS 中的方法 acquireSharedInterruptibly

```java
// AbstractQueuedSynchronizer.java

public final void acquireSharedInterruptibly(int arg)
    throws InterruptedException {
    if (Thread.interrupted() ||
        (tryAcquireShared(arg) < 0 &&
         acquire(null, arg, true, true, false, 0L) < 0))
        throw new InterruptedException();
}
```

因为 AQS 采用了 template pattern, 所有基于 AQS 的 synchronizer 只需要实现 tryAcquire/tryRelease (exclusive lock), tryAcquireShared/tryReleaseShared (shared lock)

对于 Sempahore 而言, 实现了这里在 if 中的方法 tryAcquireShared

```java
// Semaphore.java

static final class NonfairSync extends Sync {
    protected int tryAcquireShared(int acquires) {
        return nonfairTryAcquireShared(acquires);
    }
}

static final class FairSync extends Sync {
    protected int tryAcquireShared(int acquires) {
        for (;;) {
            if (hasQueuedPredecessors())
                return -1;
            int available = getState();
            int remaining = available - acquires;
            if (remaining < 0 ||
                compareAndSetState(available, remaining))
                return remaining;
        }
    }
}

abstract static class Sync extends AbstractQueuedSynchronizer {
    private static final long serialVersionUID = 1192457210091910933L;

    final int nonfairTryAcquireShared(int acquires) {
        for (;;) {
            int available = getState();
            int remaining = available - acquires;
            if (remaining < 0 ||
                compareAndSetState(available, remaining))
                return remaining;
        }
    }
}
```

前面也提到了 Semaphore 同时支持非公平锁/公平锁, 在不同锁下, tryAcquireShared() 的实现是不同的, 但本质上二者是类似的, 区别在于公平锁在通过 CAS 操作获取锁之前还会先检查一下当前线程在 AQS 的队列中是否存在前驱节点, 只有不存在前驱节点时, 才进行锁请求 => 通过 CAS 操作修改 AQS 的 state

### release

```java
// Semaphore.java

public void release() {
    sync.releaseShared(1);
}

public void release(int permits) {
    if (permits < 0) throw new IllegalArgumentException();
    sync.releaseShared(permits);
}
```

release 方法是 Semaphore 类暴露的释放锁的方法, 内部实现也是检查了一下参数就调用了 AQS 中封装的方法 releaseShared

```java
// AbstractQueuedSynchronizer.java

public final boolean releaseShared(int arg) {
    if (tryReleaseShared(arg)) {
        signalNext(head);
        return true;
    }
    return false;
}
```

就像上面说的, 基于 template pattern 的 AQS 只需要子类 synchronizer 实现方法 tryAcquireShared/tryReleaseShared (shared lock)

```java
// Semaphore.java

protected final boolean tryReleaseShared(int releases) {
    for (;;) {
        int current = getState();
        int next = current + releases;
        if (next < current) // overflow
            throw new Error("Maximum permit count exceeded");
        if (compareAndSetState(current, next))
            return true;
    }
}
```

在释放锁的时候, Semaphore 并没有区分公平锁/非公平锁 => 本质上也是通过 CAS 操作修改 AQS 的状态

## CountDownLatch

Semaphore 保证了最多只有 N 个线程进入 critical section => acquire 会让 state 减少, 而 release 会让 state 增加;

CountDownLatch 在实现的时候恰恰相反, 每个 release 会让 state 减少, 而 acquire 会在 state 不为 0 时让线程阻塞 (如果看源码的话感觉和 Semaphore 正好反过来了)

CountDownLatch 的作用是让线程阻塞, 直到其他线程完成了某些任务 => 初始化时, 多线程初始化各个模块, 全部完成后唤醒主线程

## ReentrantLock

实现可重入的锁, 关键在于借助了 AQS 中的 state 字段, 表示当前线程获取的次数

### lock

```java
// ReentrantLock.java

public void lock() {
    sync.lock();
}
```

目前为止看到的所有基于 AQS 的实现的 JUC 工具类, 都是维护了一个内部类 Sync => AQS 子类, 并通过该内部类实现锁功能

```java
// ReentrantLock.java

abstract static class Sync extends AbstractQueuedSynchronizer {

    /**
     * Checks for reentrancy and acquires if lock immediately
     * available under fair vs nonfair rules. Locking methods
     * perform initialTryLock check before relaying to
     * corresponding AQS acquire methods.
     */
    abstract boolean initialTryLock();

    @ReservedStackAccess
    final void lock() {
        if (!initialTryLock())
            acquire(1);
    }
}
```

因为 ReentrantLock 也是分为公平锁和非公平锁, 所以也存在 NonfairSync 与 FairSync 两种实现

>   在 Semaphore 哪里就能看到, 所谓公平就是检查一下当前线程是不是 AQS 的头节点

```java
// ReentrantLock.java 

static final class NonfairSync extends Sync {

    final boolean initialTryLock() {
        Thread current = Thread.currentThread();
        if (compareAndSetState(0, 1)) { // first attempt is unguarded
            setExclusiveOwnerThread(current);
            return true;
        } else if (getExclusiveOwnerThread() == current) {
            int c = getState() + 1;
            if (c < 0) // overflow
                throw new Error("Maximum lock count exceeded");
            setState(c);
            return true;
        } else
            return false;
    }
 }

static final class FairSync extends Sync {

    final boolean initialTryLock() {
        Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) {
            if (!hasQueuedThreads() && compareAndSetState(0, 1)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        } else if (getExclusiveOwnerThread() == current) {
            if (++c < 0) // overflow
                throw new Error("Maximum lock count exceeded");
            setState(c);
            return true;
        }
        return false;
    }
}
```

initialTryLock 就是通过 CAS 操作设置一下 state, 并且在当前线程是头节点的情况下, 让 state 自增, 仅此而已, 显然这个操作可能失败, 失败之后直接调用 AQS 中的 acquire 方法

```java
// AbstractQueuedSynchronizer.java

public final void acquire(int arg) {
    if (!tryAcquire(arg))
        acquire(null, arg, false, false, false, 0L);
}
```

方法 tryAcquire 是 AQS 暴露出来需要各个 synchronizer 实现的方法

```java
// ReentrantLock.java

static final class NonfairSync extends Sync {

    /**
     * Acquire for non-reentrant cases after initialTryLock prescreen
     */
    protected final boolean tryAcquire(int acquires) {
        if (getState() == 0 && compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(Thread.currentThread());
            return true;
        }
        return false;
    }
}

static final class FairSync extends Sync {
    /**
     * Acquires only if thread is first waiter or empty
     */
    protected final boolean tryAcquire(int acquires) {
        if (getState() == 0 && !hasQueuedPredecessors() &&
            compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(Thread.currentThread());
            return true;
        }
        return false;
    }
}
```

就像上面说的那样, 公平锁就是在非公平锁的基础上, 比较一下当前线程是不是 AQS 的头节点, 仅此而已, 显然这个操作也可能失败, 此时线程会被 AQS 阻塞

### unlock

```java
// ReentrantLock.java

public void unlock() {
    sync.release(1);
}


// AbstractQueuedSynchronizer.java

public final boolean release(int arg) {
    if (tryRelease(arg)) {
        signalNext(head);
        return true;
    }
    return false;
}
```

方法 tryRelease 也是 AQS 暴露出来给各个 synchronizer 实现的方法

```java
// ReentrantLock.java

abstract static class Sync extends AbstractQueuedSynchronizer {
    @ReservedStackAccess
    protected final boolean tryRelease(int releases) {
        int c = getState() - releases;
        if (getExclusiveOwnerThread() != Thread.currentThread())
            throw new IllegalMonitorStateException();
        boolean free = (c == 0);
        if (free)
            setExclusiveOwnerThread(null);
        setState(c);
        return free;
    }
}
```

想想也是, 所谓公平说的是获得锁的顺序, 而不是释放锁的顺序, 所以不管是不是公平锁释放锁的操作都是一样的

### 优势

相比 synchronization, ReentrantLock 的优势:

*   可被打断: 这一点是基于 AQS 实现的, AQS 提供了接口 acquireInterruptibly(), 不需要死等了
*   公平锁: 通过检查当前线程是否为 AQS 头节点实现
*   Condition: 实现了基于 Condition 的等待/通知机制

## one more thing

```java
class CLH {
    private final ThreadLocal<Node> node = ThreadLocal.withInitial(Node::new);
    private final AtomicReference<Node> tail = new AtomicReference<>(new Node());

    private static class Node {
        private volatile boolean locked;
        private Node next;
        private final Thread thread;

        public Node() {
            this.next = null;
            this.thread = Thread.currentThread();
        }
    }

    public void lock() {
        Node n = node.get();
        n.locked = true;
        Node pre = tail.getAndSet(n);
        pre.next = n;
        while (pre.locked) {
            LockSupport.park();
        }
    }

    public void unlock() {
        Node n = node.get();
        n.locked = false;
        if (n.next != null) {
            LockSupport.unpark(n.next.thread);
        }
        node.set(new Node());
    }
}

// CLH.java
public class CLH {
    private static class Node {
        private volatile boolean locked;
        private volatile Thread next;

        public Node() {
            this.locked = false;
        }
    }

    private final ThreadLocal<Node> current;
    private final AtomicReference<Node> tail;

    public CLH() {
        current = ThreadLocal.withInitial(Node::new);
        tail = new AtomicReference<>(new Node());
    }

    public void lock() {
        Node cur = current.get();
        cur.locked = true;
        Node pre = tail.getAndSet(current.get());
        pre.next = Thread.currentThread();
        while (pre.locked) {
            LockSupport.park();
        }
    }

    public void unlock() {
        Node cur = current.get();
        cur.locked = false;
        if (cur.next != null) {
            LockSupport.unpark(cur.next);
        }
        current.set(new Node());
    }
}
```

>   实现一个可以阻塞等待线程的 CLH 并没有那么难

# Unsafe

一个很重要的类，比如`LockSupport`底层的`park`和`unpark`其实都是调用了`Unsafe`类的方法

首先这个类位于：`jdk.internal.misc`，这个类是`final`类型的，单例的，且为懒汉式加载的

```java
public final class Unsafe {

    private static native void registerNatives();
    static {
        registerNatives();
    }

    private Unsafe() {}

    private static final Unsafe theUnsafe = new Unsafe();
    ...
}
```

要注意的是正常情况下是无法使用`Unsafe`直接修改数据的，会报异常：`java.lang.SecurityException: Unsafe`

原因看源码：

```java
    /**
     * Provides the caller with the capability of performing unsafe
     * operations.
     * 
     * The returned {@code Unsafe} object should be carefully guarded
     * by the caller, since it can be used to read and write data at arbitrary
     * memory addresses.  It must never be passed to untrusted code.
     * 返回的unsafe对象需要被谨慎对待，因为这个对象可以直接对内存进行读写；
     * unsafe对象禁止被传递给不受信的代码
     *
     * @throws  SecurityException if the class loader of the caller
     *          class is not in the system domain in which all permissions
     *          are granted.
     * 注意到只要调用这个方法的类的类加载器不是引导类加载器，他就会抛出异常
     * 所谓受信的代码，就是说那些使用了引导类加载器进行加载的类
     */
    @CallerSensitive
    public static Unsafe getUnsafe() {
        Class<?> caller = Reflection.getCallerClass();
        if (!VM.isSystemDomainLoader(caller.getClassLoader()))
            throw new SecurityException("Unsafe");
        return theUnsafe;
    }
```

如果还是希望获取到`unsafe`对象，需要考虑使用暴力反射：

```java
// 域名为theUnsafe，这个是源码里定义的
Field theUnsafe = Unsafe.class.getDeclaredField("theUnsafe");
// 暴力反射获取
theUnsafe.setAccessible(true);
Unsafe unsafe = (Unsafe) theUnsafe.get(null);
```

## 进行cas操作

还记得在原子类`AtomicInteger`中的方法：`compareAndSet`：

```java
public final boolean compareAndSet(int expectedValue, int newValue) {
     return U.compareAndSetInt(this, VALUE, expectedValue, newValue);
 }
// 调用了Unsafe类的方法，第一个参数为变量的内存地址，第二个参数为内存中的偏移量
@IntrinsicCandidate
public final native boolean compareAndSetInt(Object o, long offset,
                                             int expected,
                                             int x);
// 注意到这是一个native的方法
```

下面举一个具体的例子，使用`unsafe`进行`cas`操作，修改变量

```java
@Data
class BundleData {
	private volatile int val;

	public BundleData(int val) {
		this.val = val;
	}
}

public class GeneralTest {
	@Test
	public void test() throws NoSuchFieldException, IllegalAccessException {
		// 域名为theUnsafe，这个是源码里定义的
		Field theUnsafe = Unsafe.class.getDeclaredField("theUnsafe");
		// 暴力反射获取
		theUnsafe.setAccessible(true);
		Unsafe unsafe = (Unsafe) theUnsafe.get(null);
		BundleData data = new BundleData(10); // 默认传入的为10
        // 获取该对象的对应成员变量（域）在内存中的偏移地址
		long offset = unsafe.objectFieldOffset(BundleData.class.getDeclaredField("val"));
        // 传入的前两个参数分别为，该对象在内存中的地址，对象对应的成员变量z
		unsafe.compareAndSwapInt(data, offset, 10, 20);
		System.out.println(data.getVal()); //20
	}
}
```

## 自定义AtomicInteger

```java
@Data
@AllArgsConstructor
class MyAtomicInteger {
	private static final Unsafe UNSAFE;
	private volatile int val;
	private static final long OFFSET;

	static {
		try {
			Field theUnsafe = Unsafe.class.getDeclaredField("theUnsafe");
			theUnsafe.setAccessible(true);
			UNSAFE = (Unsafe) theUnsafe.get(null);
			OFFSET = UNSAFE.objectFieldOffset(MyAtomicInteger.class.getDeclaredField("val"));
		} catch (NoSuchFieldException | IllegalAccessException e) {
			throw new RuntimeException(e);
		}
	}

	public void setNew(int newVal) {
		while (true) {
			int pre = getVal();
			if (UNSAFE.compareAndSwapInt(this, OFFSET, pre, newVal)) break;
		}
	}

	public int incrementAndGet(int delta) {
		while (true) {
			int pre = getVal();
			int next = pre + delta;
			if (UNSAFE.compareAndSwapInt(this, OFFSET, pre, next)) return next;
		}
	}
}
```

就是简单的`cas`操作

测试：

```java
@Test
public void test() {
    MyAtomicInteger atomicInteger = new MyAtomicInteger(10);
    ExecutorService service = Executors.newFixedThreadPool(4);
    for (int i = 0; i < 4; i++) {
        service.execute(() -> {
            for (int j = 0; j < 100; j++) atomicInteger.incrementAndGet(2);
        });
    }
    try {
        TimeUnit.SECONDS.sleep(5);
        System.out.println(atomicInteger.getVal()); // 810
    } catch (InterruptedException e) {
        throw new RuntimeException(e);
    }
}
```

# jdk1.6的锁优化

在jdk1.6之后，`synchronized`关键字在底层被优化，引入了偏向锁、轻量级锁，减小了获得锁和释放锁的开销

锁的级别优先级：`无锁 < 偏向锁 < 轻量级锁 < 重量级锁`

锁可以升级，但不可以降级，即`无锁 -> 偏向锁 -> 轻量级锁 -> 重量级锁`是单向的

>   jdk 18 之后偏向锁被彻底废弃了

在java中所有的对象均可以作为锁，那么我们需要知道锁的一些信息，比如说这个锁当前是哪个线程持有的？其中一个解决的方式是使用一个全局的map存储锁和线程的映射关系，不过这种方式存在线程的安全性问题，我们总不能为了记录锁和线程的关系，结果还在map本身上加锁吧

所以真实中可行的方案其实是在对象头保存锁信息，包括当前对象是哪个线程持有的信息，区分不同的锁，主要区别在于对象头中的`MarkWord`部分不同

> 对象头为16Btyes：其中8Bytes表示`MarkWord`，8Bytes为类型指针

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/mark_word_details.png)

锁升级的过程：

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/locking_process.gif)

首先如果对象处于`unlocked`状态，那么此时最后两位一定是`01`

> 这里的`unlocked`应该就是说匿名偏向锁和无锁两种状态

当进入同步代码块（或者是同步方法，官网的写法是`a method synchronizes on an object`），此时会在当前的栈帧中添加一条`lock record`，一个`lock record`中包含了锁对象的对象头和一个指向了锁对象的指针

## JOL

一个`openjdk`的工具，因为下面涉及到观察锁对象的`mark word`，需要观察对象的内存分布，所以这里简单介绍一下

通过`maven`的形式引入：

```xml
<dependency>
    <groupId>org.openjdk.jol</groupId>
    <artifactId>jol-core</artifactId>
    <version>0.16</version>
</dependency>
```

注意如果是新建的项目，希望在`main`方法中使用这个工具，要把`<scope>provided</scope>`去掉

> 具体的解释看一下：[基础不牢地动山摇](./基础不牢地动山摇.md#Scope)

我们主要使用的方法：`ClassLayout.parseInstance(obj).toPrintable()`

## 偏向锁

偏向锁本质上并不具有同步的功能，它仅仅是为了应对那些带有同步标志，而实际中仅一个线程会进入同步的场景，尤其是用来优化早期的代码，那些为了线程安全而一味的将所有方法都添加了同步标志的代码，没错说的就是你`Vector`

> 这里额外提一句，轻量级锁本身也是针对于那些本身就不会出现多线程竞争，线程依次进入临界区的情况
>
> 偏向锁不过是为了进一步简化轻量级锁而提出的，轻量级锁的问题在于，如果发生了锁重入，那么还是会进行一次`CAS`操作，`jvm`的设计者认为一次`CAS`操作也是耗时的，也可以进行优化

偏向锁只要遇到了竞争就会进行偏向锁的撤销，这会导致其在竞争较多的环境中表现并不好

在`jdk15`之前，`JVM`是启用了偏向锁的，在对象被`new`出来之后，对象的`mark word`中的`thread_id`字段为0，即此时为匿名偏向锁状态

而在`jdk15`之后，`JVM`禁用了偏向锁，对象被`new`出来之后，对象的偏向标识为`0`，此时锁对象处于无锁状态，不过要注意的是此时对象的`hashCode`也是0，比如：

```java
package com.buzz.locks;

import org.openjdk.jol.info.ClassLayout;

/**
 * @program: tough_thread
 * @description:
 * @author: buzz
 * @create: 2022-04-24 15:01
 **/
public class Bias {

	public static void main(String[] args) throws InterruptedException {
		SynLock lock = new SynLock(1);
		System.out.println(ClassLayout.parseInstance(lock).toPrintable());
	}
}

class SynLock{
	int val;
	public SynLock(int val) {
		this.val = val;
	}
}
```

打印结果如下：

```shell
com.buzz.locks.SynLock object internals:
OFF  SZ   TYPE DESCRIPTION               VALUE
  0   8        (object header: mark)     0x0000000000000001 (non-biasable; age: 0)
  8   4        (object header: class)    0x00c01200
 12   4    int SynLock.val               1
Instance size: 16 bytes
Space losses: 0 bytes internal + 0 bytes external = 0 bytes total
```

> 64位系统中，`VALUE`一共16位，每一位由四位二进制标识，所以最后的`1`其实是：`0001`
>
> 最后的`01`标识锁对象目前是无锁状态，之前的`0`标识锁对象不偏向
>
> 开头的0没有意义，因为一共需要4位才能表示一个分代年龄，它需要和前面的结合起来才行

### 加锁

当一个线程访问同步代码块时，会检查锁对象的`mark word`，首先看看锁标志位，为`01`时说明此时锁对象为无锁，或偏向锁的状态

然后会再检查偏向锁标志是否为`1`：

* 如果偏向锁标识为0，说明此时处于无锁状态，未启用偏向锁，那么就进行锁升级，将其升级为轻量级锁

* 如果偏向锁标识为1，说明此时处于偏向锁状态，然后检查锁对象`mard word`中的`thread_id`和当前线程的是否相同：

  * 如果相同，说明此时当前线程已经获取过该锁对象了，此时不会使用`CAS`操作加锁，直接进入同步部分

  * 如果不同，使用`CAS`将锁对象的`thread_id`修改为当前线程的`id`：
    * 如果当前锁对象的`thread_id`为0，那么修改一定成功，当前线程获得锁对象
    * 如果当前锁对象的`thread_id`不为0，说明当前锁对象被其他线程占用，此时需要进行偏向锁的撤销

对于偏向锁而言，**一旦出现线程的"竞争"**，就立刻执行偏向锁的撤销

### 撤销

首先需要知道的时，偏向锁的撤销一定要等到一个全局安全点，即`safe point`，在这个状态下，所有的线程均处于暂停状态

> 全局安全点可参考：

根据上述，我们知道了，当线程需要获取到偏向锁，而偏向锁的`thread_id`为其他线程时，需要进行偏向锁撤销

注意，这里的`thread_id`为其他线程，并不意味着其他线程依旧存活，因为偏向锁和轻量级锁、重量级锁是不同的，线程离开临界区后不会进行解锁操作

首先会检查锁对象当前`mark word`中`thread_id`对应的线程的情况：

* 如果当前线程仍在临界区：此时锁升级为轻量级锁，不过当前正持有锁的线程仍持有锁
* 如果当前线程不存活：检查当前的随对象是否允许重偏向：
  * 如果不允许重偏向，那么进行锁膨胀，偏向锁升级为轻量级锁
  * 如果允许重偏向，那么将锁对象设置为匿名偏向锁的状态，然后通过`CAS`的方式，让正在竞争的线程获取到锁对象

锁撤销的伪代码：

```java
if mark word 存储的不是可偏向状态:
    return;     // 如果不是偏向锁，那么没有撤销偏向的必要
else:
    if Thread ID 指向的线程不存活:
        if 允许重偏向:
            退回可偏向但未偏向的状态   // Thread ID为0
        else:
            偏向撤销，变为无锁状态
    else:
        if Thread ID 指向的线程，仍然拥有锁:
            升级为轻量级锁，将mark word复制到线程栈中，然后stack pointer指向最老的相关锁记录
        else:
            if 允许重偏向:
                退回可偏向但未偏向的状态   // Thread ID为0
            else:
                偏向撤销，变为无锁状态
```

### 批量重偏向

这个其实也叫：`bulk rebias`

> 我最开始还以为，重偏向还分成了批量的和不批量的两种呢，其实就是一种，之所以使用批量去形容，主要是因为这是形容类的。

首先要知道，偏向锁默认是不允许重偏向的，且又因为偏向锁在线程离开临界区后，并不会进行解锁（复写对象头）。

如果两个线程先后进行加锁的操作，那么第二个线程会因为，对象头不是0，而进入偏向锁撤销的操作，随后又会因为默认不允许重偏向，而将锁对象升级为轻量级锁。

一个比较疑惑的点在于，那为什么默认不允许重偏向呢，jvm设计师，你知道我的痛楚吗。

对于一个类，可以具有若干个锁对象，一个默认处于偏向锁状态的锁对象，默认在不允许重偏向时，它也仅仅会经历一次偏向锁撤销（因为撤销过一次后就是轻量级锁，解锁后就是无锁状态，再也回不到偏向锁状态了）。

jvm设计师，觉得如果一老进行偏向锁升级确实开销比较大（毕竟进行偏向锁加锁就是一个CAS操作，升级成轻量级锁有需要来一次CAS），所以设计出了重偏向。对于一个类下的锁对象，如果进行了20次偏向锁升级后，就允许其他还是偏向锁状态的锁对象，重新偏向（而至于那些已经升级为轻量级锁的对象，就放弃了，他们爱怎么玩就怎么玩吧）。

这个20次锁撤销就重偏向不是随便说说的：

```shell
$ java -XX:+PrintFlagsFinal -version | grep Biased
     intx BiasedLockingBulkRebiasThreshold         = 20                                        {product} {default}
     intx BiasedLockingBulkRevokeThreshold         = 40                                        {product} {default}
     intx BiasedLockingDecayTime                   = 25000                                     {product} {default}
     intx BiasedLockingStartupDelay                = 0                                         {product} {default}
     bool UseBiasedLocking                         = true                                      {product} {default}
openjdk version "11.0.13" 2021-10-19 LTS
OpenJDK Runtime Environment 18.9 (build 11.0.13+8-LTS)
```

我们在jvm启动的时候添加了参数：`-XX:+PrintFlagsFinal`，这样他会打印一些默认值，可以看到，它有一项，`BiasedLockingBulkRebiasThreshold`，偏向锁重偏向阈值，默认就是20

> 此外我们还能看到在jdk11中，默认启动了偏向锁，如果更换版本的话就变为了：
>
> ```shell
> $ java -XX:+PrintFlagsFinal -version | grep UseBiasedLocking
>      bool UseBiasedLocking                         = false                                     {product} {default}
> openjdk version "17.0.1" 2021-10-19 LTS
> OpenJDK Runtime Environment 21.9 (build 17.0.1+12-LTS)
> OpenJDK 64-Bit Server VM 21.9 (build 17.0.1+12-LTS, mixed mode, sharing)
> ```
>
> 可以看到在jdk17中偏向锁就默认关闭了

举个简单的例子：

```java
package com.buzz.locks;

import org.openjdk.jol.info.ClassLayout;

import java.util.ArrayList;
import java.util.List;

/**
 * @program: tough_thread
 * @description:
 * @author: buzz
 * @create: 2022-04-24 15:01
 **/
public class BulkRebias {

	public static void main(String[] args) {
		List<SynLock> list = new ArrayList<>();
		Object testLock1 = new Object();
		Thread t1 = new Thread(() -> {
			for (int i = 0; i < 21; i++) {
				SynLock lock = new SynLock(i);
				synchronized (lock) {
					System.out.println((ClassLayout.parseInstance(lock)).toPrintable());
				}
				list.add(lock);
			}
			System.out.println("-----------------");
			synchronized (testLock1) {
				testLock1.notify();
			}
		});
		t1.start();

		Thread t2 = new Thread(() ->{
			synchronized (testLock1) {
				try {
					testLock1.wait();
				} catch (InterruptedException e) {
					throw new RuntimeException(e);
				}
			}
			for (int i = 0; i < 21; i++) {
				SynLock lock = list.get(i);
				synchronized (lock) {
					System.out.println(ClassLayout.parseInstance(lock).toPrintable());
				}
			}
			System.out.println("-----------------");
		});
		t2.start();
	}
}

class SynLock{
	int val;
	public SynLock(int val) {
		this.val = val;
	}
}
```

我们开启了两个线程，他们都会争夺锁`testLock1`，如果第二个线程先争夺到了，就会进入休眠。我们设置锁`testLock1`的目的就是通过`wait-notify`的机制保证了线程执行的先后顺序。

> 其实这里使用`join`也可以达到相同的目的，不过一般而言`join`并不如`wait-notify`灵活，因为`join`之后的线程就终止了，而`notify`后的线程还可以进行其他的操作。
>
> 注意到，其实我们的这个例子是不太好的，因为可能出现线程假醒的状态，使用`wait-notify`机制的正确方法，是把`wait`放进一个循环中，具体的，可以看[之前的内容](#可恶的`wait`、`notify`、`notifyAll`)

第一个线程，锁住了`SynLock`类的21个对象，jvm启动的时候添加了参数`-XX:+UseBiasedLocking`，所以这21个对象最开始都处于匿名偏向锁状态，进入同步代码块后就变为了偏向锁状态；注意到离开同步代码块时，这21个对象的对象头并不会改变。

第二个线程被唤醒后，也会争夺`SynLock`类的21个锁对象，因为`mark word`中已经写为线程1的id了，所以`CAS`替换操作必然失败，进入锁撤销的环节，前20个锁因为不允许重偏向，所以膨胀为轻量级锁。而第`21`个锁对象，因为经历了20次锁撤销后，在锁撤销的时候会判断允许重偏向，因此不会第21个锁对象不会升级为轻量级锁。

这里我发现了一个版本的问题，在`jdk17`的环境中，第二个线程中到第21个对象，才变为偏向锁，之前都是轻量级锁，而`jdk11`的版本中第20个对象已经变为偏向锁了：

```shell
# 下面这个是jkd11，注意val的取值和循环的i是一致的，所以val为18，其实已经是第19个对象了
com.buzz.locks.SynLock object internals:
OFF  SZ   TYPE DESCRIPTION               VALUE
  0   8        (object header: mark)     0x00000062d9efeca0 (thin lock: 0x00000062d9efeca0)
  8   4        (object header: class)    0x2000ce49
 12   4    int SynLock.val               18
Instance size: 16 bytes
Space losses: 0 bytes internal + 0 bytes external = 0 bytes total

com.buzz.locks.SynLock object internals:
OFF  SZ   TYPE DESCRIPTION               VALUE
  0   8        (object header: mark)     0x000001da3702f105 (biased: 0x00000000768dc0bc; epoch: 0; age: 0)
  8   4        (object header: class)    0x2000ce49
 12   4    int SynLock.val               19
Instance size: 16 bytes
Space losses: 0 bytes internal + 0 bytes external = 0 bytes total

com.buzz.locks.SynLock object internals:
OFF  SZ   TYPE DESCRIPTION               VALUE
  0   8        (object header: mark)     0x000001da3702f105 (biased: 0x00000000768dc0bc; epoch: 0; age: 0)
  8   4        (object header: class)    0x2000ce49
 12   4    int SynLock.val               20
Instance size: 16 bytes
Space losses: 0 bytes internal + 0 bytes external = 0 bytes total

-----------------

# 下面这个是jdk17
com.buzz.locks.SynLock object internals:
OFF  SZ   TYPE DESCRIPTION               VALUE
  0   8        (object header: mark)     0x0000008b666fef80 (thin lock: 0x0000008b666fef80)
  8   4        (object header: class)    0x00c03000
 12   4    int SynLock.val               19
Instance size: 16 bytes
Space losses: 0 bytes internal + 0 bytes external = 0 bytes total

com.buzz.locks.SynLock object internals:
OFF  SZ   TYPE DESCRIPTION               VALUE
  0   8        (object header: mark)     0x000001bf7ed9a905 (biased: 0x000000006fdfb66a; epoch: 0; age: 0)
  8   4        (object header: class)    0x00c03000
 12   4    int SynLock.val               20
Instance size: 16 bytes
Space losses: 0 bytes internal + 0 bytes external = 0 bytes total

-----------------
```

> `thin lock`，说明对象处于轻量级锁的状态，而`biased`说明对象处于偏向状态

### 批量锁撤销

也叫`bulk revocation`

从上面的打印`jvm`的启动标志的时候，就已经看到了除了`BiasedLockingBulkRebiasThreshold`，还有一个`BiasedLockingBulkRevokeThreshold`，这个就是偏向锁撤销，它的极限阈值是40。

就是说我们上面通过允许重偏向，使得原来偏向第一个线程的锁对象，现在可以批量的重偏向到第二个线程。但如果现在批量重偏向的锁对象有需要偏向到第三第四个线程，那么还是会出现竞争，从而出现锁撤销，锁膨胀。

所以现在如果某个类下的锁对象进行了40次偏向锁升级，那么`jvm`认为这个类下的锁对象竞争真是太严重了，紧接着如果再`new`对象的时候，就禁用了偏向锁，上来就是无锁的状态，如果要加锁，加的也是轻量级锁。

举个小例子：

```java
package com.buzz.locks;

import org.openjdk.jol.info.ClassLayout;

import java.util.ArrayList;
import java.util.List;

/**
 * @program: tough_thread
 * @description:
 * @author: buzz
 * @create: 2022-04-24 15:01
 **/
public class BulkRevoke {

	public static void main(String[] args) {
		List<SynLock> list = new ArrayList<>();
		Object testLock1 = new Object();
		Object testLock2 = new Object();
		Thread t1 = new Thread(() -> {
			for (int i = 0; i < 40; i++) {
				SynLock lock = new SynLock(i);
				synchronized (lock) {
					System.out.println((ClassLayout.parseInstance(lock)).toPrintable());
				}
				list.add(lock);
			}
			System.out.println("-----------------");
			synchronized (testLock1) {
				testLock1.notify();
			}
			synchronized (testLock2) {
				try {
					testLock2.wait();
				} catch (InterruptedException e) {
					throw new RuntimeException(e);
				}
			}
			for (int i = 0; i < 40; i++) {
				SynLock lock = list.get(i);
				synchronized (lock) {
					System.out.println(ClassLayout.parseInstance(lock).toPrintable());
				}
			}
			System.out.println("-----------------");
			System.out.println(ClassLayout.parseInstance(new SynLock(100)).toPrintable());
		});
		t1.start();

		Thread t2 = new Thread(() ->{
			synchronized (testLock1) {
				try {
					testLock1.wait();
				} catch (InterruptedException e) {
					throw new RuntimeException(e);
				}
			}
			for (int i = 0; i < 40; i++) {
				SynLock lock = list.get(i);
				synchronized (lock) {
					System.out.println(ClassLayout.parseInstance(lock).toPrintable());
				}
			}
			System.out.println("-----------------");
			synchronized (testLock2) {
				testLock2.notify();
			}
		});
		t2.start();
	}
}

class SynLock{
	int val;
	public SynLock(int val) {
		this.val = val;
	}
}

```

和刚才基本一致，只不过现在当40个锁对象的后20个偏向到第二个线程后，再唤醒第一个线程，争夺锁对象。在40个锁对象中，前20个是无锁状态，所以上来就是轻量级锁，而后20个锁对象重偏向到了第二个线程，`mark word`中偏向标识还是1，所以这里`CAS`加锁失败，进入锁撤销，锁膨胀的环节。

所以上面一共发生了`40`次锁膨胀，随后`jvm`将认为当前这个类就不应该上偏向锁，随后，在第一个线程中`new`的对象就都是无锁状态了。

```shell
# 下面的在jdk17的环境中

# 这里是第一个线程打印的最后一个锁对象，可以看到第40个对象已经膨胀为轻量级锁了
com.buzz.locks.SynLock object internals:
OFF  SZ   TYPE DESCRIPTION               VALUE
  0   8        (object header: mark)     0x0000008283aff630 (thin lock: 0x0000008283aff630)
  8   4        (object header: class)    0x00c03000
 12   4    int SynLock.val               39
Instance size: 16 bytes
Space losses: 0 bytes internal + 0 bytes external = 0 bytes total

-----------------
# 这里是new出来的新对象，可以看到，是无锁的状态
com.buzz.locks.SynLock object internals:
OFF  SZ   TYPE DESCRIPTION               VALUE
  0   8        (object header: mark)     0x0000000000000001 (non-biasable; age: 0)
  8   4        (object header: class)    0x00c03000
 12   4    int SynLock.val               100
Instance size: 16 bytes
Space losses: 0 bytes internal + 0 bytes external = 0 bytes total
```

### 其他

* 当线程离开同步代码块时，线程不会主动释放偏向锁
* 调用锁对象的方法：`hashCode()`会计算对象的`hash`值，从而使得偏向锁失效，锁对象变为无锁状态
* 调用方法：`wait`或`notify`时会隐式的将其升级为重量级锁；我们前面已经讨论过了，当使用这两个方法的时候，一定要保证当前线程持有对象监视器`monitor`对象，这其实就已经暗含了将其升级为重量级锁

### 被废弃的偏向锁

在jdk15之后的openjdk中，默认关闭了偏向锁，如果需要启用需要给`jvm`添加参数：`-XX:+UseBiasdLocking`

原因如下：[JEP 374: Deprecate and Disable Biased Locking (java.net)](https://openjdk.java.net/jeps/374)

偏向锁具有的优势体现在单个线程无竞争的访问同步代码块时，此时不要争夺锁，一次`CAS`操作就可以实现加锁；这种优化主要针对的是远古使其的代码，他们大都为了保证线程安全性，添加了`synchronized`关键字，而实际运行的时候，大部分情况下又不存在线程的竞争关系，在这种情况下偏向锁确实又有

但后来的`jdk`中添加了单线程下运行的集合库，比如`ArrayList`、`HashMap`，同时也有多线程下也可以保证安全的集合库比如`ConcurrentHashMap`，你需要同步，就加锁，不需要就不加锁

那些明显存在大量竞争的场景就别使用偏向锁了，不然还得先加偏向锁，后撤销，反倒开销更大

> 比如生产者消费者的例子，就存在大量的竞争

## 轻量级锁

要明确的是，轻量级锁也适用于无竞争的状态，如果存在线程竞争，会发生锁膨胀，并升级为重量级锁

在`jdk15`之后，因为偏向锁被禁用，所以默认的当我们使用了`synchronized`关键字后，对象加锁加的就是轻量级锁

### 加锁

首先会在当前线程的虚拟机栈中方法的栈帧中创建一个`Lock Record`，`Lock Record`由两部分组成，一部分是`displaced mark word`，另一部分是指向了锁对象的指针

> 这个`displaced mark word`其实就是对象头，不过是加了轻量级锁的对象头，即最后两位为`00`，前面`62`为当前`lock record`的地址

然后尝试通过`CAS`的操作，将当前的`displaced mark word`写到锁对象头上，要注意的是，这里是真正的交换操作，即如果`CAS`操作成功了，那么此时`Lock Record`的`displaced mark word`中存储的就变成了原来锁对象的对象头了

> `CAS`交换的成功与否取决于此时锁对象的锁标记位是否为`01`，即是否为无锁，或偏向锁的状态

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/light_lock_1.png)

`CAS`交换失败，有两种情况，一种比较简单的情况，就是多个线程竞争，其他的线程会通过自旋，不断进行`CAS`，直到达到上限，此后会发生锁膨胀，轻量级锁膨胀为重量级锁；另外一种情况称为锁重入

### 锁重入

既然提到了锁重入，那么显然，轻量级锁是一种可重入锁：

所谓锁重入，就是一个线程进入同一个锁对象的不同方法，最简单的例子：

```java
public class Test{
    static Object lock = new Object();
    public static void main(String[] args) {
        new Thread(() -> {
            method1();
        })
    }
    
    public void method1() {
        synchronized(lock) {
            method1();
        }
    }
    
    public void method2() {
        synchronized(lock) {
            
        }
    }
}
```

当发生锁重入时，此时`CAS`一定会失败，因为此时锁对象的`mark word`的锁标志位已经变为`00`了，不过此时锁对象的`ptr_to_lock_record`指向的正是当前虚拟机栈中的某个栈帧，所以此时，线程可以获得锁，从而进入同步代码块

而要注意的时，此时会在栈帧中添加一个`lock record`，这个`lock record`中的`displaced mard word`部分为`null`，而对象引用还是指向锁对象

### 锁膨胀

不断的自旋过后，轻量级锁将升级为重量级锁，简单来说就是当轻量级锁通过`CAS`加锁失败后，发现锁对象指向的`lock record`并不指向当前线程的栈，那么就进行锁膨胀

这个过程涉及到将锁对象的`mark word`替换成一个指向`monitor`的指针，随后，将当前竞争失败的线程加入`EntryList`，从而使得当前线程进入`blocked`状态

> 注意到，不管是偏向锁膨胀为轻量级锁或是轻量级锁膨胀为重量级锁都不会影响正在执行的线程的控制权

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/light_lock_inflation.png)

### 解锁

对于锁重入的情况，只要清除掉`lock record`就好了，反正里面的`displaced mark word`也是`null`

否则的话，就需要通过`CAS`操作，将`displaced mard word`中的字段还原到原来的锁对象头

注意到，此时进行`CAS`进行还原的操作时可能是失败的，即，此时轻量级锁已经膨胀为了重量级锁，此时进行的将是重量级锁的解锁操作

## 重量级锁

其实就是1.6之前`jdk`中的`synchronized`关键字

首先要明白，真正起到同步作用的是`monitor`对象监视器，在`java`中，全都是对象，所以这个对象监视器，显然也是一个对象，不过我们直观操作的是锁对象，而并不是这个`monitor`

每个锁对象都会在内存中对应一个`monitor`对象，所以希望锁起作用，一定要保证锁的唯一性

> 千万别再出现局部变量作为锁结构的情况了，服了

我们使用关键字`synchronized`，将并发的线程变为串行执行的线程，称这部分区域为临界区：

```java
synchronized(obj) {
    // 这里就是临界区
}
```

线程进入临界区，需要获得对象监视器，即需要获得锁对象，当第一次进入临界区时，锁对象会先和一个`monitor`对象进行绑定

如下图所示，重量级锁的状态下，对象的`mark word`中保存了一个指针，这个指针指向了堆区中的一个`monitor`对象

一个`montior`对象由以下几个字段组成：`cxp(ContentionList)`、`EntryList`、`WaitSet`、`Owner`

![](https://cdn.jsdelivr.net/gh/SunYuanI/img/img/heavy_weight_monitor.webp)

其中要注意的是`ContentionList`、`EntryList`、`WaitSet`均为链表（队列）、`Owner`指向当前持有锁对象的线程

### 加锁

当线程进入临界区，`Owner`会指向对应的线程，而线程头部的`mark word`会指向一个`monitor`对象

当竞争的线程尝试持有锁时，如果锁已经被占用，那么该线程会被封装为`ObjectWaiter`对象，并加入`EntryList`，这个队列就是线程`blocked`的队列，同时该线程会被阻塞

当正在运行的线程释放资源时，会从队列中选出一个线程，`Owner`将指向这个线程，而其余的线程依旧会存在于`EntryList`中，注意到这种选举是和底层实现有关的，这部分就是`jvm`的源码了，暂时看不懂

一个正在运行着的线程调用了方法`wait`会进入`WaitSet`中，并释放锁结构，当线程被`notify`后线程对应封装的`ObjectWaiter`才会从`WaitSet`中取出，并加入`EntrySet`

### 解锁

其实过程很简单，因为此时锁对象的对象头中存储的是`ptr_heavyweight_monitor`，所以正在运行的线程可以通过锁对象找到`monitor`对象，将其`Owner`置为null，并从`blocked`的线程中唤醒一个使得`Owner`指向对应的线程

## 锁自旋

自旋操作其实就是轮询，进入一个循环，不断执行`CAS`操作，在失败了一定次数后会放弃自旋

自旋的存在，一定程度上可以避免线程的阻塞和唤醒，正是因为这一点，才使得自旋这种轮询的操作是有意义的

> 因为java中的线程是依托于操作系统层面的线程的，频繁的线程阻塞会系统开销比较大

自旋的问题在于，这种轮询的操作本身是具有开销的；考虑临界区的代码均为耗时的操作，那么自旋是没有意义的，因为自旋的线程在不断轮询的过程中`不太可能获得锁`

所以自旋的次数就比较关键了，`jvm`默认的自旋次数是10次，而这个次数并不是固定的；如果当前线程通过自旋，获得到锁结构，那么下次会增加自旋次数的上限，`jvm`认为一次自旋的成功，表示了后面自旋也可能成功，于是增加了自旋的上限；而如果本次自旋达到上限后还是没能成功，那么会`jvm`会减少自旋次数的上限

# 不可变类

如果一个类是不可变的，那么它本身就是线程安全的，毕竟就是常量么

一个例子，比如`SimpleDataFormat`，使用这个类进行日期转化的时候需要注意在多线程访问下是不安全的，会抛出异常，所以建议是使用`LocalDateTime`，具体的看[java8 的时间类](./基础不牢地动山摇#java8的时间类)

最典型的不可变类：`String`，本身就是`final`修饰的，在`jdk9`之后，内部的`value`属性添加了`@Stable`注解，用来保证`value`数组只会被修改一次

> 默认的`null`被赋值就算一次修改

当试图获取`substring`的时候，其会对原`value`数组进行复制，并返回新的`string`，以此实现不可变；这种不修改原来的`value`，而每次重新复制的操作，称为保护性拷贝

对于不可变类，如果获取值的时候都进行保护性拷贝，确实有点浪费空间了，所以提出了一种设计模式：享元模式

## 享元模式

flyweight: an object that minimizes memory usage by sharing some of its data with other similar objects.

共享相同取值的对象

在包装类的设计中大量使用了享元模式，比如在`Integer`中，默认缓存了`-128 ~ 127`之间的值：

```java
Integer a = 128;
Integer b = 128;
System.out.println(a == b); // false

Integer c = 1;
Integer d = 1;
System.out.println(c == d); // true
```

并且在`jdk`源码中是可以看到缓存类的：

```java
private static class IntegerCache {
        static final int low = -128;
        static final int high;
        static final Integer[] cache;
        static Integer[] archivedCache;

        static {
            // high value may be configured by property
            int h = 127;
            String integerCacheHighPropValue =
                VM.getSavedProperty("java.lang.Integer.IntegerCache.high");
            if (integerCacheHighPropValue != null) {
                try {
                    h = Math.max(parseInt(integerCacheHighPropValue), 127);
                    // Maximum array size is Integer.MAX_VALUE
                    h = Math.min(h, Integer.MAX_VALUE - (-low) -1);
                } catch( NumberFormatException nfe) {
                    // If the property cannot be parsed into an int, ignore it.
                }
            }
            high = h;
            ...
        }
    ...
}
```

甚至可以在`jvm`启动的时候手动设置缓存的大小

其他的包装类都是包含了缓存：

* `Byte`、`Short`、`Long`均缓存了`-128 ~ 127`，且不能改变
* `Integet`缓存范围和上面一样，但是可以改变缓存上限：`-Djava.lang.Integer.IntegerCache.high`：根据上面的源码，如果上上限比`127`小的话，他还是默认缓存到`127`
* `Character`类型缓存范围为`0 ~ 127`，对于字符而言，负数确实没什么意义
* `Boolean`缓存了`true`和`false`

既然包装类本身的不可变性保证了线程安全性，那为什么还需要类似`AtomicIntger`这样的原子类呢：这是因为对于包装类，其`get`，`set`方法确实是原子的，但是以自增操作举例，其本身需要先`get`，然后进行计算，最后`set`，包装类保证了这三个操作，每个操作都是原子的，但是不能保证这三个操作作为自增操作这个整体是原子的。

享元模式的一个应用：数据库连接池，避免了反复创建数据库连接，下面给出一个简单的数据库连接池：

```java
class ConnectionPool {
	// 连接池大小
	private final int size;
	// 创建连接
	private Connection[] connections;
	/*
	 	表示连接的状态，这里需要使用原子类，不然无法保证线程访问时的原子修改
	 	0表示未连接，1表示已经连接
	 */
	private AtomicIntegerArray states;

	public ConnectionPool(int size) {
		this.size = size;
		this.connections = new Connection[size];
		this.states = new AtomicIntegerArray(size);
		for (int i = 0; i < size; i++) {

		}
	}

	public Connection connect() {
		while (true) {
			for (int i = 0; i < size; i++) {
				if (states.get(i) == 0 && states.compareAndSet(i, 0, 1)) {
					return connections[i];
				}
			}
			/* 
				如果循环一次发现没有空闲连接，可以让当前线程休眠等待
            	特别适用于长连接的情况，加入线程进行的CRUD操作比较耗时
            	而其他的线程获取不到数据库连接池，可以进入休眠，避免过度占用处理器资源
            */
			synchronized (this) {
				try {
					wait();
				} catch (InterruptedException e) {
					throw new RuntimeException(e);
				}
			}
		}
	}

	public void close(Connection connection) {
		for (int i = 0; i < size; i++) {
			if (connections[i] == connection) {
                // 注意这里不需要进行cas的写操作，因为在获取线程池的时候保证了只有一个线程可以获取到某个connection
				states.set(i, 0);
				synchronized (this) {
					notifyAll();
				}
				return;
			}
		}
	}
}
```

## final

为`final`修饰的变量赋值时，将在赋值操作后添加写屏障：

```java
class Test {
    private final int val = 10;
}
```

```shell
$ javap -v Test.class
 0: aload_0
 1: invokespecial #1                  // Method java/lang/Object."<init>":()V
 4: aload_0
 5: bipush        10
 7: putfield      #2                  // Field val:I
 # 这里添加了写屏障，保证了其他 putfield 指令不会被重排到写屏障后，同时还保证了putfield操作会同步到主存中
 10: return
```

获取`final`类型的时候他会直接在栈中使用`bipush`添加数据，而不需要`getstatic`：

```java
public class Test{
    final int a = 10;
    static final int b = 20;

    public static void main(String[] args) {
        int num = new Test().a;
        num = Test.b;
    }
}
```

```shell
$ javap -v Test.class
# new 对象并完成初始化
 0: new           #3                  // class Test
 3: dup
 4: invokespecial #4                  // Method "<init>":()V
 7: invokestatic  #5                  // Method java/util/Objects.requireNonNull:(Ljava/lang/Object;)Ljava/lang/Object;
 10: pop
 # 直接把a对应的10 push 进入栈中
 11: bipush        10
 13: istore_1
 # 直接把b对应的20 push 进栈中
 14: bipush        20
 16: istore_1
 17: return
```

# 线程池

[Java 线程池详解](https://javaguide.cn/java/concurrent/java-thread-pool-summary.html#线程池介绍)

借助 Executor 框架管理线程 (jdk5) 以实现线程池 -> 据说可以避免 this 逃逸: 构造函数返回之前其他线程就持有该对象的引用

Executor 的三个组成部分:

*   任务: Executor 可以执行实现了 Runnable/Callable 接口的任务 

*   执行: 调度的关键, 各种提供调度服务的调度器都实现了 ExecutorServive 接口, 较为常用的是 ThreadPoolExecutor 和 ScheduledThreadPoolExecutor

    >   后者是前者的子类

    应用程序通过调用 execute (Executor 定义) 或 submit (ExecutorService 定义) 进行任务的提交

*   异步结果: 实现了 Future 接口的对象表示一个任务执行的结果, 方法 submit 的返回值为一个 Future

## ThreadPoolExecutor

最常用的线程池, 先从构造方法入手:

```java
public ThreadPoolExecutor(int corePoolSize,		// 保存在线程池中的线程数, 不会被回收
                          int maximumPoolSize,  // 线程池具备的最大线程数 (线程池中的线程数量是动态变化的)
                          long keepAliveTime,   // 在当前线程数大于 corePoolSize 后, 空闲的线程会在时间 keepAliveTime 后被回收
                          TimeUnit unit,        // keepAliveTime 的单位
                          BlockingQueue<Runnable> workQueue, // 保存各个任务 (待执行)
                          ThreadFactory threadFactory,       // 创建线程的工厂类, 线程池使用这个工厂类完成线程创建
                          RejectedExecutionHandler handler)  // 用来定义当线程池满后的策略 
```

在 ThreadPoolExecutor 中预定义了若干 handler:

*   `ThreadPoolExecutor.DiscardPolicy`: 不处理新任务

*   `ThreadPoolExecutor.AbortPolicy`: 抛出 `RejectedExecutionException` 来拒绝新任务的处理

*   `ThreadPoolExecutor.CallerRunsPolicy`: 直接在调用 `execute` 方法的线程中运行当前任务; 如果线程池已关闭, 则会丢弃该任务;

    >   这种策略会降低对于新任务提交速度 (因为提交任务的线程会被用来执行任务本身)

*   `ThreadPoolExecutor.DiscardOldestPolicy`: 队首的未执行的任务直接出队, 并让当前任务入队

除了通过构造方法构建线程池之外还可以通过 Executor 框架的工具类 Executors.java 构建

*   newFixedThreadPool: 创建一个具有固定线程个数的线程池
*   newSingleThreadExecutor: 创建一个只包含了一个线程的线程池, 但其队列是 unbounded (可以放很多任务), 按照任务提交的顺序依次执行
*   newCachedThreadPool: 创建一个没有上限的线程池(Integer.MAX_VALUE), 默认线程的回收时间是 60 s; 所有任务优先在已有的线程中执行, 官方给出的解释是比较适合用来执行: short-lived asynchronous tasks
*   newScheduledThreadPool: 主要是用来返回 -> ScheduledThreadPoolExecutor

>   阿里巴巴开发手册禁止使用 Executors 工具类创建线程池:
>
>   *   newFixThreadPool 和 newSignleThreadExecutor 默认配置的 workQueue 是一个链表, 默认的容量上限是 Integer.MAX_VALUE
>   *   newCachedThreadPool 会没有上限的创建线程, 同时使用的是 SynchronousQueue 没有容量上限

一般的, 有如下几种 BlockingQueue:

*   LinkedBlockingQueue: 在 newFixedThreadPool 和 newSignleThreadExecutor 中使用, 基于链表实现, 默认上限是 Integer.MAX_VALUE
*   SynchronousQueue: 在 newCachedThreadPool 中使用, 同步队列, 相比于队列, 更类似同步点, 每个 offer 和 take 都是对应的, 当一个线程调用 offer 后进入阻塞, 直到另外一个线程调用 take; 在 newCachedThreadPool 中, 只要任务提交的速度足够快, 那么线程池创建线程的速度也飞快, 没有容量上限
*   DelayedWorkQueue: 在 newScheduledThreadPool 中使用, 基于堆实现, 按照延时的时间对各个任务排序, 延时短的任务排在堆顶

 一般而言, 用户程序提交的任务首先会被呈递给 core thread (corePoolSize 确定), 如果 core thread 均在工作, 则试图将任务置于 BlockingQueue, 在队列已满后才会继续尝试创建新队列执行新的任务 (maximumPoolSize 确定), 最终无法被执行的任务会根据 handler 执行拒绝策略

## API 对比

*   Runnable & Callable: 都用来抽象任务, 区别在于:

    *   Runnable 没有返回值, 且不会显式抛出异常, 不需要进行异常处理
    *   Callable 具有一个泛型类型表示返回值, 且需要主动进行异常处理
    *   在工具类 Executors 中提供了方法 callable() 用来将一个 runnable 对象转化为 Callable\<Object>; callable(Runnable task, T result) 还可以用来确定返回值类型

*   execute() & submit(): 都用来进行任务的提交, 区别在于:
    *   execute() 没有返回值, 自然也没有任务的执行结果
    *   submit() 返回一个 Future 类型的对象; 当应用线程调用了 Future 的 get 方法后, 会被阻塞直到任务完成返回; 当然 jdk 也提供了 get(long timout, TimeUnit unit) 用来保证 get 可以在限定的时间内返回 -> 以 exception 的形式返回: java.util.concurrent.TimeoutException

## 状态维护

ThreadExecutorPool 内部通过两个字段 runState (运行状态) 与 workerCount (线程数量) 维护线程池的运行状态

而实际在内部表示中, ThreadExecutorPool 使用 bit mode 将两个字段合成为一个字段表示

```java
// ThreadPoolExecutor.java

public class ThreadPoolExecutor extends AbstractExecutorService {
    /**
     * The main pool control state, ctl, is an atomic integer packing
     * two conceptual fields
     *   workerCount, indicating the effective number of threads
     *   runState,    indicating whether running, shutting down etc
     *
     * In order to pack them into one int, we limit workerCount to
     * (2^29)-1 (about 500 million) threads rather than (2^31)-1 (2
     * billion) otherwise representable. If this is ever an issue in
     * the future, the variable can be changed to be an AtomicLong,
     * and the shift/mask constants below adjusted. But until the need
     * arises, this code is a bit faster and simpler using an int.
     *
     * The workerCount is the number of workers that have been
     * permitted to start and not permitted to stop.  The value may be
     * transiently different from the actual number of live threads,
     * for example when a ThreadFactory fails to create a thread when
     * asked, and when exiting threads are still performing
     * bookkeeping before terminating. The user-visible pool size is
     * reported as the current size of the workers set.
     *
     * The runState provides the main lifecycle control, taking on values:
     *
     *   RUNNING:  Accept new tasks and process queued tasks
     *   SHUTDOWN: Don't accept new tasks, but process queued tasks
     *   STOP:     Don't accept new tasks, don't process queued tasks,
     *             and interrupt in-progress tasks
     *   TIDYING:  All tasks have terminated, workerCount is zero,
     *             the thread transitioning to state TIDYING
     *             will run the terminated() hook method
     *   TERMINATED: terminated() has completed
     *
     * The numerical order among these values matters, to allow
     * ordered comparisons. The runState monotonically increases over
     * time, but need not hit each state. The transitions are:
     *
     * RUNNING -> SHUTDOWN
     *    On invocation of shutdown()
     * (RUNNING or SHUTDOWN) -> STOP
     *    On invocation of shutdownNow()
     * SHUTDOWN -> TIDYING
     *    When both queue and pool are empty
     * STOP -> TIDYING
     *    When pool is empty
     * TIDYING -> TERMINATED
     *    When the terminated() hook method has completed
     *
     * Threads waiting in awaitTermination() will return when the
     * state reaches TERMINATED.
     *
     * Detecting the transition from SHUTDOWN to TIDYING is less
     * straightforward than you'd like because the queue may become
     * empty after non-empty and vice versa during SHUTDOWN state, but
     * we can only terminate if, after seeing that it is empty, we see
     * that workerCount is 0 (which sometimes entails a recheck -- see
     * below).
     */
    private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
    private static final int COUNT_BITS = Integer.SIZE - 3;
    private static final int COUNT_MASK = (1 << COUNT_BITS) - 1;

    // runState is stored in the high-order bits
    private static final int RUNNING    = -1 << COUNT_BITS;
    private static final int SHUTDOWN   =  0 << COUNT_BITS;
    private static final int STOP       =  1 << COUNT_BITS;
    private static final int TIDYING    =  2 << COUNT_BITS;
    private static final int TERMINATED =  3 << COUNT_BITS;

    // Packing and unpacking ctl
    private static int runStateOf(int c)     { return c & ~COUNT_MASK; }
    private static int workerCountOf(int c)  { return c & COUNT_MASK; }
    private static int ctlOf(int rs, int wc) { return rs | wc; }
}
```

源码中可以看到 ThreadExecutorPool 采用字段 ctl 维护状态, 其中 ctl 的高 3 bit 表示当前的运行状态, 低 29 bit 用于记录线程个数

在源码中也说明了, 线程池具有若干种状态:

* RUNNING: 既可以接受新提交的任务, 也可以处理当前队列中缓存的任务
* SHUTDOWN: 不能接受新提交的任务了, 只能调度当前队列中已经缓存的任务
* STOP: 既不能接受新提交的任务, 也不能调度当前队列中缓存的任务, 被缓存的任务会被中断
* TIDYING: 缓存队列被清空了, 线程池也空了, 转变为了 TIDYING 状态, 该状态下唯一的操作就是调用方法 terminate()
* TERMINATED: terminate() 方法返回

## execute

在 ThreadPoolExecutor 正常运行时, 进行任务提交会按照如下流程进行任务调度:

![](https://cdn.jsdelivr.net/gh/buzzxI/img@latest/img/24/07/16/16:22:26:ThreadPoolExecutor_execute.png)

线程池刚刚初始化时, 此时线程池中的线程数量小于 corePoolSize, 此时会创建新线程执行任务 => 即便此时存在空闲线程还是会创建新线程

一旦当前运行的线程的数量达到了 corePoolSize, 此后任务会被添加到阻塞队列中 (workQueue)

只有在阻塞队列满时会进一步判断当前线程数是否已经达到了 maximumPoolSize, 如果没有达到则会创建额外的线程执行任务 => 额外的线程执行的是被刚刚提交的任务, 不是队列头的任务

如果当前线程数达到了 maximumPoolSize, 额外的任务会根据拒绝策略被拒绝

```java
// ThreadPoolExecutor.java

/**
 * Executes the given task sometime in the future.  The task
 * may execute in a new thread or in an existing pooled thread.
 *
 * If the task cannot be submitted for execution, either because this
 * executor has been shutdown or because its capacity has been reached,
 * the task is handled by the current {@link RejectedExecutionHandler}.
 *
 * @param command the task to execute
 * @throws RejectedExecutionException at discretion of
 *         {@code RejectedExecutionHandler}, if the task
 *         cannot be accepted for execution
 * @throws NullPointerException if {@code command} is null
 */
public void execute(Runnable command) {
    if (command == null)
        throw new NullPointerException();
    /*
     * Proceed in 3 steps:
     *
     * 1. If fewer than corePoolSize threads are running, try to
     * start a new thread with the given command as its first
     * task.  The call to addWorker atomically checks runState and
     * workerCount, and so prevents false alarms that would add
     * threads when it shouldn't, by returning false.
     *
     * 2. If a task can be successfully queued, then we still need
     * to double-check whether we should have added a thread
     * (because existing ones died since last checking) or that
     * the pool shut down since entry into this method. So we
     * recheck state and if necessary roll back the enqueuing if
     * stopped, or start a new thread if there are none.
     *
     * 3. If we cannot queue task, then we try to add a new
     * thread.  If it fails, we know we are shut down or saturated
     * and so reject the task.
     */
    int c = ctl.get();
    if (workerCountOf(c) < corePoolSize) {
        if (addWorker(command, true))
            return;
        c = ctl.get();
    }
    if (isRunning(c) && workQueue.offer(command)) {
        int recheck = ctl.get();
        if (! isRunning(recheck) && remove(command))
            reject(command);
        else if (workerCountOf(recheck) == 0)
            addWorker(null, false);
    }
    else if (!addWorker(command, false))
        reject(command);
}
```

# 线程安全的工具类

*   CopyOnWriteArrayList: 线程安全的 ArrayList, 主要面向读多写少的场景, 每次进行更新 (set) 或添加 (add) 操作时都不是对原有的数组进行修改, 而是直接创建一个新的数组, 进行覆盖替换
*   BlockQueue: 线程安全的 Queue, 阻塞队列, 主要面向消费者/生产者的场景
*   ConcurrentHashMap: 线程安全的 HashMap, 通过 CAS + 锁拆分的方式进行优化, 本质上还是通过数组 + 链表的方式实现的, hash 对应 idx 的位置为空时采用 CAS 赋值; 否则获取当前 idx 对应的锁后再进行元素添加 -> 锁拆分

## DelayQueue

延迟队列, 本质上是一个阻塞队列, 所有的任务都需要实现接口 Delayed

```java
// Delayed.java

public interface Delayed extends Comparable<Delayed> {

    /**
     * Returns the remaining delay associated with this object, in the
     * given time unit.
     *
     * @param unit the time unit
     * @return the remaining delay; zero or negative values indicate
     * that the delay has already elapsed
     */
    long getDelay(TimeUnit unit);
}
```

因为这个接口继承了接口 Comparable, 自定义的任务需要实现方法 getDelay() 与方法 compareTo()

一种比较简单的实现

```java
class DelayedTask implements Delayed {
    private final long executeTime;
    private final Runnable task;

    public DelayedTask(long delay, Runnable task) {
        this.executeTime = System.currentTimeMillis() + delay;
        this.task = task;
    }

    public Runnable getTask() {
        return task;
    }

    @Override
    public long getDelay(TimeUnit unit) {
        return unit.convert(executeTime - System.currentTimeMillis(), TimeUnit.MILLISECONDS);
    }

    @Override
    public int compareTo(Delayed o) {
        return Long.compare(this.executeTime, ((DelayedTask) o).executeTime);
    }
}
```

方法 getDelay() 用来返回当前时间到任务执行时间的差值; 方法 compareTo() 用来比较当前任务的执行时间和参数任务的执行时间

其实在实现了这两个方法之后, 大概也能知道 DelayQueue 是怎么实现的, 通过小顶堆维护延迟任务, 堆顶任务一定是执行之间最近的, 线程获取任务时, 只有在任务超时后才会返回

这里主要关注同步阻塞方法 take 的实现

```java
// DelayQueue.java

private final transient ReentrantLock lock = new ReentrantLock();
private final PriorityQueue<E> q = new PriorityQueue<E>();

/**
 * Thread designated to wait for the element at the head of
 * the queue.  This variant of the Leader-Follower pattern
 * (http://www.cs.wustl.edu/~schmidt/POSA/POSA2/) serves to
 * minimize unnecessary timed waiting.  When a thread becomes
 * the leader, it waits only for the next delay to elapse, but
 * other threads await indefinitely.  The leader thread must
 * signal some other thread before returning from take() or
 * poll(...), unless some other thread becomes leader in the
 * interim.  Whenever the head of the queue is replaced with
 * an element with an earlier expiration time, the leader
 * field is invalidated by being reset to null, and some
 * waiting thread, but not necessarily the current leader, is
 * signalled.  So waiting threads must be prepared to acquire
 * and lose leadership while waiting.
 */
private Thread leader;

/**
 * Condition signalled when a newer element becomes available
 * at the head of the queue or a new thread may need to
 * become leader.
 */
private final Condition available = lock.newCondition();

/**
 * Retrieves and removes the head of this queue, waiting if necessary
 * until an element with an expired delay is available on this queue.
 *
 * @return the head of this queue
 * @throws InterruptedException {@inheritDoc}
 */
public E take() throws InterruptedException {
    // 线程安全的方法, 因此执行之前需要获取锁
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        for (;;) {
            E first = q.peek();
            // 堆顶为空, 当前线程阻塞在条件数上
            if (first == null)
                available.await();
            else {
                // 获取堆顶任务的剩余时间
                long delay = first.getDelay(NANOSECONDS);
                // 剩余时间小于 0, 当前线程返回堆顶任务
                if (delay <= 0L)
                    return q.poll();
                first = null; // don't retain ref while waiting
                // leader 用来标识是否有线程正在等待堆顶任务超时
                // 如果 leader 不为 null, 说明此时已经有线程等待堆顶任务了, 阻塞当前线程即可
                if (leader != null)
                    available.await();
                else {
                    // leader 为 null, 说明此时没有线程等待堆顶任务完成
                    // 那当前线程设置为 leader 即可
                    Thread thisThread = Thread.currentThread();
                    leader = thisThread;
                    // 当前线程的等待时间为堆顶任务的超时时间
                    try {
                        available.awaitNanos(delay);
                    } finally {
                        if (leader == thisThread)
                            leader = null;
                    }
                }
            }
        }
    } finally {
        // 这部分一定会执行, 当前线程在获取到任务之后, 在堆顶不为空的情况下, 唤醒其余线程
        if (leader == null && q.peek() != null)
            available.signal();
        lock.unlock();
    }
}
```

因为 DelayQueue 是一个线程安全的队列, 因此不管是添加 (offer), 还是获取 (take) 都需要获取锁对象

```java
// DelayQueue.java

/**
 * Inserts the specified element into this delay queue.
 *
 * @param e the element to add
 * @return {@code true}
 * @throws NullPointerException if the specified element is null
 */
public boolean offer(E e) {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        q.offer(e);
        // 如果新添加的任务变成了堆顶, 就会设置 leader 为 null, 表示还没有线程等待堆顶任务
        // 此时直接唤醒等待的各个线程
        if (q.peek() == e) {
            leader = null;
            available.signal();
        }
        return true;
    } finally {
        lock.unlock();
    }
}
```





